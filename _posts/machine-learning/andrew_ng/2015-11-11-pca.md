---
layout: page
title: Principal Component Analysis (PCA)
tagline: Dimensionality Reduction
categories: machine-learning

---

#### Motivation:

1. Data Compression
2. Data Visualization

#### PCA Problem Formulation

- Minimize the projection error.
- PCA is not linear regression.

#### PCA Algorithm

1. Mean normalization
2. covariance matrix

$$
\Sigma = \frac{1}{m}\sum_{i=1}^n(x^{(i)})(x^{(i)})^T
$$

Compute "eigenvector" of matrix $$\Sigma$$

[U,S,V] = svd(Sigma)

`SVD`: singular value decomposition

$$
U \in R^{n \times n}
$$

Reconstruction from compressed representation

---

降维：把多个类似的维度合并成一个。

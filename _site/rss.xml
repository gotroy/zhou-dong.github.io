<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
        <title>Dong</title>
        <description>Dong - Dong Zhou</description>
        <link>http://zhou-dong.github.io</link>
        <link>http://zhou-dong.github.io</link>
        <lastBuildDate>2015-06-03T13:19:02-05:00</lastBuildDate>
        <pubDate>2015-06-03T13:19:02-05:00</pubDate>
        <ttl>1800</ttl>


        <item>
                <title>Javascript Notes</title>
                <description>
&lt;p&gt;javascript:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ECMAscript&lt;/li&gt;
  &lt;li&gt;DOM&lt;/li&gt;
  &lt;li&gt;BOM&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;defer=’defer’: 立即下载，但是页面渲染完以后再执行
asyn=’asyn’: 立即下载，但是不阻断页面的渲染，也不能保证javascript的执行顺序&lt;/p&gt;

&lt;p&gt;JQuery&lt;/p&gt;

&lt;p&gt;Javascript原生的方法就是可以把function当做参数来传递，jquery继承了这个方式&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
$(document).ready(function(){
    $(&#39;div&#39;).click(function(){
        $(this).hover(
            function(){
                //do some thing
            };
            function(){
                //do some thing
            } ;
        );
    });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JQuery selector&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;原生的DOM对象直接用引号&lt;/li&gt;
  &lt;li&gt;. # 选择class和id&lt;/li&gt;
  &lt;li&gt;可以使用CSS的选择器&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;
var $p = $(&quot;p&quot;);
var $div = $(&#39;div&#39;);
var $ol = $(&#39;ol&#39;) ;
var $cls = $(&quot;.class-name&quot;) ;
var $id = $(&quot;#id-name&quot;);
var $name = $(&#39;input[name=name-attr]&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;JQuery UI&lt;/p&gt;

&lt;p&gt;JQuery UI添加了各种动画效果的实现和更多的内置样式。&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/javascript%20jquery/2015/05/29/js</link>
                <guid>http://zhou-dong.github.io/javascript%20jquery/2015/05/29/js</guid>
                <pubDate>2015-05-29T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Statistics</title>
                <description>
&lt;h2 id=&quot;section&quot;&gt;统计学习方法笔记&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;统计学习方法概论&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;感知机&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;k邻近法&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;朴素贝叶斯法&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;决策树&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;逻辑斯蒂回归与最大熵模型&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;支持向量机&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;提升方法&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;EM算法及其推广&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;隐含马尔科夫模型&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;条件随机场&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
                <link>http://zhou-dong.github.io/2015/05/28/statistics</link>
                <guid>http://zhou-dong.github.io/2015/05/28/statistics</guid>
                <pubDate>2015-05-28T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>HTML CSS Bootstrap</title>
                <description>
&lt;h4 id=&quot;bootstrap&quot;&gt;Bootstrap&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Bootstrap把页面分为12列，称为grid&lt;/li&gt;
  &lt;li&gt;class=”container” 是正文部分，包含了边距等&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;html&quot;&gt;HTML&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;导航栏应该有ul + li&lt;/li&gt;
  &lt;li&gt;好像差不多也没啥可说的&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;css&quot;&gt;CSS&lt;/h4&gt;

&lt;p&gt;display&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;block: 重新起一行&lt;/li&gt;
  &lt;li&gt;inline: 在原有行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;position &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;relative: 与&lt;strong&gt;本应该在的位置&lt;/strong&gt;的相对位置&lt;/li&gt;
  &lt;li&gt;absolute：在页面的中的绝对位置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;background-attachment: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;fixed: 背景不随下来框移动&lt;/li&gt;
  &lt;li&gt;scroll: 默认值。背景图像会随着页面其余部分的滚动而移动。&lt;/li&gt;
  &lt;li&gt;inherit: 规定应该从父元素继承 background-attachment 属性的设置。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;margin:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;margin-left: auto 最大限度的向右&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;margin-right: auto 最大限度的向左&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;同时margin-left:auto, margin-right:auto&lt;/li&gt;
  &lt;li&gt;或者margin: auto&lt;/li&gt;
  &lt;li&gt;向左和向右中和了，所以居中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;border-redius: 100% 圆圈&lt;/p&gt;

</description>
                <link>http://zhou-dong.github.io/2015/05/26/html-css</link>
                <guid>http://zhou-dong.github.io/2015/05/26/html-css</guid>
                <pubDate>2015-05-26T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Javascript Notes</title>
                <description>
&lt;h4 id=&quot;section&quot;&gt;原型：&lt;/h4&gt;

&lt;p&gt;参考地址： http://www.ruanyifeng.com/blog/2011/06/designing_ideas_of_inheritance_mechanism_in_javascript.html&lt;/p&gt;

&lt;p&gt;javascript 使用&lt;strong&gt;构造函数&lt;/strong&gt;来构造一个对象，如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
function Person(name, age){  
    this.name = name;
    this.age = age;
};
var person1 = new Person(&quot;Linda&quot;, 28) ;
var person2 = new Person(&quot;Snow&quot;, 24) ;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样的缺点是，那就是无法共享属性和方法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
function Female(name, age){
    this.name = name ;
    this.age = age ;
    this.gender = &#39;female&#39; ;
};
var person1 = new Female(&quot;Linda&quot;, 28) ;
var person2 = new Female(&quot;Snow&quot;, 24) ;
person1.gender = &#39;male&#39; ;
console.log(person1.gender) // male
console.log(person2.gender) //female
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;每一个实例对象，都有自己的属性和方法的副本。这不仅无法做到数据共享，也是极大的资源浪费。&lt;/p&gt;

&lt;p&gt;考虑到这一点，Brendan Eich决定为构造函数设置一个prototype属性。&lt;/p&gt;

&lt;p&gt;这个属性包含一个对象（以下简称”prototype对象”），所有实例对象需要共享的属性和方法，都放在这个对象里面；那些不需要共享的属性和方法，就放在构造函数里面。&lt;/p&gt;

&lt;p&gt;实例对象一旦创建，将自动引用prototype对象的属性和方法。也就是说，实例对象的属性和方法，分成两种，一种是本地的，另一种是引用的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
function Female(name, age){
    this.name = name ;
    this.age = age ;
};
Female.prototype = {gender: &#39;female&#39;} ;
var person1 = new Female(&quot;Linda&quot;, 28) ;
var person2 = new Female(&quot;Snow&quot;, 24) ;
console.log(person1.gender) // female
console.log(person2.gender) //female
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&quot;section-1&quot;&gt;总结&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;
由于所有的实例对象共享同一个prototype对象，那么从外界看起来，prototype对象就好像是实例对象的原型，而实例对象则好像&quot;继承&quot;了prototype对象一样。
&lt;/code&gt;&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/javascript/2015/05/25/js-note</link>
                <guid>http://zhou-dong.github.io/javascript/2015/05/25/js-note</guid>
                <pubDate>2015-05-25T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Review Machine learning in action</title>
                <description>
&lt;h4 id=&quot;supervised-learning-method&quot;&gt;Supervised Learning method&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;KNN (k nearest neighbor)
    &lt;ol&gt;
      &lt;li&gt;Calculate the distance will all the data.&lt;/li&gt;
      &lt;li&gt;Find the nearest k data&lt;/li&gt;
      &lt;li&gt;From this k nearest data find the most frequent category&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Decision Tree
    &lt;ol&gt;
      &lt;li&gt;Find the most efficient propercity to divided the datas&lt;/li&gt;
      &lt;li&gt;Check if all the sub tree has been divied&lt;/li&gt;
      &lt;li&gt;If not recurive steps 1 and 2&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Naive Bayes
    &lt;ul&gt;
      &lt;li&gt;根据朴素贝叶斯概率模型来计算一个目标可能出现在哪个分类中&lt;/li&gt;
      &lt;li&gt;如果出现在分来A的概率大于出现在分类B的概率，则结果为A反之为B&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Regression
    &lt;ul&gt;
      &lt;li&gt;找出或者画出一条可以拟合数据走向的线&lt;/li&gt;
      &lt;li&gt;最小二乘&lt;/li&gt;
      &lt;li&gt;logistic regression&lt;/li&gt;
      &lt;li&gt;CART Classification-and-Regression-Trees&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SVM (support vector machine)
    &lt;ul&gt;
      &lt;li&gt;找出支撑点&lt;/li&gt;
      &lt;li&gt;利用kernel把地位的数据映射到高维求解&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Adaboost
    &lt;ul&gt;
      &lt;li&gt;可以多次重复同一函数，也可用不同函数&lt;/li&gt;
      &lt;li&gt;每次计算以后，增加错误数据的权重，减小正确数据的权重&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;unsupervised-learning-method&quot;&gt;Unsupervised Learning method&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;K means
    &lt;ul&gt;
      &lt;li&gt;首先定义K个中心店，然后计算所有点到这些点的距离&lt;/li&gt;
      &lt;li&gt;把里这些点最近的点合成一簇，&lt;/li&gt;
      &lt;li&gt;找出簇内的中心店，继续迭代&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Apriori
    &lt;ul&gt;
      &lt;li&gt;原理是认为如果一项不频繁，那些包含它的集合也不是频繁项&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;FP-Growth
    &lt;ul&gt;
      &lt;li&gt;先构建FP tree&lt;/li&gt;
      &lt;li&gt;扫描FP tree，获得频繁项&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;other-optimize&quot;&gt;Other optimize&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;PCA
    &lt;ul&gt;
      &lt;li&gt;找出最能表现数据的维度作为坐标轴&lt;/li&gt;
      &lt;li&gt;通过这种方式来降维&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SVD
    &lt;ul&gt;
      &lt;li&gt;把一个大的系数矩阵，切分为几个矩阵来运算&lt;/li&gt;
      &lt;li&gt;通过上面的方法来达到降维的目的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/2015/05/24/reviews</link>
                <guid>http://zhou-dong.github.io/machine-learning/2015/05/24/reviews</guid>
                <pubDate>2015-05-24T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Introduction to NLP</title>
                <description>
&lt;p&gt;分析一段句子的步骤&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Tagging（词性标注）
    &lt;ul&gt;
      &lt;li&gt;单词词性的标注。
        &lt;ul&gt;
          &lt;li&gt;Verb&lt;/li&gt;
          &lt;li&gt;Noun&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;命名体识别，几个单词组成一个词，如：
        &lt;ul&gt;
          &lt;li&gt;人名：John Hopkins&lt;/li&gt;
          &lt;li&gt;地点：Wall Street&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Phase（句子划分）
    &lt;ul&gt;
      &lt;li&gt;Definition:
        &lt;ul&gt;
          &lt;li&gt;根据英语语法的规则来切分句子&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;method：
        &lt;ul&gt;
          &lt;li&gt;Parse Tree&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;例子:
        &lt;ul&gt;
          &lt;li&gt;主谓宾&lt;/li&gt;
          &lt;li&gt;定状补&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Context Free Grammer
        &lt;ul&gt;
          &lt;li&gt;与具体的单词意思无关&lt;/li&gt;
          &lt;li&gt;根据单词的词性，以及在上下文中的位置&lt;/li&gt;
          &lt;li&gt;来切分句子&lt;/li&gt;
          &lt;li&gt;在不同的切分中，找到概率最高的&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Probabilistic Context-Free Grammars(PCFG)
        &lt;ul&gt;
          &lt;li&gt;CKY (one of dynamic programming)&lt;/li&gt;
          &lt;li&gt;Use dynamic programming to find the max probalities&lt;/li&gt;
          &lt;li&gt;Chomsky Normal Form&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Weaknesses of PCFGs
        &lt;ul&gt;
          &lt;li&gt;Lack of sensitivity of lexical information&lt;/li&gt;
          &lt;li&gt;Lack of sensitivity of structural frequencies&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Lexical of PCFGs&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Machine Translation&lt;/p&gt;

&lt;p&gt;First genereaion&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;IBM Model&lt;/li&gt;
  &lt;li&gt;EM Algorithm for IBM Model&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Second generation&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;phase based translation&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/2015/05/10/intro</link>
                <guid>http://zhou-dong.github.io/2015/05/10/intro</guid>
                <pubDate>2015-05-10T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>CS-5549 Final Review</title>
                <description>
&lt;p&gt;Greddy Algorithm&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Description:
    &lt;ul&gt;
      &lt;li&gt;是一种在每一步选择中都采取在当前状态下最好或最优（即最有利）的选择，从而希望导致结果是最好或最优的算法。比如在旅行推销员问题中，如果旅行员每次都选择最近的城市，那这就是一种贪心算法。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;用在哪些地方：
    &lt;ul&gt;
      &lt;li&gt;贪心法可以解决一些最优化问题，如：求图中的最小生成树、求哈夫曼编码……对于其他问题。&lt;/li&gt;
      &lt;li&gt;贪心法一般不能得到我们所要求的答案。一旦一个问题可以通过贪心法来解决，那么贪心法一般是解决这个问题的最好办法。&lt;/li&gt;
      &lt;li&gt;由于贪心法的高效性以及其所求得的答案比较接近最优结果，贪心法也可以用作辅助算法或者直接解决一些要求结果不特别精确的问题。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;我们学过的贪心算法：
    &lt;ul&gt;
      &lt;li&gt;Prime&lt;/li&gt;
      &lt;li&gt;Kruskal&lt;/li&gt;
      &lt;li&gt;Dijkstra&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Search Tree or Map&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Breadth First Search
    &lt;ul&gt;
      &lt;li&gt;先建立priori queue&lt;/li&gt;
      &lt;li&gt;先进先出，然后遍历所有的的结点。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Depth First Search
    &lt;ul&gt;
      &lt;li&gt;朝一个方向深度遍历。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Minimum Spanning Tree&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;最小生成树的边，应该是顶点总数减一：(total_vertex-1)。&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Prime
    &lt;ul&gt;
      &lt;li&gt;Description: 由一条最短的边，逐渐扩展成一棵树&lt;/li&gt;
      &lt;li&gt;Steps:
        &lt;ol&gt;
          &lt;li&gt;随便找一个顶点，然后找出与这个顶点相连的最的边。把这条变加入到树中。&lt;/li&gt;
          &lt;li&gt;找出与这棵树相连的最短的边，加入树中。&lt;/li&gt;
          &lt;li&gt;重复步骤2，直到所有的定点都加入到树中。&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Kruskal
    &lt;ul&gt;
      &lt;li&gt;Description: 找出最短的边，以每个边为基础，生成多个tree，然后这些tree合并成一个tree。&lt;/li&gt;
      &lt;li&gt;Steps:
        &lt;ol&gt;
          &lt;li&gt;首先按边进行排序，并放在queue中。&lt;/li&gt;
          &lt;li&gt;新建一个key-value set，来标记这些点是否已经在set中。&lt;/li&gt;
          &lt;li&gt;依次中queue中取出边，如果两个顶点都不在set中，这个边加入到set中。&lt;/li&gt;
          &lt;li&gt;重复第二步，直到所有的点都加入到set中。&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Single Source Shortest Path&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Bellman Ford
    &lt;ul&gt;
      &lt;li&gt;Specical: can work on negative edge weight graph&lt;/li&gt;
      &lt;li&gt;Description: 多次松弛。&lt;/li&gt;
      &lt;li&gt;Steps:
        &lt;ol&gt;
          &lt;li&gt;设置开始结点离所有点的距离都为无穷大。&lt;/li&gt;
          &lt;li&gt;遍历所开始结点相邻的所有点，并且更新距离。&lt;/li&gt;
          &lt;li&gt;依次遍历，剩下的结点，如果通过剩下的结点，可以使到开始结点的距离变短，更新结点，并更新父结点。&lt;/li&gt;
          &lt;li&gt;重复上面的步骤n(结点的个数)次。&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dijkstra:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=5GT5hYzjNoo&quot;&gt;教学视频&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Description: 找到最短的路径，然后逐渐的松弛每条边，然后找出单点到其它点的最短路径。&lt;/li&gt;
      &lt;li&gt;Stepson：
        &lt;ol&gt;
          &lt;li&gt;找出与起始点相连的所有点，然后找出其中距离最短的点&lt;/li&gt;
          &lt;li&gt;通过最短的点来做松弛。并标记松弛点的来源。&lt;/li&gt;
          &lt;li&gt;在剩下的点中，找出最短的点，并通过这个点做松弛。&lt;/li&gt;
          &lt;li&gt;重复第3步，直到使用完所有的点做松弛。&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;More：
        &lt;ul&gt;
          &lt;li&gt;可以用堆做优化，来找出距离最短的电&lt;/li&gt;
          &lt;li&gt;可以继续优化成斐波那契堆，可以更高的提高效率。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Multiple Source Shortest Path&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Floyd Warshall
    &lt;ul&gt;
      &lt;li&gt;时间复杂度是n的立方&lt;/li&gt;
      &lt;li&gt;Steps: 所有点依次通过每个点，到其它点的距离做松弛。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Johnson’s Algorithm
    &lt;ol&gt;
      &lt;li&gt;在图的外边添加另一个顶点q，并初始化q到其它点的距离为0&lt;/li&gt;
      &lt;li&gt;使用Bellman Ford算法，求q到其它点的距离。&lt;/li&gt;
      &lt;li&gt;reweight各个点之间的距离。&lt;/li&gt;
      &lt;li&gt;使用Dijkstra算法，分别求出每个点到其它点的最短距离。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;NP-complete&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;简单来说，P = NP问题问道：如果是／不是问题的正面答案可以很快验证，其答案是否也可以很快计算？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;不严格的讲，NP完全问题是NP类中“最难”的问题，也就是说它们是最可能不属于P类的。&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Some problems are intractable: as they grow large, we are unable to solve them in reasonable time.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What constitutes &lt;code&gt;reasonable time&lt;/code&gt;? Standard working definition: &lt;code&gt;polynomial time&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Polynomial time: &lt;script type=&quot;math/tex&quot;&gt; O(n^2), O(n^3), O(1), O(n \log n) &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Not in polynomial time: &lt;script type=&quot;math/tex&quot;&gt; O(2^n), O(n^n), O(n!) &lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Polynomial-Time Algorithms&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We define P to be the class of problems solvable in polynomial time.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NP-Complete Problems&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The NP-Complete problems are an interesting class of problems whose status is unknown.&lt;/li&gt;
  &lt;li&gt;NP (nondeterministic polynomial time) is the set of problems that can be solved in polynomial time by a nondeterministic computer.&lt;/li&gt;
  &lt;li&gt;NP-hard Problem：对于这一类问题，用一句话概括他们的特征就是“at least as hard as the hardest problems in NP Problem”， 就是NP-hard问题至少和NP问题一样难。&lt;/li&gt;
  &lt;li&gt;NP-complete Problem: 对于这一类问题，他们满足两个性质:
    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;一个就是在polynomial时间内可以验证一个candidate answer是不是真正的解。&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;另一个性质就是我们可以把任何一个NP问题在polynomial的时间内把他的input转化，使之成为一个NP-complete问题。&lt;/strong&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;NP = problems verifiable in polynomial time&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;P: problems that can be solved in polynomial time&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;NP: problems for which a solution can be verified in polynomial time&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Unknown whether P = NP (most suspect not)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Example: Hamiltonian-cycle problem is in NP:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cannot solve in polynomial time&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Easy to verify solution in polynomial time (How?)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;All the P problem is NP problem.&lt;/li&gt;
  &lt;li&gt;Not all the NP problem are p problem.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;NP-Complete problems are the “hardest” problems in NP.&lt;/p&gt;

&lt;p&gt;NP-Complete可以简单地理解为：那些在NP中，同时最不可能在P中的问题。&lt;/p&gt;

</description>
                <link>http://zhou-dong.github.io/2015/04/28/final-review</link>
                <guid>http://zhou-dong.github.io/2015/04/28/final-review</guid>
                <pubDate>2015-04-28T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Text Retrieval and Search Engines</title>
                <description>
&lt;h3 id=&quot;vector-space-model&quot;&gt;Vector Space Model&lt;/h3&gt;

&lt;p&gt;Basic Idea is: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use &lt;code&gt;Dot Product&lt;/code&gt; to calculate the similarity between Query and Documents&lt;/li&gt;
  &lt;li&gt;两个向量求内积，通过这两个向量的内积来判断相似度。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Difficult part is to calculate the weight of the terms&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;TF
    &lt;ul&gt;
      &lt;li&gt;词频&lt;/li&gt;
      &lt;li&gt;Term在文档中出现的频率&lt;/li&gt;
      &lt;li&gt;Term在文章中出现的频率越高，说明Term与这个文章的主题越接近&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;IDF
    &lt;ul&gt;
      &lt;li&gt;逆文档频率&lt;/li&gt;
      &lt;li&gt;文档总数/包含这个term的文档数&lt;/li&gt;
      &lt;li&gt;包含这个Term的文档越多，说明这个Term在整体文档库中越不重要。&lt;/li&gt;
      &lt;li&gt;可以对这个值取log，来避免这个值太大&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Doc Length Normation
    &lt;ul&gt;
      &lt;li&gt;Pivoted length normalization&lt;/li&gt;
      &lt;li&gt;以doc的平均长度作为pivot，如果长度大于pivot减分；如果长度小于pivot加分。&lt;/li&gt;
      &lt;li&gt;K = (1-b) + b(dl/avdl)&lt;/li&gt;
      &lt;li&gt;把K作为分母，这样就可以保证大于pivot减分，小于pivot加分。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;BM25
    &lt;ul&gt;
      &lt;li&gt;通过4个维度来计算weight值
        &lt;ol&gt;
          &lt;li&gt;IDF&lt;/li&gt;
          &lt;li&gt;TF&lt;/li&gt;
          &lt;li&gt;Doc Length&lt;/li&gt;
          &lt;li&gt;Query TF&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;个人理解：
        &lt;ul&gt;
          &lt;li&gt;在各个维度都可以添加调节因子来计算weight的值&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;BM25F 
    &lt;ul&gt;
      &lt;li&gt;Name From: BM25 and Fields&lt;/li&gt;
      &lt;li&gt;(Term在各个域中出现的频率*这个域的调节因子)/这个域的文档长度&lt;/li&gt;
      &lt;li&gt;Term出现在doc的不同域中，会对doc的weight做出不同大小的贡献&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;probabilistic-retrieval-model&quot;&gt;Probabilistic Retrieval Model&lt;/h3&gt;

&lt;p&gt;Basic Idea is: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;计算每个Term出现在各个doc中的概率，可通过贝叶斯规则进行计算&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;P(A,B) = P(A) * P(B&lt;/td&gt;
          &lt;td&gt;A) = P(B) * P(A&lt;/td&gt;
          &lt;td&gt;B).&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;Example:&lt;/li&gt;
  &lt;li&gt;d1 a, a, a, b, c, e, f, f&lt;/li&gt;
  &lt;li&gt;d2 a, b, b, d, f, f, f, f&lt;/li&gt;
  &lt;li&gt;d3 b, b, c, c, d, d, d, f&lt;/li&gt;
  &lt;li&gt;total_a = 4&lt;/li&gt;
  &lt;li&gt;total_b = 5&lt;/li&gt;
  &lt;li&gt;total_c = 3&lt;/li&gt;
  &lt;li&gt;total_d = 4&lt;/li&gt;
  &lt;li&gt;total_e = 1&lt;/li&gt;
  &lt;li&gt;total_f = 7&lt;/li&gt;
  &lt;li&gt;Data:&lt;/li&gt;
  &lt;li&gt;p(d1,a)=3/4 p(d1,b)=1/5 p(d1,c)=1/3 p(d1,d)=0/4 p(d1,e)=1/1 p(d1,f)=2/7 &lt;/li&gt;
  &lt;li&gt;p(d2,a)=1/4 p(d2,b)=2/5 p(d2,c)=0/3 p(d2,d)=1/4 p(d2,e)=0/1 p(d2,f)=4/7 &lt;/li&gt;
  &lt;li&gt;p(d3,a)=0/4 p(d3,b)=2/5 p(d3,c)=2/3 p(d3,d)=3/4 p(d3,e)=0/1 p(d3,f)=1/7&lt;/li&gt;
  &lt;li&gt;p(d1) = 5/6&lt;/li&gt;
  &lt;li&gt;p(d2) = 4/6&lt;/li&gt;
  &lt;li&gt;p(d3) = 4/6 &lt;/li&gt;
  &lt;li&gt;p(a) = 4/24 &lt;/li&gt;
  &lt;li&gt;p(b) = 5/24 &lt;/li&gt;
  &lt;li&gt;p(c) = 3/24 &lt;/li&gt;
  &lt;li&gt;p(d) = 4/24 &lt;/li&gt;
  &lt;li&gt;p(e) = 1/24 &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;p(f) = 7/24&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Smoothing Methods&lt;/li&gt;
  &lt;li&gt;Rocchio Method&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;collaborative-filtering&quot;&gt;Collaborative Filtering&lt;/h3&gt;

&lt;p&gt;Basic Info： 根据相似的物或者相似的人，来推荐商品。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Items Based Filtering：基于item的协同过滤
    &lt;ul&gt;
      &lt;li&gt;通过商品的各个属性来求商品之间的相似度。&lt;/li&gt;
      &lt;li&gt;可以通过余弦相似来求给个商品之间的相似度。&lt;/li&gt;
      &lt;li&gt;通过这种方法可以返回与某个商品相似的商品。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Users Based Filtering：基于user的协同过滤
    &lt;ul&gt;
      &lt;li&gt;购买过这个商品的人还买过什么，是典型的协同过滤。&lt;/li&gt;
      &lt;li&gt;通过公共感兴趣的商品，来求人人之间的相似度。&lt;/li&gt;
      &lt;li&gt;然后根据相似的人来推荐产品。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;协同过滤的劣势是：如果一个人以前没有任何行为&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;就没有办法找到与他相似的人。&lt;/li&gt;
  &lt;li&gt;就没法适用协同过滤推荐商品。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们PEOPLE-TP-PEOPLE项目其实使用的就是协同过滤的思想。&lt;/p&gt;

&lt;h3 id=&quot;feedback&quot;&gt;Feedback&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;在用户中，做调查，哪些是有效的结果，哪些是无效的结果。
    &lt;ul&gt;
      &lt;li&gt;可以通过这些来查找同义词&lt;/li&gt;
      &lt;li&gt;也可以慢慢增加Term在doc中的权重&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pseudo Feedback
    &lt;ul&gt;
      &lt;li&gt;假设搜索返回的前N个是相关度高的，用这些相关度高的文章来训练query的同义词。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Implicit Feedback
    &lt;ul&gt;
      &lt;li&gt;通过分析的对搜索结果的行为，如浏览、点击等来查找query的同义词。&lt;/li&gt;
      &lt;li&gt;也可以增加Term在doc中的权重。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;通过query中同时出现的词，来查找query的同义词。
    &lt;ul&gt;
      &lt;li&gt;FP-Growth&lt;/li&gt;
      &lt;li&gt;Aprior&lt;/li&gt;
      &lt;li&gt;Vertical index&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Rocchio Feedback
    &lt;ul&gt;
      &lt;li&gt;使query逐渐与目标doc相似&lt;/li&gt;
      &lt;li&gt;增加query的同义词&lt;/li&gt;
      &lt;li&gt;增强正影响，减少负影响&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;section&quot;&gt;二次搜索：&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;加入同义词重新搜索同一个索引库。&lt;/li&gt;
  &lt;li&gt;建立新的索引库专门为二次搜索提供服务。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;page-rank&quot;&gt;Page Rank&lt;/h3&gt;

&lt;p&gt;马尔科夫链：每行的值相加为1&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;求转移概率矩阵，假设a = 0.5&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1 -&amp;gt; 2, 3 -&amp;gt; 2, 2 -&amp;gt; 1, 2-&amp;gt; 3&lt;/p&gt;

&lt;p&gt;概率矩阵x：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;0.0 1.0 0.0&lt;/li&gt;
  &lt;li&gt;0.5 0.0 0.5&lt;/li&gt;
  &lt;li&gt;0.0 1.0 0.0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;随机跳转矩阵y：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1/3 1/3 1/3&lt;/li&gt;
  &lt;li&gt;1/3 1/3 1/3&lt;/li&gt;
  &lt;li&gt;1/3 1/3 1/3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;转移概率矩阵P：&lt;/p&gt;

&lt;p&gt;(1-a)x + ab = 0.5x + o.by =&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1/6 2/3 1/6&lt;/li&gt;
  &lt;li&gt;5/12 1/6 5/12&lt;/li&gt;
  &lt;li&gt;1/6 2/3 1/6&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;假设初始向量x_0 = (1 0 0)&lt;/p&gt;

&lt;p&gt;迭代运算，直到最后的值趋于稳定为止&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;x_0*p = (1/6 2/3 1/6) = x_1&lt;/li&gt;
  &lt;li&gt;x_1*p = (1/3 1/3 1/3) = x_2&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;x_2*p = (1/4 1/2 1/4) = x_3&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;x_n*p = (5/18 4/9 5/18) = x_{n+1}&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;hit&quot;&gt;HIT&lt;/h2&gt;

&lt;p&gt;对每个网页打分：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;hub值&lt;/li&gt;
  &lt;li&gt;authority值&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/data-mining/2015/04/17/search-engines</link>
                <guid>http://zhou-dong.github.io/data-mining/2015/04/17/search-engines</guid>
                <pubDate>2015-04-17T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Frequent Pattern Mining for Text Data</title>
                <description>
&lt;ol&gt;
  &lt;li&gt;Simultaneously inferring phrases and topics
    &lt;ul&gt;
      &lt;li&gt;Bigram Topic Model&lt;/li&gt;
      &lt;li&gt;Topical N-Grams&lt;/li&gt;
      &lt;li&gt;Phrase-Discovering LDA&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Post Topic Modeling Phrase Construction&lt;/li&gt;
  &lt;li&gt;First Phrase Mining then Topic Modeling&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Phrase Mining and Topic Modeling&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Generate bag-of-words to generate sequence of tokens&lt;/li&gt;
  &lt;li&gt;Post bag-of-words model inference, visualize topics with n-grams&lt;/li&gt;
  &lt;li&gt;Prior bag-of-words model inference, ming phrases and impose to the bag-of-words model&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;First Phrase Mining then Topic Modeling 先找出频繁项，然后再从里面找出文章的主题&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Perform frequent contiguous pattern mining to extract candidate phrases and their counts&lt;/li&gt;
  &lt;li&gt;bag-of-phrases&lt;/li&gt;
  &lt;li&gt;LDA&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Challenges for Data Analysis in Data Streams&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fast changing&lt;/li&gt;
  &lt;li&gt;In and out streaming&lt;/li&gt;
  &lt;li&gt;有的方式，想apriori或者FPgrowth，需要2次或者2次以上的读取数据，这些算法就不能用在data streams&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Spatiotemporal and Trajectory Pattern&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在空间的维度上找出pattern，比如在坐标上相近的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Software bug mining&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use pattern mining to find bugs in software&lt;/li&gt;
  &lt;li&gt;Static bug detection&lt;/li&gt;
  &lt;li&gt;dynamic bug detection&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;debugging&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;pattern mining&lt;/li&gt;
  &lt;li&gt;some patterns are likely bugs&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/2015/04/12/pattern-mining-text</link>
                <guid>http://zhou-dong.github.io/2015/04/12/pattern-mining-text</guid>
                <pubDate>2015-04-12T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Pattern Mining Methods</title>
                <description>
&lt;h3 id=&quot;apriori&quot;&gt;Apriori&lt;/h3&gt;

&lt;p&gt;Basic Knowledge:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Other name: Down Closure Property of Frequent Patterns&lt;/li&gt;
  &lt;li&gt;Discription: Any subset of frequent itemset must be frequent&lt;/li&gt;
  &lt;li&gt;Then: If any subset of itemset S is infrequent, then there is no change for S to be frequent&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;先在所有的数据集中找出每个item出现的频率&lt;/li&gt;
  &lt;li&gt;删除频率低的&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;我们就得到了出现频率大于某个阀值的items&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;通过第一次得到的数据，再去数据集中去查询同时出现2个商品，并记录他们的频率&lt;/li&gt;
  &lt;li&gt;删除其中出现频率低的&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这样我们就得到了出现频率大于某个阀值的一对items&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;通过第二次得到的数据，再去数据集中查询同时出现的3个商品，并记录他们的频率&lt;/li&gt;
  &lt;li&gt;删除其中频率低的&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这样我们就得到了一组频率大于某个阀值的3个同时出现的items&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;通过上面的算法，继续计算更多商品同时出现的频率。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Improvements:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Reduce passes of transaction database scans
    &lt;ul&gt;
      &lt;li&gt;Partitioning: Scan database only twice&lt;/li&gt;
      &lt;li&gt;Partition database and find local frequent patterns&lt;/li&gt;
      &lt;li&gt;Consilidate global frequent patterns&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Shrink the number of candidates&lt;/li&gt;
  &lt;li&gt;Exploring special data structure&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;eclat&quot;&gt;Eclat&lt;/h3&gt;

&lt;p&gt;Basic info&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Theory: Exploring vertical Data Format&lt;/li&gt;
  &lt;li&gt;Whole NameEquivalence Class Transformation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Method:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;给每个item建立索引，然后做并集&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Improvement：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果他们的并集很大的话，可以用他们的并集取反来来存贮结果，这样存贮和计算效率会更高。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;fpgrowth&quot;&gt;FPgrowth&lt;/h3&gt;

&lt;p&gt;Basic info&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;FP-tree&lt;/li&gt;
  &lt;li&gt;Mine each conditional pattern-base recursively&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;需要扫描两次数据集&lt;/li&gt;
  &lt;li&gt;第一次统计所有items的出现频率，删除频率较低的，然后对所有items按出现频率排序&lt;/li&gt;
  &lt;li&gt;第二次扫描，把所有的数据生成一棵树&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;相同商品，在不同的分支之间，应该关联起来。这样在第二部分的统计的时候会方便。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;分析生成的FP-tree，然后从下向上统计出与每个商品同时出现的商品。&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/apriori/eclat/fpgrowth/2015/04/12/pattern-mining-methods</link>
                <guid>http://zhou-dong.github.io/apriori/eclat/fpgrowth/2015/04/12/pattern-mining-methods</guid>
                <pubDate>2015-04-12T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Pattern Evaluation</title>
                <description>
&lt;p&gt;在同一个系统的中：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;不同的level应该有不同的阀值&lt;/li&gt;
  &lt;li&gt;不同的商品也应该有不同的阀值&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Multi-Dimensional Associations&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;single-dimensional 如果A买苹果，也买了香蕉&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Inter-dimensional 如果A是18-25岁，并且是学生，所以买coke&lt;/li&gt;
  &lt;li&gt;Hybrid-dimensional 如果A是18-25岁，并且买popcorn，可能会买coke&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Mining Quantitative Associations&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Numberical atrributes: age and salary&lt;/li&gt;
  &lt;li&gt;Deviation analysis: gender: male and female&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rare Patterns vs. Negative Patterns&lt;/p&gt;

&lt;p&gt;Rare Patterns&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Very low support but interesting&lt;/li&gt;
  &lt;li&gt;How to mine them? different group-based thresholds&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nagative Patterns&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Nagetively corealted &lt;/li&gt;
  &lt;li&gt;How to define&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Constraint Based Mining&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Different kinds of constraints lead to different pruning strategies&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;constraints can be categorized as&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Pattern sapce pruning (pruning某些data)
    &lt;ul&gt;
      &lt;li&gt;Anti-monotonic&lt;/li&gt;
      &lt;li&gt;Monotonic&lt;/li&gt;
      &lt;li&gt;Succinct&lt;/li&gt;
      &lt;li&gt;Convertible&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;data space pruning (pruning 一个data的一部分)
    &lt;ul&gt;
      &lt;li&gt;Data succinct&lt;/li&gt;
      &lt;li&gt;Data anti-monotonic&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Sequence Patterns&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Sequence Databases&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Gapped sequential patterns (GSP)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Non-gapped sequential patterns&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Generalized Sequential Patterns&lt;/li&gt;
  &lt;li&gt;Vertical format-based&lt;/li&gt;
  &lt;li&gt;Pattern-growth methods&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Pattern-Based Classification&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;apple pie&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;apple ipad&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;pattern first, then classification&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;CBA (Classification Based on Associations)&lt;/li&gt;
  &lt;li&gt;CMAR&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Discriminative Patterns&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;选取数据集中最具代表性的properties&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/2015/04/12/pattern-evaluation</link>
                <guid>http://zhou-dong.github.io/2015/04/12/pattern-evaluation</guid>
                <pubDate>2015-04-12T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Courses In Data Mining</title>
                <description>
&lt;ul&gt;
  &lt;li&gt;Pattern Discovery in Data Mining
    &lt;ol&gt;
      &lt;li&gt;A Brief Introduction to Data Mining
        &lt;ul&gt;
          &lt;li&gt;We are drowning in Data but straving for knowledge!&lt;/li&gt;
          &lt;li&gt;Necessity is the mother of invention&lt;/li&gt;
          &lt;li&gt;Knowledge mining from Data&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Pattern Discovery: Basic Concepts&lt;/li&gt;
      &lt;li&gt;Efficient Pattern Mining Methods
        &lt;ul&gt;
          &lt;li&gt;Down closure Property of Frequent Pattern (Apriori) &lt;/li&gt;
          &lt;li&gt;Any subset of frequent itemset must be frequent&lt;/li&gt;
          &lt;li&gt;If any subset of an itemset S infrequent, then there is no change for S to be frequent&lt;/li&gt;
          &lt;li&gt;I think it is kind of Dynamic Programming&lt;/li&gt;
          &lt;li&gt;Scalable mining methods: 3 major approaches&lt;/li&gt;
          &lt;li&gt;Apriori&lt;/li&gt;
          &lt;li&gt;Eclat&lt;/li&gt;
          &lt;li&gt;FPgrowth&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Pattern Evaluation
        &lt;ul&gt;
          &lt;li&gt;Objective: By math to calculate&lt;/li&gt;
          &lt;li&gt;Subjective: One man’s trash could be another man’s treasure&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Mining Diverse Frequdent Patterns&lt;/li&gt;
      &lt;li&gt;Constraint-Based Pattern Mining&lt;/li&gt;
      &lt;li&gt;Sequential Pattern Mining&lt;/li&gt;
      &lt;li&gt;Graph Pattern Mining&lt;/li&gt;
      &lt;li&gt;Pattern-Based Classification&lt;/li&gt;
      &lt;li&gt;Pattern Analysis: Application Exploration&lt;/li&gt;
      &lt;li&gt;Futher Topics on Pattern Analysis&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;More data mining steps:
    &lt;ul&gt;
      &lt;li&gt;Data Mining Process step 1
        &lt;ul&gt;
          &lt;li&gt;Data cleaning&lt;/li&gt;
          &lt;li&gt;Data integration&lt;/li&gt;
          &lt;li&gt;Data normalization&lt;/li&gt;
          &lt;li&gt;Feature selection&lt;/li&gt;
          &lt;li&gt;Dimension reduction&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Data Mining Process step 2
        &lt;ul&gt;
          &lt;li&gt;Multi-dimensional data summary&lt;/li&gt;
          &lt;li&gt;Pattern discovery&lt;/li&gt;
          &lt;li&gt;Association and correaltion&lt;/li&gt;
          &lt;li&gt;Classification&lt;/li&gt;
          &lt;li&gt;Clustering (How to group data from new categories)&lt;/li&gt;
          &lt;li&gt;Outlier analysis (Discovery of anomalies and rare events)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Data mining Process step 3
        &lt;ul&gt;
          &lt;li&gt;Pattern evalution&lt;/li&gt;
          &lt;li&gt;Pattern selection&lt;/li&gt;
          &lt;li&gt;Pattern interpretation&lt;/li&gt;
          &lt;li&gt;Pattern visualization &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Data mining include:
    &lt;ul&gt;
      &lt;li&gt;Machine Learning&lt;/li&gt;
      &lt;li&gt;Statistics&lt;/li&gt;
      &lt;li&gt;Pattern Recognition&lt;/li&gt;
      &lt;li&gt;Applications&lt;/li&gt;
      &lt;li&gt;Visualization&lt;/li&gt;
      &lt;li&gt;Algorithm&lt;/li&gt;
      &lt;li&gt;Database Technology&lt;/li&gt;
      &lt;li&gt;Distributed/Cloud computing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Text Retrieval and Search Engines&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Cluster Analysis in Data Mining&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Text Mining and Analytics&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Visualization&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Data Mining Capstone&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/data-mining/2015/04/11/courses-data-mining</link>
                <guid>http://zhou-dong.github.io/data-mining/2015/04/11/courses-data-mining</guid>
                <pubDate>2015-04-11T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Protein</title>
                <description>
&lt;p&gt;Protein Structure:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;一级结构：氨基酸的序列 &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;二级结构：由氨基酸序列构成的物理结构&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;三级结构：三维的folding结构&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;Protein Type:&lt;/p&gt;

&lt;p&gt;肉类蛋白，豆类蛋白，乳清蛋白，奶中的蛋白，和蔬菜蛋白之间的区别：&lt;/p&gt;

&lt;p&gt;动物蛋白和蔬菜蛋白之间的区别：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先人类的身体的可以制造出大部分自己所需要的蛋白质来。&lt;/li&gt;
  &lt;li&gt;但是有9种氨基酸人类制造不出来，必须从我们的食物中获取&lt;/li&gt;
  &lt;li&gt;大多数的动物蛋白质都包含人类所必须的9中氨基酸。&lt;/li&gt;
  &lt;li&gt;植物蛋白也可能包含我们所需要的蛋白质，但是含量可能不是很理想。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;肉蛋白：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一提到肉蛋白，大多数人可能会想到：牛肉。&lt;/li&gt;
  &lt;li&gt;牛肉蛋白里面包含人类所需的所有氨基酸&lt;/li&gt;
  &lt;li&gt;但是纯度其实不高，20%的牛肉重量是蛋白质&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;而且营养元素的含量也不高&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;3盎司的牛肉中大约包含：
    &lt;ul&gt;
      &lt;li&gt;23 克蛋白质&lt;/li&gt;
      &lt;li&gt;15 克脂肪&lt;/li&gt;
      &lt;li&gt;蛋白质净使用率73&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;家禽蛋白：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;人们一般觉得跟牛肉相比鸡肉包含较少的营养元素，事实上&lt;/li&gt;
  &lt;li&gt;3盎司的鸡肉瘦肉（不含皮肤）包含：
    &lt;ul&gt;
      &lt;li&gt;27 克蛋白质&lt;/li&gt;
      &lt;li&gt;2-3克脂肪&lt;/li&gt;
      &lt;li&gt;蛋白质净使用率80&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;鱼肉脂肪：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;鱼肉里面包含大量的蛋白质，关键的是里面没有碳水化合物，而且只有少量脂肪&lt;/li&gt;
  &lt;li&gt;它的脂肪里面包含大量对人类有益的Omega-3 fatty acids（omega-3饱和脂肪酸）&lt;/li&gt;
  &lt;li&gt;3盎司鱼肉中：
    &lt;ul&gt;
      &lt;li&gt;蛋白质净使用率81&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;猪肉蛋白：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果不是来自第三世界国家，吃垃圾长大的猪，猪肉的质量还是可以保证对人类无害的&lt;/li&gt;
  &lt;li&gt;现在证明：
    &lt;ul&gt;
      &lt;li&gt;猪肉和牛肉、鸡肉一样健康&lt;/li&gt;
      &lt;li&gt;猪肉相对牛肉其实更容易消化&lt;/li&gt;
      &lt;li&gt;猪肉含有相对较高的脂肪&lt;/li&gt;
      &lt;li&gt;全美的猪肉质量是有保证的&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;奶蛋白：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;很多人对奶蛋白过敏&lt;/li&gt;
  &lt;li&gt;蛋白质净使用率81&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;乳清蛋白:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当前最好的蛋白质来源&lt;/li&gt;
  &lt;li&gt;蛋白质的使用率90-100&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;鸡蛋：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In fact, the whole biological value scale is based on egg protein ranking a benchmark 100&lt;/li&gt;
  &lt;li&gt;鸡蛋蛋白是最容易引起过敏的。&lt;/li&gt;
  &lt;li&gt;吃整鸡蛋比光是蛋白含有更多的营养。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;豆类蛋白质：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;豆类其实不是一个有效的蛋白质的来源。&lt;/li&gt;
  &lt;li&gt;豆类中包含很多过敏的元素，而且都会有抑制矿物质元素的吸收。&lt;/li&gt;
  &lt;li&gt;蛋白质的包含量：70-70&lt;/li&gt;
  &lt;li&gt;蛋白质的净利用率只有61&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;谷物&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;虽有谷物和豆类包含了人类所需的蛋白质。但是氨基酸的包含比例是不平衡的。&lt;/li&gt;
  &lt;li&gt;所以食用纯素的时候，可能需要根据蛋白质的含量不同，食用不同比例的食物&lt;/li&gt;
  &lt;li&gt;所以如果纯食素的话，对运动员、减肥的人、病人是不好的。&lt;/li&gt;
  &lt;li&gt;如果需要健身的话，需要高纯度的蛋白质的，而且需要合理的氨基酸比例&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;resource from: http://www.nutribodyprotein.com/protein-types.php&lt;/p&gt;

</description>
                <link>http://zhou-dong.github.io/protein/2015/03/28/protein-type</link>
                <guid>http://zhou-dong.github.io/protein/2015/03/28/protein-type</guid>
                <pubDate>2015-03-28T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Intro of Bioinformatics</title>
                <description>
&lt;p&gt;bioinformatics about：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;gene：基因&lt;/li&gt;
  &lt;li&gt;genome：基因组&lt;/li&gt;
  &lt;li&gt;protein：蛋白质&lt;/li&gt;
  &lt;li&gt;cell：细胞&lt;/li&gt;
  &lt;li&gt;amino acid：氨基酸&lt;/li&gt;
  &lt;li&gt;nucleotide：核酸&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;bioinformatics aim：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;预测&lt;/li&gt;
  &lt;li&gt;建模&lt;/li&gt;
  &lt;li&gt;设计&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;database：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;primary database: DNA and “amino acid” sequence&lt;/li&gt;
  &lt;li&gt;secondary database: fingerprint, profile, block&lt;/li&gt;
  &lt;li&gt;teriary database: domains, folding&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;sequence alignment:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Identify very short exact matches&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Dynamic Programming&lt;/li&gt;
  &lt;li&gt;HMM&lt;/li&gt;
  &lt;li&gt;FASTA&lt;/li&gt;
  &lt;li&gt;BLAST&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Website: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;www.expasy.org&lt;/li&gt;
  &lt;li&gt;ncbi&lt;/li&gt;
  &lt;li&gt;biopython&lt;/li&gt;
&lt;/ul&gt;

</description>
                <link>http://zhou-dong.github.io/bioinformatics/2015/03/27/intro</link>
                <guid>http://zhou-dong.github.io/bioinformatics/2015/03/27/intro</guid>
                <pubDate>2015-03-27T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>FASTA AND BLAST</title>
                <description>
&lt;p&gt;Pairwise alignment&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Global
    &lt;ul&gt;
      &lt;li&gt;Best score from among alignments of full-length sequences&lt;/li&gt;
      &lt;li&gt;Needelman-Wunch algorithm&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Local
    &lt;ul&gt;
      &lt;li&gt;Best score form among alignments of partial sequences&lt;/li&gt;
      &lt;li&gt;Smith-Waterman algorithm&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;FASTA: First fast sequence search algorithm for comparing query sequency against a database&lt;/p&gt;

&lt;p&gt;BLAST: Basic Locial Alignment Search Technique, improvement of FASTA: search speed, ease of use, statistics rigor.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;FASTA and BLAST&lt;/p&gt;

&lt;p&gt;Dynamic programming&lt;/p&gt;

&lt;p&gt;Basic idea: short lengths of exact matches:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First: identify very short exact matches&lt;/li&gt;
  &lt;li&gt;Next: the best short hits from the first step are extended to longer regions of similarity&lt;/li&gt;
  &lt;li&gt;Finally: the best hits are optimized&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;FASTA Algorithm:&lt;/p&gt;

&lt;p&gt;Derived from logic of dot plot&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;computer best diagonals from all frames of alignment&lt;/li&gt;
  &lt;li&gt;the method look for exact matches between words in query and test sequence
    &lt;ul&gt;
      &lt;li&gt;DNA sequence are usually 6 nucleotides long&lt;/li&gt;
      &lt;li&gt;protein words are 2 amino acids long&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Five steps of FASTA:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;idenfity common k-words between I and J （把query和Test同时放在一个matrix中）&lt;/li&gt;
  &lt;li&gt;score diagonals with k-word matches, identify 10 best diagonals （在matrix中，标记处横坐标和纵坐标相同的点，然后连城线段）&lt;/li&gt;
  &lt;li&gt;recore initial regions with a substitution of matrix (把一些较短的线段的分值调低)&lt;/li&gt;
  &lt;li&gt;join inital regions with gaps, penalise for gaps&lt;/li&gt;
  &lt;li&gt;perform dynamic programming to find final alignments&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;BLAST Algorithm&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;BLAST can not handle gaps well&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Three steps of BLAST:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;word search method
    &lt;ul&gt;
      &lt;li&gt;find the list of high scoring words of length w&lt;/li&gt;
      &lt;li&gt;compare the word list to database and identify exact matches&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;identification of exact word method
    &lt;ul&gt;
      &lt;li&gt;break the query into words&lt;/li&gt;
      &lt;li&gt;break the database sequences into words&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;maximum segment pair alignment method
    &lt;ul&gt;
      &lt;li&gt;extend hits one base at a time&lt;/li&gt;
      &lt;li&gt;scroing of alignment&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The result of word matching and attemps to extend the alignment are segments called HSPs:
- high scoring segmeng pair&lt;/p&gt;

&lt;p&gt;BLAST ofter product sereral short HSPs&lt;/p&gt;

&lt;p&gt;WEBSITE: www.expasy.org&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/fasta/blast/bioinformatics/2015/03/26/fasta-blast</link>
                <guid>http://zhou-dong.github.io/fasta/blast/bioinformatics/2015/03/26/fasta-blast</guid>
                <pubDate>2015-03-26T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Bioinformatics</title>
                <description>
&lt;p&gt;Analysis of: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;gene&lt;/li&gt;
  &lt;li&gt;genome&lt;/li&gt;
  &lt;li&gt;protein&lt;/li&gt;
  &lt;li&gt;cell&lt;/li&gt;
  &lt;li&gt;ecological system&lt;/li&gt;
  &lt;li&gt;medical information&lt;/li&gt;
  &lt;li&gt;robots&lt;/li&gt;
  &lt;li&gt;artifical intelligence&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Use the knowledge for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;prediction&lt;/li&gt;
  &lt;li&gt;modelling&lt;/li&gt;
  &lt;li&gt;design&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;amino acid: 氨基酸&lt;/p&gt;

&lt;p&gt;data type：&lt;/p&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;primary data&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;sequence&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;–&amp;gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;primary database&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;AATGCGTAAGTC&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;DNA&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;DMPVERILEALAVE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;amino acid&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;secondary data&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;secondary protein structure&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;–&amp;gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;secondary db&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;“motif”&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e.g.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;regular expressions&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e.g.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;block&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e.g.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;profiles&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e.g.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;fingerprints&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e.g.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;teriary data&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;teriary protein structure&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;–&amp;gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;teriary db&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;atomic co-ordinates&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;domains, folding units&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;p&gt;databases:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Nucleotide: 核酸
    &lt;ul&gt;
      &lt;li&gt;primary db&lt;/li&gt;
      &lt;li&gt;secondary db&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;tritiary db&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;EMBL [The European Molecular Boilogy Laboratory] Germany&lt;/li&gt;
      &lt;li&gt;GenBank &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;DDBJ [DNA data bank of Janpan]&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;All together is under INSDC [International Nucleotide Sequence Databases] &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;protein
    &lt;ul&gt;
      &lt;li&gt;sequence
        &lt;ul&gt;
          &lt;li&gt;Uniprot&lt;/li&gt;
          &lt;li&gt;PIR&lt;/li&gt;
          &lt;li&gt;SwissProt&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;interaction
        &lt;ul&gt;
          &lt;li&gt;Biogrid&lt;/li&gt;
          &lt;li&gt;STRING&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;structure
        &lt;ul&gt;
          &lt;li&gt;PDB&lt;/li&gt;
          &lt;li&gt;CATH&lt;/li&gt;
          &lt;li&gt;SCOPE&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;INSDC [International Nucleotide Sequence Databases]
    &lt;ul&gt;
      &lt;li&gt;EMBL (EUROPE)
        &lt;ul&gt;
          &lt;li&gt;EMBL&lt;/li&gt;
          &lt;li&gt;EBI&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;DDBJ (JAPAN)
        &lt;ul&gt;
          &lt;li&gt;NIG&lt;/li&gt;
          &lt;li&gt;CIB&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;GenBank (USA)
        &lt;ul&gt;
          &lt;li&gt;NLM&lt;/li&gt;
          &lt;li&gt;NCBI&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;sequence alignment&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;2&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;3&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;4&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;5&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;6&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;A&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;C&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;G&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&amp;gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Sequence one&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;C&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;A&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&amp;gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Sequcece two&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;GAP&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MISMATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;we wanna use that way to get maximum match&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;2&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;3&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;4&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;5&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;6&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;A&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;C&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;G&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&amp;gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Sequence one&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;C&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;A&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-&amp;gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Sequcece two&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MISMATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MISMATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MISMATCH&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;GAP&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;p&gt;Score for sequcen alignment&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Match &lt;strong&gt;positive&lt;/strong&gt; score&lt;/li&gt;
  &lt;li&gt;Mismatch &lt;strong&gt;negtive&lt;/strong&gt; score&lt;/li&gt;
  &lt;li&gt;Gap &lt;strong&gt;negtive&lt;/strong&gt; score&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Align sequence must be more than one sequence&lt;/p&gt;

&lt;p&gt;Align sequence is basic of the bioinformatics&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/bioinformatics/2015/03/26/bioinformatics</link>
                <guid>http://zhou-dong.github.io/bioinformatics/2015/03/26/bioinformatics</guid>
                <pubDate>2015-03-26T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Radial Basis Function Network</title>
                <description>&lt;p&gt;Radial Basis Function Network&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;radial: only depends on distance between x and ‘center’ x_n&lt;/li&gt;
  &lt;li&gt;basis function: to be ‘combined’&lt;/li&gt;
  &lt;li&gt;跟半径有关的预测方式&lt;/li&gt;
  &lt;li&gt;其实中心店就是support vectors&lt;/li&gt;
  &lt;li&gt;找到那些中心点，和中心店的系数&lt;/li&gt;
  &lt;li&gt;可是利用kernel&lt;/li&gt;
  &lt;li&gt;Near neighbor&lt;/li&gt;
  &lt;li&gt;k-means algorithm: partition optimization&lt;/li&gt;
  &lt;li&gt;RBF using k-means&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;K-Means&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;无监督的学习&lt;/li&gt;
  &lt;li&gt;分类算法&lt;/li&gt;
  &lt;li&gt;先找定好要分成几个点，然后逐步优化接近&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;先用k-means找出代表，然后再继续使用rbf&lt;/p&gt;

&lt;p&gt;可以把高纬度的数据放到低纬度的空间来做运算&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;压缩方法转换&lt;/li&gt;
  &lt;li&gt;投影的方法转换&lt;/li&gt;
  &lt;li&gt;也可以通过其他的方法来降维&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最基本的最佳化的方法是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;梯度下降 gradient descent&lt;/li&gt;
  &lt;li&gt;牛顿法下降&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Equivalent Solution&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SVM的对偶问题&lt;/li&gt;
  &lt;li&gt;kernel logistic regression&lt;/li&gt;
  &lt;li&gt;PCA&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Multiple Steps&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;probabilistic SVM &lt;/li&gt;
  &lt;li&gt;linear blending&lt;/li&gt;
  &lt;li&gt;stacking&lt;/li&gt;
  &lt;li&gt;RBF network&lt;/li&gt;
  &lt;li&gt;deep learning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Alternating optimization&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;k-means&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Divide and conquer&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;decision tree&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;overfitting elimination via regularization&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;large-margin
    &lt;ul&gt;
      &lt;li&gt;svm&lt;/li&gt;
      &lt;li&gt;adaboost&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;L2 regularization
    &lt;ul&gt;
      &lt;li&gt;SVR&lt;/li&gt;
      &lt;li&gt;kernel models&lt;/li&gt;
      &lt;li&gt;nnet&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;voting/averaging
    &lt;ul&gt;
      &lt;li&gt;uniform blending&lt;/li&gt;
      &lt;li&gt;bagging&lt;/li&gt;
      &lt;li&gt;random forest&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;denosing
    &lt;ul&gt;
      &lt;li&gt;autoencoder&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;weight-elimination
    &lt;ul&gt;
      &lt;li&gt;NNET&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;pruning
    &lt;ul&gt;
      &lt;li&gt;decision tree&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;early stopping
    &lt;ul&gt;
      &lt;li&gt;RBF&lt;/li&gt;
      &lt;li&gt;auto encoder&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;constraining&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/rbf/2015/03/20/rbf</link>
                <guid>http://zhou-dong.github.io/rbf/2015/03/20/rbf</guid>
                <pubDate>2015-03-20T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Neural Netword & Deep Learning</title>
                <description>&lt;p&gt;Neural Netword&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一层一层的做运算，一层的输出作为另一层的输入，层层递进。&lt;/li&gt;
  &lt;li&gt;每一层可以用以前学的方法来执行。&lt;/li&gt;
  &lt;li&gt;经过多层的运算，我们希望我们得到的结果是好的。&lt;/li&gt;
  &lt;li&gt;可以用gradient descent来实现，来一步一步的做最佳化&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;其实gradient descent就是做偏微分。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;因为经过了多次的转化 ，所以可能得不到最优解。&lt;/li&gt;
  &lt;li&gt;可能得到的是局部最优解，而不是全局最优解，所以需要
    &lt;ul&gt;
      &lt;li&gt;选好梯度下降的起始点&lt;/li&gt;
      &lt;li&gt;选好梯度下降的步伐&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;同时要防止overfitting
    &lt;ul&gt;
      &lt;li&gt;需要regularization for neural network&lt;/li&gt;
      &lt;li&gt;Early Stopping，在某个中间点就停下来。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Deep Learning&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Deep neural network
    &lt;ul&gt;
      &lt;li&gt;每一层找出不同的内容，即每层做一点点的东西&lt;/li&gt;
      &lt;li&gt;多层之间的结果合并&lt;/li&gt;
      &lt;li&gt;给出结果&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;通过每层来做一些简单的东西，然后多层合并，最终可以做复杂的运算&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;difficult structure decisions: 
        &lt;ul&gt;
          &lt;li&gt;解决方法之一是加上人对某个领域的理解&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;high model complexity: 
        &lt;ol&gt;
          &lt;li&gt;no big worries if big enough data&lt;/li&gt;
          &lt;li&gt;regularization towards noise-tolerant,like dropout, denoising&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;hard optimization
        &lt;ul&gt;
          &lt;li&gt;careful initialization to avoid bad local minimun called pre-training&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;huge computational complexity
        &lt;ul&gt;
          &lt;li&gt;novel hardware/architecture: like mini-batch with GPU&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Autoencoder
    &lt;ul&gt;
      &lt;li&gt;information-preserving encoding&lt;/li&gt;
      &lt;li&gt;usefulness of approximating identity function&lt;/li&gt;
      &lt;li&gt;首先先查找每一层之间维度的抽取&lt;/li&gt;
      &lt;li&gt;然后在一层给维度编码&lt;/li&gt;
      &lt;li&gt;在另一层给相同维度解码&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Denoising Autoencoder
    &lt;ul&gt;
      &lt;li&gt;this is one of regularization&lt;/li&gt;
      &lt;li&gt;加上一些条件使得每一层之间的连接没有那么多&lt;/li&gt;
      &lt;li&gt;可能Early stopping的效果更好&lt;/li&gt;
      &lt;li&gt;杂絮越多，资料越少，越容易overfitting
        &lt;ol&gt;
          &lt;li&gt;直接的想法是，想办法删除杂絮&lt;/li&gt;
          &lt;li&gt;另外特殊的想法是，把杂絮加到资料中&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;我们的目标是创建强壮的程序&lt;/li&gt;
      &lt;li&gt;即使是资料中有杂絮，也能有好的输出&lt;/li&gt;
      &lt;li&gt;所以我们可以输入有杂絮的资料，然后返回干净的资料&lt;/li&gt;
      &lt;li&gt;所以我们可以把干净的资料变为干净的资料&lt;/li&gt;
      &lt;li&gt;而且我们更可以把不干净的资料变为干净的资料&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;principal Component Analyze&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/machine/learning/neural/deep/2015/03/20/neural-network</link>
                <guid>http://zhou-dong.github.io/machine/learning/neural/deep/2015/03/20/neural-network</guid>
                <pubDate>2015-03-20T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Decision Tree and Random Forest</title>
                <description>&lt;p&gt;Decision Tree&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先要考虑tree停下来的条件&lt;/li&gt;
  &lt;li&gt;可以用binary tree&lt;/li&gt;
  &lt;li&gt;Build subtree&lt;/li&gt;
  &lt;li&gt;final return&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;C &amp;amp; RT 算法&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;避免overfitting&lt;/li&gt;
  &lt;li&gt;Regularization by Pruning&lt;/li&gt;
  &lt;li&gt;E in 要低，而且叶子节点也不要太多&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以pruning（修剪）decision tree&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;比adaboost要有效率一些&lt;/li&gt;
  &lt;li&gt;adaboost每次都是全部切分&lt;/li&gt;
  &lt;li&gt;C &amp;amp; RT在局部切分，会更有效率一些&lt;/li&gt;
  &lt;li&gt;adaboost和decision tree的切分结果可能会不同&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Random Forest&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bagging + Decision Tree&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Bagging first, then Decision Tree&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;先对资料随机抽样，比如可以从很多个特征中，抽取一定的特征做成一棵树&lt;/li&gt;
  &lt;li&gt;通过上面，可以变成一个低纬度的subspace处理&lt;/li&gt;
  &lt;li&gt;希望做成不一样的tree，然后再把他们合起来&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;找到low-dimensional的投影平面&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;out of bag estimate&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以用这些没有被使用的维度来判断结果好不好&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Feature Selection：怎么选择适当的特征，或者适当的输入&lt;/li&gt;
  &lt;li&gt;从多个维度中更有效的选取资料
    &lt;ul&gt;
      &lt;li&gt;如，年龄和生日这两个资料重复了&lt;/li&gt;
      &lt;li&gt;还有有些资料在我们的算法中是不需要的&lt;/li&gt;
      &lt;li&gt;通过算法自动降维，或者自动转换&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;可以降低计算复杂度&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;可以更好得避免overfitting&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;选择本身是有计算复杂度的&lt;/li&gt;
  &lt;li&gt;可能会选到不好的维度，而删除了好的维度&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果维度选择错误的话，可能会更加的overfitting&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;相当于是一个组合爆炸的问题&lt;/li&gt;
  &lt;li&gt;可以给每个维度打一个分数，然后找出里面分值最高的维度&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;permutation test&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;比decision tree的效果要平滑很多&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Gradient Boosted Decision Tree&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;adaboost + Decision Tree&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/machine/learning/decision/tree/random/forest/2015/03/20/forest</link>
                <guid>http://zhou-dong.github.io/machine/learning/decision/tree/random/forest/2015/03/20/forest</guid>
                <pubDate>2015-03-20T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Regression</title>
                <description>&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;kernel Logistic Regression&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Support Vector Regression&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Kernel Ridge Regression: 利用kernel regression代替linear regression&lt;/li&gt;
      &lt;li&gt;Support Vector Regression Primal&lt;/li&gt;
      &lt;li&gt;即使是分割曲线相同，但是支撑点的个数可能不同，所以最后预测的复杂度也不同。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
                <link>http://zhou-dong.github.io/machine/learning/regression/2015/03/19/regression</link>
                <guid>http://zhou-dong.github.io/machine/learning/regression/2015/03/19/regression</guid>
                <pubDate>2015-03-19T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Aggregation</title>
                <description>&lt;p&gt;Aggregation&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;融合各种方法在一起来提高分类效果。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Blending：混合各种方法在一起. 各个算法的参数求均值。&lt;/p&gt;

&lt;p&gt;Linear blending：把各个算法的结果做线性组合。
    - LinMod + hypothesees as transform + constrains&lt;/p&gt;

&lt;p&gt;Bagging：边学习，边blending&lt;/p&gt;

&lt;p&gt;Adaptive Boosting&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;逐步增强，逐步添加限制条件。&lt;/li&gt;
  &lt;li&gt;可以通过增强或者惩罚来达到。&lt;/li&gt;
  &lt;li&gt;可以在犯过错的地方强调一下。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Diversity By Re-weighting&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;根据不同的部分给不同的weight&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Adaptive Boosting Algorithm&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一刀一刀的切，放大错误的，缩小正确的，逐渐优化分类器&lt;/li&gt;
  &lt;li&gt;scaling factor&lt;/li&gt;
  &lt;li&gt;放大错误的&lt;/li&gt;
  &lt;li&gt;缩小正确的&lt;/li&gt;
  &lt;li&gt;做成功的应用是人脸识别&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/machine/learning/aggregation/adaboost/2015/03/19/aggregation</link>
                <guid>http://zhou-dong.github.io/machine/learning/aggregation/adaboost/2015/03/19/aggregation</guid>
                <pubDate>2015-03-19T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Machine Learning Techniques Course Design</title>
                <description>&lt;p&gt;Three major techniques surrouding &lt;code&gt;feature transforms&lt;/code&gt;（特征转换）:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Support Vector Machine (SVM) model (支撑向量机)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Adaptive Boosting (AdaBoost) model（逐步增强法）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Deep Learning model（深度学习）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
                <link>http://zhou-dong.github.io/machine/learning/svm/2015/03/18/course-design</link>
                <guid>http://zhou-dong.github.io/machine/learning/svm/2015/03/18/course-design</guid>
                <pubDate>2015-03-18T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Support Vector Machine</title>
                <description>&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Linear Support Vector Machine&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;why use linear support vector machine:
        &lt;ul&gt;
          &lt;li&gt;PLA depending on randomness&lt;/li&gt;
          &lt;li&gt;tolerate more noise&lt;/li&gt;
          &lt;li&gt;more robust to overfitting&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;how to implement
        &lt;ol&gt;
          &lt;li&gt;w classifiles every (&lt;script type=&quot;math/tex&quot;&gt;x_n, y_n&lt;/script&gt;) correctly&lt;/li&gt;
          &lt;li&gt;fatness(w) = min distance(&lt;script type=&quot;math/tex&quot;&gt;x_n, w&lt;/script&gt;)&lt;/li&gt;
          &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;v_1x_1 + v_2x_2 = 0&lt;/script&gt;.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;method:
        &lt;ul&gt;
          &lt;li&gt;求两点之间的中锤线&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;steps:
        &lt;ul&gt;
          &lt;li&gt;一个平面到一个点的距离&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dual Support Vector Machine&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;每个点，到平面的距离，就相当于求每个点在平面上的投影&lt;/li&gt;
      &lt;li&gt;而且需要考虑的是对偶问题&lt;/li&gt;
      &lt;li&gt;利用lagrange来约束计算的复杂度&lt;/li&gt;
      &lt;li&gt;转化为解对偶的问题&lt;/li&gt;
      &lt;li&gt;找出在边界上并且大于0的点，作为support vectors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kernel Support Vector Machine&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Kernel Trick: 简化计算的复杂度&lt;/li&gt;
      &lt;li&gt;Polynomial Kernel: 二次转化的优化&lt;/li&gt;
      &lt;li&gt;Gaussian Kernel: 在SVM上利用Gaussian kernel优化计算，泰勒展开是实现&lt;/li&gt;
      &lt;li&gt;Comparison of Kernels&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sofe-Margin Support Vector Machine&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Motivation and Primal Problem: 为了避免overfiting，允许有杂绪。&lt;/li&gt;
      &lt;li&gt;记录每个点，违反的程度，而不是记录违反点的个数。&lt;/li&gt;
      &lt;li&gt;Dual Problem: 就是是soft也有可能会有overfitting&lt;/li&gt;
      &lt;li&gt;多项式的分割会更灵活&lt;/li&gt;
      &lt;li&gt;Message behind Soft-Margin&lt;/li&gt;
      &lt;li&gt;Model Selection: 可以选高斯kernel，也可以用其他的kernel来修改参数的值&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
                <link>http://zhou-dong.github.io/machine/learning/svm/2015/03/18/SVM</link>
                <guid>http://zhou-dong.github.io/machine/learning/svm/2015/03/18/SVM</guid>
                <pubDate>2015-03-18T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Neumann Kernal</title>
                <description>
&lt;p&gt;Neumann Kernal&lt;/p&gt;

&lt;p&gt;NK: Diffusion Factor - Equation &amp;amp; Effect&lt;/p&gt;

&lt;p&gt;Neumann Kernel defines two matrices incorporating a diffusion factor:&lt;/p&gt;

&lt;p&gt;page 157&lt;/p&gt;

&lt;p&gt;HITS: is special case&lt;/p&gt;

&lt;p&gt;NK: is the generational&lt;/p&gt;

&lt;p&gt;Shared Nearest Neighbor(SNN) K-Nearest&lt;/p&gt;

&lt;p&gt;K 邻近&lt;/p&gt;

&lt;p&gt;邻近算法，或者说K最近邻(kNN，k-NearestNeighbor)分类算法是数据挖掘分类技术中最简单的方法之一。所谓K最近邻，就是k个最近的邻居的意思，说的是每个样本都可以用它最接近的k个邻居来代表。&lt;/p&gt;

&lt;p&gt;kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 kNN方法在类别决策时，只与极少量的相邻样本有关。由于kNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，kNN方法较其他方法更为适合。&lt;/p&gt;

</description>
                <link>http://zhou-dong.github.io/graphical/data/mining/2015/03/16/graphical-data-mining</link>
                <guid>http://zhou-dong.github.io/graphical/data/mining/2015/03/16/graphical-data-mining</guid>
                <pubDate>2015-03-16T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Achieved Courses</title>
                <description>
&lt;p&gt;Create an jekyll project:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize new jekyll project: 
    &lt;ul&gt;
      &lt;li&gt;jekyll new troy-cssa&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Start jekyll project: 
    &lt;ul&gt;
      &lt;li&gt;jekyll server&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Default address: 
    &lt;ul&gt;
      &lt;li&gt;http://localhost:4000/&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Intro to jekyll project&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;_config.yml&lt;/li&gt;
  &lt;li&gt;_layouts&lt;/li&gt;
  &lt;li&gt;_posts&lt;/li&gt;
  &lt;li&gt;_site
    &lt;ul&gt;
      &lt;li&gt;jekyll will generate files into this folder&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;css&lt;/li&gt;
  &lt;li&gt;index.html&lt;/li&gt;
&lt;/ul&gt;

</description>
                <link>http://zhou-dong.github.io/2015/03/13/jekyll-steps</link>
                <guid>http://zhou-dong.github.io/2015/03/13/jekyll-steps</guid>
                <pubDate>2015-03-13T00:00:00-05:00</pubDate>
        </item>

        <item>
                <title>Notes for people-to-people</title>
                <description>
&lt;h4 id=&quot;natural-language-processing&quot;&gt;Natural Language Processing:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Stop word(should we eliminate stop word)&lt;/li&gt;
  &lt;li&gt;Word Tokenization
    &lt;ul&gt;
      &lt;li&gt;用自然语言分析，最归一化，如data mining == data mine, Nosql = NOSQL, &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;weight-of-the-attributes&quot;&gt;Weight of The Attributes:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Company Name Have &lt;code&gt;negative&lt;/code&gt; Weight&lt;/li&gt;
  &lt;li&gt;Others have the &lt;code&gt;positive&lt;/code&gt; Weight&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;cold-start-problem&quot;&gt;Cold start Problem&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;If most of the key words have the TF of 0, our result will not go will.&lt;/li&gt;
  &lt;li&gt;Answer: We initialize all the words with small weight to smooth the data.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/2015/03/02/people-to-people</link>
                <guid>http://zhou-dong.github.io/2015/03/02/people-to-people</guid>
                <pubDate>2015-03-02T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Play with Galois Field</title>
                <description>
&lt;h4 id=&quot;decsciption&quot;&gt;Decsciption:&lt;/h4&gt;

&lt;p&gt;Galois Field 2: has just two element 0 and 1&lt;/p&gt;

&lt;p&gt;Addition is like exclusive-or:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
 
    \begin{array}{c | c c } + &amp; 0 &amp; 1 \\
        \hline 
        0 &amp; 0 &amp; 1 \\
        1 &amp; 1 &amp; 0 \\
    \end{array}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Multiplication is like ordinary mutipication:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
 
    \begin{array}{c | c c } \times &amp; 0 &amp; 1 \\
        \hline 
        0 &amp; 0 &amp; 0 \\
        1 &amp; 0 &amp; 1 \\
    \end{array}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;And: &lt;script type=&quot;math/tex&quot;&gt; a \cdot (b + c) = a \cdot b + a \cdot c &lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;application&quot;&gt;Application:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Encription&lt;/li&gt;
  &lt;li&gt;Network coding&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/matrix/python/2015/03/01/galois-field</link>
                <guid>http://zhou-dong.github.io/matrix/python/2015/03/01/galois-field</guid>
                <pubDate>2015-03-01T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>CS-5549 Midterm Review</title>
                <description>
&lt;h2 id=&quot;sorting-method&quot;&gt;Sorting Method&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Sort Name&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Description&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Best Case&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Worst Case&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Average Case&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BubbleSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;比较相邻的元素，第一个比第二个大就交换位置。对每个元素重复上一个步骤&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;SelectionSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;每次查找剩下元素中最小的元素，然后放在已经排序好的前面序列的最后一位&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;InsertionSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;将当前元素插入到比它大的元素前,现实中比Bubble Sort，Selection Sort更有效&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;GnomeSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;比较相邻元素如果第2个比第1个小替换位置并继续与前面的元素比较直到遇到比它大的。对每个元素重复上一个步骤&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;ShellSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;比较第i个和第i+n/2个元素，并继续与前i+n/2个元素比较，重复前面步骤&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Depends on Gap Sequence&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;QuickSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1.找出pivot 2.从数组两边找出比pivot大和小的替换位置，直到大、小元素相遇确定pivot位置，循环上面的步骤&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^2)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;MergeSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;一半元素之间进行比较，然后合并。递归调用&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;HeapSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;先建立一棵树，然后依次从数种取出root，heapify tree，再取出root直到数为空&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n\lg_{n})&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;BucketSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;以最大数初始化空数组，然后循环要排序的数组，把下标为元素的值设置为1，打印初始数组&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;CountingSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Bucketsort的优化版，先bucketsort，然后查看每个元素前面有多少个元素比它小，然后排序&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta(n+k)&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;RadixSort&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;一次从最后一位数取模，然后放在bucket中，然后再除以10取模，重复前面步骤&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(N)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;O(kN)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;— — —&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;conclusion&quot;&gt;Conclusion:&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Heapsort、Mergesort会占用额外的空间。&lt;/li&gt;
  &lt;li&gt;Bucketsort、Countingsort、Radixsort要占用额外的空间，尤其是bucketsort和countingsort，占用空间不可控。而且对小数和分数很难支持。&lt;/li&gt;
  &lt;li&gt;一般排序的时候，使用的还是comparison，因为它对小数和分数有很好的支持，而且它的空间负责度也低。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;medians-and-order-statistics&quot;&gt;Medians and Order Statistics&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;同时找出最大值和最小值，有两种方法：
    &lt;ol&gt;
      &lt;li&gt;循环整个数组，一个元素与最大值比较一次，与最小值比较一次。&lt;/li&gt;
      &lt;li&gt;先比较两个元素，然后小的与最小值比较，大的与最大值比较。这样每两个数比较3次。
        &lt;ul&gt;
          &lt;li&gt;奇数个元素，从第2个元素开始循环&lt;/li&gt;
          &lt;li&gt;偶数个元素，从第3个元素开始循环&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Randomized Selection
    &lt;ol&gt;
      &lt;li&gt;与Quicksort相似，先找pivot，然后进行一轮排序&lt;/li&gt;
      &lt;li&gt;比较pivot是否在要查找的元素的位置：
        &lt;ul&gt;
          &lt;li&gt;如果是返回pivot&lt;/li&gt;
          &lt;li&gt;如果pivot的位置比要找元素的位置靠前，在后半个数组使用&lt;code&gt;Quicksort&lt;/code&gt;查找&lt;/li&gt;
          &lt;li&gt;如果pivot的位置比要找元素的位置靠后，在前半个数组使用&lt;code&gt;Quicksort&lt;/code&gt;查找&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Mideum of Mideum
    &lt;ul&gt;
      &lt;li&gt;作用：为了优化Quicksort和Randomized-Selection，我们需要找到中位数来做pivot&lt;/li&gt;
      &lt;li&gt;步骤：
        &lt;ol&gt;
          &lt;li&gt;把数组分成最小5份&lt;/li&gt;
          &lt;li&gt;在每份使用Insertion sort找出中位数&lt;/li&gt;
          &lt;li&gt;在这五份中位数中找出中位数&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;做为quicksort的中位数&lt;/li&gt;
      &lt;li&gt;Worst Case：
        &lt;ol&gt;
          &lt;li&gt;5份数据的第一份里面找出的是最小的20% = n/5,中位数等于 n/5/2 = 10%&lt;/li&gt;
          &lt;li&gt;在5份数据中的中位数，最少有多少个数小于中位数：3 * 10% = 30%&lt;/li&gt;
          &lt;li&gt;For large n, 3[n/10] &lt;script type=&quot;math/tex&quot;&gt;\le&lt;/script&gt; n/4&lt;/li&gt;
          &lt;li&gt;So at least n/4 elements &lt;script type=&quot;math/tex&quot;&gt;\le&lt;/script&gt; x&lt;/li&gt;
          &lt;li&gt;Similarly: at least n/4 elements &lt;script type=&quot;math/tex&quot;&gt;\ge&lt;/script&gt; x&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;recursion&quot;&gt;Recursion&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Telescoping&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt; T(n) = aT(n/b) + f(n) &lt;/script&gt;&lt;/p&gt;

    &lt;p&gt;Example: Let: &lt;script type=&quot;math/tex&quot;&gt; a=2, \ b=2, \ f(n) = 1 &lt;/script&gt;&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th style=&quot;text-align: center&quot;&gt;Step&lt;/th&gt;
          &lt;th style=&quot;text-align: left&quot;&gt;Function One&lt;/th&gt;
          &lt;th style=&quot;text-align: center&quot;&gt;Equal&lt;/th&gt;
          &lt;th&gt;Functin Two&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 2T(n/2) + 1 &lt;/script&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
          &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^1T(n/2^1) + 1 &lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 4T(n/4) + 1 + 1 &lt;/script&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
          &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^2T(n/2^2) + 2 &lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 8T(n/8) + 1 + 1 + 1 &lt;/script&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
          &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^3T(n/2^3) + 3 &lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = \ \ \ \ \ \ \  \vdots &lt;/script&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
          &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \ \ \ \ \ \ \  \vdots &lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
          &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = nT(n/n) + \log_{2} n &lt;/script&gt;&lt;/td&gt;
          &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
          &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\log_{2}n}T(n/2^{\log_{2}n}) + \log_{2} n &lt;/script&gt;&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;p&gt;Step1 + Step2 + &lt;script type=&quot;math/tex&quot;&gt; \cdots &lt;/script&gt; + Step5 :
  &lt;script type=&quot;math/tex&quot;&gt; T(n) = nT(1)  + \sum_{i=0}^{\log_{2}n} i \le n\log_2 n = n \lg_n&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Master Theorem&lt;/strong&gt; &lt;/p&gt;

    &lt;p&gt;Let a &lt;script type=&quot;math/tex&quot;&gt; \ge &lt;/script&gt; 1 and b &amp;gt; 1 be constants, let f(n) be a function. &lt;code&gt;T(n) = aT(n/b) + f(n)&lt;/code&gt; ;&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = O(n^{\log_{b} a - \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a })&lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Theta(n^{\log_{b} a}) &lt;/script&gt; then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a} \lg n) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Omega(n^{\log_{b} a + \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &lt;/script&gt; &amp;gt; 0 , and if &lt;script type=&quot;math/tex&quot;&gt; af(n/b) \le cf(n)&lt;/script&gt; for some constant c &amp;lt; 1 and all sufficiently large n, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(f(n))&lt;/script&gt;.&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;Examples: &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  2T(n/2) + n^4 &lt;/script&gt;&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; a = 2, \ b = 2, \ f(n) = n^4 &lt;/script&gt; ,&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\log_{b} a} = n^{\log_{2} 2} = n^1 &lt;/script&gt; ,&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; f(n) = n^4 = \Omega(n^{\log_{b}a + \epsilon})  = \Omega(n^{1 + 3}) &lt;/script&gt; ,&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \epsilon = 3  &lt;/script&gt; ,&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \therefore \  T(n) = \Theta(n^4) &lt;/script&gt; .&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;datastructure&quot;&gt;Datastructure&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Binary Tree
    &lt;ul&gt;
      &lt;li&gt;one root&lt;/li&gt;
      &lt;li&gt;every node has no parent&lt;/li&gt;
      &lt;li&gt;every node can have at most two children&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Complete Binary Tree
    &lt;ul&gt;
      &lt;li&gt;Is Binary Tree&lt;/li&gt;
      &lt;li&gt;In every level, except possibly the last, is completely filled&lt;/li&gt;
      &lt;li&gt;Basic for HeapSort&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Binary Search Tree
    &lt;ul&gt;
      &lt;li&gt;Is Binary Tree&lt;/li&gt;
      &lt;li&gt;Left child is small&lt;/li&gt;
      &lt;li&gt;Right child is bigger&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Avl Tree
    &lt;ul&gt;
      &lt;li&gt;Is Binary Search Tree&lt;/li&gt;
      &lt;li&gt;Balanced Tree&lt;/li&gt;
      &lt;li&gt;left child level is less than or eq 1 to right level&lt;/li&gt;
      &lt;li&gt;compore to Red Black Tree more balanced&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Red Black Tree
    &lt;ul&gt;
      &lt;li&gt;Is Binary Search Tree&lt;/li&gt;
      &lt;li&gt;Balanced Tree&lt;/li&gt;
      &lt;li&gt;Use 5 rules to make sure tree is Balanced&lt;/li&gt;
      &lt;li&gt;Popular in memory, compare to Avl Tree has less rotations&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;B Tree
    &lt;ul&gt;
      &lt;li&gt;Not Binary Tree&lt;/li&gt;
      &lt;li&gt;One node has more than two children&lt;/li&gt;
      &lt;li&gt;Self balanced tree&lt;/li&gt;
      &lt;li&gt;Popular in databases&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;B Plus Tree
    &lt;ul&gt;
      &lt;li&gt;Enhanced B Tree&lt;/li&gt;
      &lt;li&gt;All value instored in leafs&lt;/li&gt;
      &lt;li&gt;Leaf connected to next and above&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;big-o-notation&quot;&gt;Big O Notation&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; O &lt;/script&gt; : Less than (Worst Situation)&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; o &lt;/script&gt; : Less or Equal&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \Omega &lt;/script&gt; : Bigger than (Best Situation)&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \omega &lt;/script&gt; : Big or Equal&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta &lt;/script&gt; : Between { &lt;script type=&quot;math/tex&quot;&gt; O,\ \ \Omega &lt;/script&gt; }&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dynamic-programming&quot;&gt;Dynamic Programming&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;What situation we will use dynamic Programming
    &lt;ol&gt;
      &lt;li&gt;Can be divided into small parts&lt;/li&gt;
      &lt;li&gt;Small parts have &lt;code&gt;Optimal Structure&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;Prove or&lt;/li&gt;
          &lt;li&gt;Persuade Or Convince&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Equation&lt;/li&gt;
      &lt;li&gt;Build Table&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Longest common subsequence
    &lt;ul&gt;
      &lt;li&gt;Two Rules:
        &lt;ol&gt;
          &lt;li&gt;If same, shoulder += 1&lt;/li&gt;
          &lt;li&gt;If not same, choose bigger one from both sides&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;Create Table:
  &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

  X = {B A D C B A B} \\
  Y = {A C D B C A} \\
  \begin{array}{|c|c|c|c|c|c|c|}
  \hline
  0 &amp;x_i &amp; B &amp; A &amp; D &amp; C &amp; B &amp; A &amp; B \\
  \hline
  y_i&amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
  \hline
  A  &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
  \hline
  C  &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 \\
  \hline
  D  &amp; 0 &amp; 0 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 \\
  \hline
  B  &amp; 0 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 3 \\
  \hline
  C  &amp; 0 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 \\
  \hline
  A  &amp; 0 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 4 &amp; 4 \\
  \hline
  \end{array}
   %]]&gt;&lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;Decode:
        &lt;ul&gt;
          &lt;li&gt;A D C A&lt;/li&gt;
          &lt;li&gt;A D B A&lt;/li&gt;
          &lt;li&gt;A C B A&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Matrix-chain multiplication
    &lt;ul&gt;
      &lt;li&gt;i must less than j&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_1 = (30 \times 35) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_2 = (35 \times 15) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_3 = (15 \times 5) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_4 = (5 \times 10) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_5 = (10 \times 20) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A_6 = (20 \times 25) &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;Tables:
  &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

  \begin{array}{|c|c|c|c|c|c|c|}
   \hline
  -- &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6  \\
  \hline
  6  &amp; 15125 &amp; 10500 &amp; 5375 &amp; 3500 &amp; 5000 &amp; 0  \\
  \hline
  5  &amp; 11875 &amp; 7125 &amp; 2500 &amp; 1000 &amp; 0 &amp; -  \\
  \hline
  4  &amp; 9375 &amp; 4375 &amp; 750 &amp; 0 &amp; - &amp; -  \\
  \hline
  3  &amp; 7875 &amp; 2625 &amp; 0 &amp; - &amp; - &amp; -  \\
  \hline
  2  &amp; 15750 &amp; 0 &amp; - &amp; - &amp; - &amp; -  \\
  \hline
  1  &amp; 0 &amp; - &amp; - &amp; - &amp; - &amp; -  \\
  \hline
  \end{array}
   %]]&gt;&lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; min(1,2) = min(1,1) + min(2,2) + p_0 \times p_1 \times p_2 = 0 + 0 + 30 * 35 * 15 = 15750 &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; min(2,3) = min(2,2) + min(3,3) + p_1 \times p_2 \times p_3 = 0 + 0 + 35 * 15 * 5 = 2625 &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; min(3,4) = min(3,3) + min(4,4) + p_2 \times p_3 \times p_4 = 0 + 0 + 15 * 5 * 10 = 750 &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; min(4,5) = min(4,4) + min(5,5) + p_3 \times p_4 \times p_5 = 0 + 0 + 5 * 10 * 20 = 1000 &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; min(5,6) = min(5,5) + min(6,6) + p_4 \times p_5 \times p_6 = 0 + 0 + 10 * 20 * 25 = 5000 &lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;
   min(1,3) = min(1,1) + min(2,3) + p_0 \times p_1 \times p_3 = 0 + 2625 + 30 * 35 * 5 = 2625 + 5250 = 7875 \\
   min(1,3) = min(1,2) + min(3,3) + p_0 \times p_2 \times p_3 = 15750 + 30 * 15 * 5 = 18000
&lt;/script&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/2015/03/01/cs-5549-midterm-review</link>
                <guid>http://zhou-dong.github.io/2015/03/01/cs-5549-midterm-review</guid>
                <pubDate>2015-03-01T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Play with complex numbers</title>
                <description>
&lt;h4 id=&quot;complex-number-as-points-in-the-complex-plane&quot;&gt;Complex number as points in the complex plane&lt;/h4&gt;

&lt;p&gt;Can interpret &lt;em&gt;real&lt;/em&gt; and &lt;em&gt;imaginary&lt;/em&gt; parts of a complex number as &lt;em&gt;x&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; coordinates.
Thus can interpret a complex number as a &lt;em&gt;point&lt;/em&gt; in the plane.&lt;/p&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
import matplotlib.pyplot as plt
import numpy as np

number_list = [2+2j, 3+2j, 1.75+1j, 2+1j, 2.25+1j, 2.5+1j, 2.75+1j, 3+1j, 3.25+1j]
for number in number_list:
    plt.scatter(number.real, number.imag)
plt.title(&quot;Interpert Complex Number&quot;)
plt.xlabel(&quot;Real number&quot;)
plt.ylabel(&quot;Imaginary number&quot;)
plt.show()
&lt;/pre&gt;

&lt;h4 id=&quot;complex-numbers-as-arrows&quot;&gt;Complex numbers as arrows&lt;/h4&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
z = -6 + 5j
plt.title(&quot;Complex as Arrow&quot;)
plt.xlabel(&quot;Real Number&quot;)
plt.ylabel(&quot;Imaginary Number&quot;)
plt.arrow(0, 0, z.real, z.imag)
plt.xlim(-10,10)
plt.ylim(-10,10)
plt.grid(True)
plt.show()
&lt;/pre&gt;

&lt;h4 id=&quot;add-two-complex-numbers&quot;&gt;Add two complex numbers&lt;/h4&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
z = x + y
plt.title(&quot;Complex Composition&quot;)
plt.xlabel(&quot;Real Number&quot;)
plt.ylabel(&quot;Imaginary Number&quot;)
plt.arrow(0, 0, x.real, x.imag, color=&#39;g&#39;)
plt.arrow(0, 0, y.real, y.imag, color=&#39;b&#39;)
plt.arrow(0, 0, z.real, z.imag, color=&#39;r&#39;)
plt.xlim(-3,6)
plt.ylim(-3,6)
plt.grid(True)
plt.show()
&lt;/pre&gt;

&lt;h4 id=&quot;multiply-complex-numbers&quot;&gt;Multiply complex numbers&lt;/h4&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
z = time * complex_number
plt.title(&quot;Multiply Complex&quot;)
plt.xlabel(&quot;Real Number&quot;)
plt.ylabel(&quot;Imaginary Number&quot;)
plt.arrow(0, 0, complex_number.real, complex_number.imag, color=&#39;b&#39;)
plt.arrow(0, 0, z.real, z.imag, color=&#39;y&#39;)
plt.xlim(-3,6)
plt.ylim(-3,6)
plt.grid(True)
plt.show()
&lt;/pre&gt;

&lt;h4 id=&quot;rotate-ninty-degree&quot;&gt;Rotate ninty degree&lt;/h4&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
 z = 1j * complex_number
plt.title(&quot;Multiply Complex&quot;)
plt.xlabel(&quot;Real Number&quot;)
plt.ylabel(&quot;Imaginary Number&quot;)
plt.arrow(0, 0, complex_number.real, complex_number.imag, color=&#39;b&#39;)
plt.arrow(0, 0, z.real, z.imag, color=&#39;y&#39;)
plt.xlim(-3,3)
plt.ylim(-3,3)
plt.grid(True)
plt.show()
&lt;/pre&gt;

&lt;h4 id=&quot;rotate-with-theta-degree&quot;&gt;Rotate with &lt;script type=&quot;math/tex&quot;&gt;\Theta&lt;/script&gt; degree&lt;/h4&gt;
&lt;p&gt;Use: &lt;strong&gt;Euler’s formula&lt;/strong&gt;&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/python/matrix/2015/02/28/playing-with-complex-number</link>
                <guid>http://zhou-dong.github.io/python/matrix/2015/02/28/playing-with-complex-number</guid>
                <pubDate>2015-02-28T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>CS-6649 Brief Note of Bioinformatics Project</title>
                <description>
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.scipy.org/&quot;&gt;SciPy&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;Description: &lt;a href=&quot;http://www.scipy.org/&quot;&gt;SciPy&lt;/a&gt; (pronounced “Sigh Pie”) is a Python-based ecosystem of open-source software for mathematics, science, and engineering. Some core packages: 
        &lt;ul&gt;
          &lt;li&gt;NumPy: Base N-dimensional array package&lt;/li&gt;
          &lt;li&gt;SciPy library: Fundamental library for scientific computing&lt;/li&gt;
          &lt;li&gt;Matplotlib: Comprehensive 2D Plotting&lt;/li&gt;
          &lt;li&gt;IPython: Enhanced Interactive Console&lt;/li&gt;
          &lt;li&gt;Sympy: Symbolic mathematics&lt;/li&gt;
          &lt;li&gt;pandas: Data structures &amp;amp; analysis&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://prody.csb.pitt.edu/&quot;&gt;ProDy&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://prody.csb.pitt.edu/&quot;&gt;ProDy&lt;/a&gt; is a free and open-source Python package for protein structural dynamics analysis.
        &lt;ul&gt;
          &lt;li&gt;Structure analysis&lt;/li&gt;
          &lt;li&gt;Dynamics analysis&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Use pip to install
        &lt;ul&gt;
          &lt;li&gt;pip install nose&lt;/li&gt;
          &lt;li&gt;pip install numpy&lt;/li&gt;
          &lt;li&gt;pip install -U ProDy &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ks.uiuc.edu/Research/vmd/&quot;&gt;VMD&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;VMD is a molecular visualization program for displaying, animating, and analyzing large biomolecular systems using 3-D graphics and built-in scripting.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.ks.uiuc.edu/Development/Download/download.cgi?PackageName=VMD&quot;&gt;Download Page&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
                <link>http://zhou-dong.github.io/2015/02/28/brief-note</link>
                <guid>http://zhou-dong.github.io/2015/02/28/brief-note</guid>
                <pubDate>2015-02-28T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Introduction to complex numbers</title>
                <description>
&lt;p&gt;Solutions to &lt;script type=&quot;math/tex&quot;&gt; x^2 = -1 &lt;/script&gt; ?&lt;br /&gt;
Mathematicians invented &lt;em&gt;i&lt;/em&gt; to be one solution.&lt;/p&gt;

&lt;p&gt;Example: &lt;script type=&quot;math/tex&quot;&gt; x^2 = -1 &lt;/script&gt; &lt;em&gt;solution is&lt;/em&gt; &lt;script type=&quot;math/tex&quot;&gt; x = 3i &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Numbers such as &lt;script type=&quot;math/tex&quot;&gt; i, -i, 3i, 2.17i &lt;/script&gt; are called &lt;strong&gt;imaginary&lt;/strong&gt; numbers.&lt;/p&gt;

&lt;p&gt;Solution to &lt;script type=&quot;math/tex&quot;&gt; (x-1)^2  = -9 ? \ x = 1 + 3i &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;A real number plus an imaginary number is a &lt;strong&gt;complex number&lt;/strong&gt;.&lt;br /&gt;
A real number has &lt;strong&gt;real part&lt;/strong&gt; and an &lt;strong&gt;imgianary part&lt;/strong&gt;.&lt;/p&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
# (x-1)**2 = -9, x = 1 + 3j
x = 1 + 3j

print x
print (x-1)**2
print type(x)

# ax + b = c
def solve(a, b, c):
    return (c-b)/a

# 10x + 5 = 30
print solve(10.0, 5.0, 30.0)

# (10 + 5i)x + 5 = 20
print solve(10+5j, 5.0, 20.0)
&lt;/pre&gt;
</description>
                <link>http://zhou-dong.github.io/python/matrix/2015/02/27/complex-numbers</link>
                <guid>http://zhou-dong.github.io/python/matrix/2015/02/27/complex-numbers</guid>
                <pubDate>2015-02-27T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>The Function and the Field</title>
                <description>
&lt;h4 id=&quot;set-terminology-and-notation&quot;&gt;Set terminology and Notation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Set: and unordered collection of objects. Example: &lt;script type=&quot;math/tex&quot;&gt; \{ X, Y, Z \}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \in &lt;/script&gt;: indicates than an object belong to a set (equivalently, that the set contains the object). For example, &lt;script type=&quot;math/tex&quot;&gt; X \in \{X, Y, Z\}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A \subseteq B &lt;/script&gt;: Read this as “A is a subset of B”. This measn A and B are sets, and every element of A is aslo an element of B.&lt;/li&gt;
  &lt;li&gt;A = B: Two sets are equal if they contain the exactly the same elements. (There is no order among elements of a set.)
    &lt;ul&gt;
      &lt;li&gt;A convenient way to prove that A and B are equal is to prove that each is a subset of the other. The proof often consists two parts:
        &lt;ol&gt;
          &lt;li&gt;a proof that &lt;script type=&quot;math/tex&quot;&gt; A \subseteq B, &lt;/script&gt; and&lt;/li&gt;
          &lt;li&gt;a proof that &lt;script type=&quot;math/tex&quot;&gt; B \subseteq A &lt;/script&gt;.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;set-expressions&quot;&gt;Set expressions:&lt;/h4&gt;

&lt;p&gt;In Mathese, we could write “the set of nonegative numbers” like that: &lt;script type=&quot;math/tex&quot;&gt; \{ x \in R: \  x \ge 0 \} &lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The colon(“:”) stands for “such that”.&lt;/li&gt;
  &lt;li&gt;There are two parts of this expression:
    &lt;ul&gt;
      &lt;li&gt;the part before the colon: This part specifies where the elements of the set come from, and introduces a variable or variables that can be used in the second part.&lt;/li&gt;
      &lt;li&gt;the part after the colon: This gives a rule that restricts which elements specified in the first part actually get to make it into the set. &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The analogous python expression is set &lt;code&gt;comprehension&lt;/code&gt;:&lt;/li&gt;
  &lt;li&gt;Python code:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre class=&quot;prettyprint linenums&quot;&gt;
    S = {-4, 4, -3, 3, -2, 2, -1, 1, 0}
    result = {x for x in S if x &amp;gt;= 0}
    print result
    result: set([0, 1, 2, 3, 4])
&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;you might see just &lt;script type=&quot;math/tex&quot;&gt; \{ x: x \ge 0 \}&lt;/script&gt;. For example: 
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \{ x: (x+1)(x-2) = 0 \}&lt;/script&gt;.&lt;/li&gt;
      &lt;li&gt;This time, the set consists of just two numbers, -1 and 2.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;set-terminology-and-notation-cartesian-product&quot;&gt;Set terminology and notation: Cartesian product&lt;/h4&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; A \times B&lt;/script&gt; is the set of all pairs &lt;script type=&quot;math/tex&quot;&gt; (a, b) &lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt; a \in A&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; b \in B&lt;/script&gt;&lt;br /&gt;
Example: for &lt;script type=&quot;math/tex&quot;&gt; A = \{ 1, 2 \}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; B = \{ x, y \}, A \times B&lt;/script&gt; is &lt;script type=&quot;math/tex&quot;&gt;\{(1,x),(2,x)(1,y)(2,y)\} &lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;tuples-in-set-expressions&quot;&gt;Tuples in set expressions&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \{ (x,y) \in R \times R: y = x^2 &lt;/script&gt; } &lt;code&gt;equal&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt; \{ (x,y): y = x^2\} &lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \{(x,y,z) \in R \times R \times R: x \ge 0, y \ge 0, z \ge 0 \} &lt;/script&gt;. &lt;code&gt;equal&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt; \{(x,y,z): x \ge 0, y \ge 0, z \ge 0\} &lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;the-function&quot;&gt;The function&lt;/h4&gt;

&lt;p&gt;Informally, for each input element in a set A, a function assigns a single output element from another set B.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A is called the &lt;code&gt;domain&lt;/code&gt; of the function&lt;/li&gt;
  &lt;li&gt;B is called the &lt;code&gt;co-domain&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: The output of a given input is called the &lt;em&gt;image&lt;/em&gt; of the input. The image of &lt;em&gt;q&lt;/em&gt; under &lt;em&gt;a&lt;/em&gt; function &lt;em&gt;f&lt;/em&gt; is denoted &lt;em&gt;f(q)&lt;/em&gt;.&lt;br /&gt;
If &lt;em&gt;f(q) = r&lt;/em&gt;, we say &lt;em&gt;q&lt;/em&gt; maps to &lt;em&gt;r&lt;/em&gt; under &lt;em&gt;f&lt;/em&gt;. In Mathese, we write this as &lt;script type=&quot;math/tex&quot;&gt; q \mapsto r &lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The set from which all the outputs are chosen is called the co-domain.&lt;br /&gt;
We write: &lt;script type=&quot;math/tex&quot;&gt; f: D \to F &lt;/script&gt;&lt;br /&gt;
when we want to say that &lt;strong&gt;f&lt;/strong&gt; is a function with domain &lt;strong&gt;D&lt;/strong&gt; and co-domain &lt;strong&gt;F&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: The &lt;em&gt;image&lt;/em&gt; of a function is the set of all images of inputs. Mathese: Im &lt;em&gt;f&lt;/em&gt;.&lt;br /&gt;
Example: Cosine Function &lt;strong&gt;cos(x)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;cos: &lt;script type=&quot;math/tex&quot;&gt; R \to R &lt;/script&gt;, which means that domain is &lt;script type=&quot;math/tex&quot;&gt;R&lt;/script&gt; and the co-domain is &lt;script type=&quot;math/tex&quot;&gt;R&lt;/script&gt;&lt;br /&gt;
The image of &lt;em&gt;cos(x)&lt;/em&gt;, Im &lt;em&gt;cos&lt;/em&gt;, is &lt;script type=&quot;math/tex&quot;&gt; \{ x \in R: -1 \le x \le 1\}&lt;/script&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: For sets F and D, &lt;script type=&quot;math/tex&quot;&gt;F^D&lt;/script&gt; denotes all functions from D to F.&lt;/p&gt;

&lt;h4 id=&quot;identity-function-and-composition&quot;&gt;Identity function and composition&lt;/h4&gt;

&lt;p&gt;Indentity function: for any domain &lt;script type=&quot;math/tex&quot;&gt; D, id_D: D \to D&lt;/script&gt;, maps each domain element &lt;em&gt;d&lt;/em&gt; to itself.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: For functions &lt;script type=&quot;math/tex&quot;&gt; f: A \to B &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; g: B \to C &lt;/script&gt;, the &lt;em&gt;functional composition&lt;/em&gt; of &lt;em&gt;f&lt;/em&gt; and &lt;em&gt;g&lt;/em&gt; is the function:&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt; (g \ o \ f) : A \to C &lt;/script&gt; defined by &lt;script type=&quot;math/tex&quot;&gt; (g \ o \ f)(x) = g(f(x))&lt;/script&gt;.&lt;br /&gt;
Example: Composition of &lt;script type=&quot;math/tex&quot;&gt; g(y) = y^2 &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; f(x) = x +1 &lt;/script&gt; is &lt;script type=&quot;math/tex&quot;&gt; (g \ o \ f)(x) = (x+1)^2&lt;/script&gt;.&lt;br /&gt;
Proposition: &lt;script type=&quot;math/tex&quot;&gt; h \ o \ (g \ o \ f) = (h \ o \ g ) \ o \ f&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;functional-inverse&quot;&gt;Functional inverse&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Functions &lt;em&gt;f&lt;/em&gt; and &lt;em&gt;g&lt;/em&gt; are functional inverses if &lt;em&gt;f o g&lt;/em&gt; and &lt;em&gt;g o f&lt;/em&gt; are defined and are indentity functions.&lt;br /&gt;
Invertible functions are &lt;strong&gt;one-to-one&lt;/strong&gt;.&lt;br /&gt;
Invertible functions are &lt;strong&gt;onto&lt;/strong&gt;.&lt;br /&gt;
&lt;strong&gt;Function Invertibility Theorem:&lt;/strong&gt; A function &lt;em&gt;f&lt;/em&gt; is invertible if and only if it is one-to-one and onto.&lt;/p&gt;

</description>
                <link>http://zhou-dong.github.io/matrix/python/2015/02/26/basic-math-intro</link>
                <guid>http://zhou-dong.github.io/matrix/python/2015/02/26/basic-math-intro</guid>
                <pubDate>2015-02-26T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Orthogonality</title>
                <description>
&lt;p&gt;正交，也就是在二维空间或者三维空间的垂直&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果有正交的sub dimensional的话，那么在矩阵的运算中，就可以极大的简化计算量。&lt;/li&gt;
  &lt;li&gt;在矩阵的运算中，就不需要高斯消去法了&lt;/li&gt;
  &lt;li&gt;只需要在各个dimension中各自求解&lt;/li&gt;
  &lt;li&gt;因为各个维度之间是没有影响的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;正交化的步骤&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;求linear dependent的matrix的basis&lt;/li&gt;
  &lt;li&gt;用其中的一个vector做标准，来正交化其它的basis&lt;/li&gt;
  &lt;li&gt;把正交化以后的新的basis做normalization，即长度都为1&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;orthogonal projection&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对subspace做orthogonal projection&lt;/li&gt;
  &lt;li&gt;对一个向量，在某个subspace做投影&lt;/li&gt;
  &lt;li&gt;把一个向量decomposition&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;orthogonal complement&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一个向量与两一个subspace中的所有向量都垂直&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;向量与subspace之间的orthogonality&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;即这个向量到这个平面的距离&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;求这个subspace的orthogonal basis，&lt;/li&gt;
  &lt;li&gt;求这个向量在这些orthogonal basis上的投影&lt;/li&gt;
  &lt;li&gt;这个向量减去在subspace上的投影，就是向量到空间的距离&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;用这个方式，可以求线性回归的问题&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/2015/02/22/orthogonality</link>
                <guid>http://zhou-dong.github.io/2015/02/22/orthogonality</guid>
                <pubDate>2015-02-22T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Eigenvalues, Eigenvectors, and Diagonaliztion</title>
                <description>
&lt;p&gt;(A - XI_n)v = 0&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;有些矩阵在实数的范围内没有eigenvalue&lt;/li&gt;
  &lt;li&gt;eigenvectors之间必须是垂直的&lt;/li&gt;
  &lt;li&gt;如果一个eigenvector不在某个eigenspace里面，那么它们之间应该是垂直的&lt;/li&gt;
  &lt;li&gt;eigenvecotrs应该是矩阵在向量空间中，各个维度的basic vector的投影的值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;characteristic polynomial&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先建立特征多项式 characteristic polynomial&lt;/li&gt;
  &lt;li&gt;求解特征方程式 characteristic equation&lt;/li&gt;
  &lt;li&gt;通过方程式的答案来求出eigenvector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;diagonalization of matrix&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对角矩阵&lt;/li&gt;
  &lt;li&gt;通过矩阵的对角化，来简化矩阵相乘的复杂度&lt;/li&gt;
  &lt;li&gt;如果能找到N个indenpent的矩阵，就能使这个矩阵对角化&lt;/li&gt;
&lt;/ul&gt;

</description>
                <link>http://zhou-dong.github.io/eigenvalue/eigenvector/2015/02/20/eigenvalues</link>
                <guid>http://zhou-dong.github.io/eigenvalue/eigenvector/2015/02/20/eigenvalues</guid>
                <pubDate>2015-02-20T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>CS-5549 Assignment 4</title>
                <description>
&lt;h4 id=&quot;question-&quot;&gt;Question :&lt;/h4&gt;
&lt;p&gt;Show the R-B trees that result after successively inserting the keys 41, 38, 31, 12, 19, 8 into an initially empty R-B tree. &lt;/p&gt;

&lt;p&gt;Answer:&lt;/p&gt;

&lt;div style=&quot;width:70%&quot;&gt;

  &lt;img alt=&quot;red-black-tree&quot; style=&quot;width:100%&quot; src=&quot;/images/Red-Black-Tree.png&quot; /&gt;

&lt;div&gt;
&lt;/div&gt;&lt;/div&gt;
</description>
                <link>http://zhou-dong.github.io/2015/02/20/cs-5549-assignment-4</link>
                <guid>http://zhou-dong.github.io/2015/02/20/cs-5549-assignment-4</guid>
                <pubDate>2015-02-20T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Matrices Mutiplication</title>
                <description>
&lt;p&gt;对角矩阵： (diagonal matrix)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对角矩阵首先是方阵&lt;/li&gt;
  &lt;li&gt;两个对角矩阵相乘，符合交换律&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对称矩阵：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;矩阵的转置，还是原矩阵&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;利用矩阵的反阵inverse可以实现相当于矩阵的除法&lt;/p&gt;

&lt;p&gt;invertible 矩阵的反转&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ax = b&lt;/li&gt;
  &lt;li&gt;A^-1 (Ax) = A^-1 b&lt;/li&gt;
  &lt;li&gt;A^-1 A x = A^-1 b&lt;/li&gt;
  &lt;li&gt;I_n x = A^-1 b&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;x = A^-1 b&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;可反转的矩阵也是方阵&lt;/li&gt;
  &lt;li&gt;如果一个矩阵可以反转，那么它最多只有一个反转矩阵&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Elementary matrix&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In mathematics, an elementary matrix is a matrix which differs from the identity matrix by one single elementary row operation.&lt;/li&gt;
  &lt;li&gt;利用elementary matrix和其它矩阵相乘，可以对矩阵做一些运算（个人理解为精确的运算）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;reduced row echelon form是唯一存在的&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;More inverse of Matrix&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;要判断一个矩阵是不是inverse的，可以看它的reduced row echelon是不是I_n，如果是那这个矩阵就是inverse的，反之就不是&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Invertable matrix theorem&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A in invertible&lt;/li&gt;
  &lt;li&gt;The reduced row echelon form is I_n&lt;/li&gt;
  &lt;li&gt;The rank of A equal n&lt;/li&gt;
  &lt;li&gt;The span of the columns of A is R^n&lt;/li&gt;
  &lt;li&gt;The equation Ax = b is consistant for every b in R^n&lt;/li&gt;
  &lt;li&gt;The nullity of A is equal 0&lt;/li&gt;
  &lt;li&gt;The column of A linear indenpendent&lt;/li&gt;
  &lt;li&gt;The only Ax = 0 is 0&lt;/li&gt;
  &lt;li&gt;A is a product of elementary matrix A是多个elementary matrix的相乘&lt;/li&gt;
  &lt;li&gt;There exists an n * n matrix B such that BA = I_n&lt;/li&gt;
  &lt;li&gt;There exists an n * n matrix C such that AC = I_n&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Linear Transformnations and Matrices&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;找出matrix transformation or linear transformation的standard matrix，就是把单位矩阵或者说单位向量依次带进去求解。&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/matrix/2015/02/16/matrices-and-linear-transformations</link>
                <guid>http://zhou-dong.github.io/matrix/2015/02/16/matrices-and-linear-transformations</guid>
                <pubDate>2015-02-16T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Intro to Matrices, Vectors, Equations, set</title>
                <description>
&lt;p&gt;&lt;strong&gt;零矩阵 != 零矩阵&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;零矩阵是有维度的，只是各个维度的值都为0&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;矩阵 乘以 0 =  零矩阵&lt;/p&gt;

&lt;p&gt;A * 0 != B * 0&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;因为矩阵A和矩阵B的维度可能不一样&lt;/li&gt;
  &lt;li&gt;所以它们生成的零矩阵可能会不一样&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;矩阵的转换：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A矩阵的transpose：A矩阵的行列转换&lt;/li&gt;
  &lt;li&gt;两个矩阵和的转置，等于两个矩阵分别转置然后再相加&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;vectors&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;row vector&lt;/li&gt;
  &lt;li&gt;column vector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;向量的加减和系数积 其实和矩阵是一样的&lt;/p&gt;

&lt;p&gt;Standard Vectors&lt;/p&gt;

&lt;p&gt;向量空间中的标准向量&lt;/p&gt;

&lt;p&gt;矩阵 * 向量&lt;/p&gt;

&lt;p&gt;矩阵 向量 相乘： 结果为一个 向量&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;单位向量、单位矩阵&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在一个向量空间中，我们可以定义各个维度单位为1的向量为这个维度的单位向量。&lt;/li&gt;
  &lt;li&gt;所以在一个N维的向量空间中，就会有个N个单位矩阵&lt;/li&gt;
  &lt;li&gt;这N个单位矩阵，按次序组成的矩阵就叫做identity matrix&lt;/li&gt;
  &lt;li&gt;由于我们知道，identity matrix在向量空间中的各个维度的值都为1，所以：&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;identity matrix和任何向量相乘，都会不改变向量的大小&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Stochastic Matrx&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在矩阵中，一列的值相加等于1&lt;/li&gt;
  &lt;li&gt;[0.85 0.03]&lt;/li&gt;
  &lt;li&gt;[0.15 0.97]&lt;/li&gt;
  &lt;li&gt;可以用这种矩阵来表示百分比的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Rotation Matrix&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;用向量空间来表示一个向量空间中旋转的角度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sytem of linear equations: （联立方程式）&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一个方程叫做linear equation&lt;/li&gt;
  &lt;li&gt;多个方程组合起来：system 藕粉 linear equations&lt;/li&gt;
  &lt;li&gt;方程式可能会有多个解，这些解的集合我们叫做solution set&lt;/li&gt;
  &lt;li&gt;Gaussian Elimination
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;所有的pivot position的上下都为0&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ax = b&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Elementary Row Operations&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;interchange&lt;/li&gt;
  &lt;li&gt;multiply nonzero scalar&lt;/li&gt;
  &lt;li&gt;add a mutiple of one row to another&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;augmented matrix&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;把变量和结果放在同一个矩阵中求解。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Set theory&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;set中是没有顺序的&lt;/li&gt;
  &lt;li&gt;union set 合集&lt;/li&gt;
  &lt;li&gt;intersection set 交集&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;difference set 两个集合相减&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;有限多元素的集合&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;无限多元素的集合&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;R^2 不是 R^3 的子集&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;一个判断一个向量的集合是否可以span出整个空间中的所有元素&lt;/li&gt;
  &lt;li&gt;只要找出整个集合中的向量，无法random出空间中的一个向量就可以了&lt;/li&gt;
  &lt;li&gt;一个集合中，如果两个向量是平行的或者是重合的，那么这两个向量在span的时候，作用是一样的&lt;/li&gt;
  &lt;li&gt;可以证明两个集合互为对方的子集&lt;/li&gt;
  &lt;li&gt;所以在整个集合中，每个向量都应该是独特的。&lt;/li&gt;
  &lt;li&gt;如果在一个set中，一个向量可以是别的向量的线性组合，那么这个向量就可以被移除掉。&lt;/li&gt;
  &lt;li&gt;判断集合中的向量是否线性相依&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Linear dependence 线性相依 L.D&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果其中的一些向量或者其实的两个向量，能组合出0向量，说明其中有的向量是线性相依的&lt;/li&gt;
  &lt;li&gt;如果解中，有一个向量是free variable那么说明这个向量是L.D&lt;/li&gt;
  &lt;li&gt;Ax = 0 有除了0向量外的其它解&lt;/li&gt;
  &lt;li&gt;Ax = b 可能有许多解&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Linear Independence L.I&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;不存在一组系数，使得集合里面任何向量之间的组合都不为0向量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;创建一组(L.I) set&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;创建一非零向量&lt;/li&gt;
  &lt;li&gt;第二个向量不能与第一个向量平行&lt;/li&gt;
  &lt;li&gt;以后添加的向量，不能是前面向量的线性组合&lt;/li&gt;
  &lt;li&gt;向量个数最多是m个&lt;/li&gt;
&lt;/ol&gt;

</description>
                <link>http://zhou-dong.github.io/matric/vector/linear/set/gaussian/2015/02/16/definitions-in-linear-algebra</link>
                <guid>http://zhou-dong.github.io/matric/vector/linear/set/gaussian/2015/02/16/definitions-in-linear-algebra</guid>
                <pubDate>2015-02-16T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Achieved Courses</title>
                <description>
&lt;h3 id=&quot;online-courses&quot;&gt;Online Courses&lt;/h3&gt;

&lt;h4 id=&quot;coursera&quot;&gt;Coursera:&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;R Programming
    &lt;ul&gt;
      &lt;li&gt;Start Date: Feb 01, 2015&lt;/li&gt;
      &lt;li&gt;End Date: Feb 10, 2015&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/zhou-dong/r-study&quot;&gt;Notes and Code&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Johns Hopkins&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;機器學習基石 (Machine Learning Foundations)
    &lt;ul&gt;
      &lt;li&gt;Start Date: Jan 31, 2015&lt;/li&gt;
      &lt;li&gt;End Date: Feb 15, 2015&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://zhou-dong.github.io/2015/02/15/revised-all/&quot;&gt;Simple Roadmap&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;National Taiwan University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;機器學習技法 (Machine Learning Techniques)
    &lt;ul&gt;
      &lt;li&gt;Start Date: March 17, 2015&lt;/li&gt;
      &lt;li&gt;End Date: March 21, 2015&lt;/li&gt;
      &lt;li&gt;National Taiwan University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;An Introduction to Interactive Programming in Python (Part 1)
    &lt;ul&gt;
      &lt;li&gt;Start Date: 02/13 2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/10 2015&lt;/li&gt;
      &lt;li&gt;Rice University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Coding the Matrix: Linear Algebra through Computer Science Applications
    &lt;ul&gt;
      &lt;li&gt;Start Date: 02/02/2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/08/2015&lt;/li&gt;
      &lt;li&gt;language: python &lt;/li&gt;
      &lt;li&gt;Brown University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Programming for Everybody (Python)
    &lt;ul&gt;
      &lt;li&gt;Start Date: 02/02 2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/14 2015&lt;/li&gt;
      &lt;li&gt;Some of chapters are useful&lt;/li&gt;
      &lt;li&gt;University of Michigan&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;An Introduction to Interactive Programming in Python (Part 2)
    &lt;ul&gt;
      &lt;li&gt;Start Date: 04/09 2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/18 2015&lt;/li&gt;
      &lt;li&gt;Rice University&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pattern Discovery in Data Mining
    &lt;ul&gt;
      &lt;li&gt;Start Date: 04/10 2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/12 2015&lt;/li&gt;
      &lt;li&gt;Not detailed enough, so don’t like so much&lt;/li&gt;
      &lt;li&gt;The University of Illinois at Urbana-Champaign&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Web Application Architectures
    &lt;ul&gt;
      &lt;li&gt;Start Date: 04/12 2015&lt;/li&gt;
      &lt;li&gt;End Date:04/14 2015&lt;/li&gt;
      &lt;li&gt;Use Ruby on rails to implement Web server&lt;/li&gt;
      &lt;li&gt;The University of New Mexico&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Text Retrieval and Search Engines
    &lt;ul&gt;
      &lt;li&gt;Start Date: 04/15 2015&lt;/li&gt;
      &lt;li&gt;End Date: 04/18 2015&lt;/li&gt;
      &lt;li&gt;I like this course, easily understand.&lt;/li&gt;
      &lt;li&gt;The University of Illinois at Urbana-Champaign&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Introduction to Recommender Systems
    &lt;ul&gt;
      &lt;li&gt;Start Date: 05/11 2015&lt;/li&gt;
      &lt;li&gt;End Date: 05/11 2015&lt;/li&gt;
      &lt;li&gt;No coding thing, just basic thing of Recommender System&lt;/li&gt;
      &lt;li&gt;The University of Minnesota &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;edex&quot;&gt;Edex:&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;MITx: 6.00.1x Introduction to Computer Science and Programming Using Python
    &lt;ul&gt;
      &lt;li&gt;Start Date: 01/07 2015&lt;/li&gt;
      &lt;li&gt;End Date: 09/04 2015&lt;/li&gt;
      &lt;li&gt;Almost finish all of them, some of them I think already know, so skip&lt;/li&gt;
      &lt;li&gt;MIT&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;youtube&quot;&gt;Youtube:&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;線性代數 (Not Finished All, Just lec01-lec-13)
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLe94oLfiYuBCN-1N9aHJVjqO0K_Ug0VwZ&quot;&gt;URL&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Start Date: Jan 04, 2015&lt;/li&gt;
      &lt;li&gt;End Date: Feb 10, 2015&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bioinformatcs (Introduction to bioinformatics)
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;/bioinformatics/2015/03/27/intro/&quot;&gt;URL&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Start Date: March 25 2015&lt;/li&gt;
      &lt;li&gt;End Date: March 28 2015&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;台大開放課程-線性代數-蘇柏青(I really like this course!)
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/playlist?list=PLw7ltASAuhMTZPgepJqpj_7Dv0AmIHJyJ&quot;&gt;URL&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Start Date: March 31 2015&lt;/li&gt;
      &lt;li&gt;End Date: April 08 2015&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;codecademy&quot;&gt;Codecademy&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Python&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HTML &amp;amp; CSS&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;JavaScript&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Make a Website (HTML css Bootstrap)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;jQuery&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;colledge&quot;&gt;Colledge&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;CS3329/CS5549-TBAA (Analysis of Algorithms)
    &lt;ul&gt;
      &lt;li&gt;2015 Spring Semester&lt;/li&gt;
      &lt;li&gt;Dr. Zhong&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Speical Topics CS6649-TXAD (Bioinformatics Algorithm)
    &lt;ul&gt;
      &lt;li&gt;2015 Spring Semester&lt;/li&gt;
      &lt;li&gt;Dr. Zhong&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Special Topics CS6649-TXAA (Graphical Data Mining)
    &lt;ul&gt;
      &lt;li&gt;2015 Spring Semester&lt;/li&gt;
      &lt;li&gt;Dr. Mago&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
                <link>http://zhou-dong.github.io/2015/02/16/achieved-courses</link>
                <guid>http://zhou-dong.github.io/2015/02/16/achieved-courses</guid>
                <pubDate>2015-02-16T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Three Learning Principles</title>
                <description>
&lt;h4 id=&quot;occams-razor&quot;&gt;Occam’s Razor&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;History:
    &lt;ul&gt;
      &lt;li&gt;An explanation of the data should be made as simple as possible, but no simpler. –Albert Einstein&lt;strong&gt;?&lt;/strong&gt;(1879-1955)&lt;/li&gt;
      &lt;li&gt;entia non sunt mutiplicanda praeter necessitatem (entities must not be mutiplied &lt;strong&gt;beyond necessity&lt;/strong&gt;) –William of Occam (1287-1347)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Definition:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Occam’s razor&lt;/strong&gt; for trimming down unnessary explanation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Explain:
    &lt;ul&gt;
      &lt;li&gt;The simplest model that fits the data is aslo the most plausible.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;One word:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Simple is Better&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;sampling-bias&quot;&gt;Sampling Bias&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Description:
    &lt;ul&gt;
      &lt;li&gt;If the data is sampled in a &lt;strong&gt;biased&lt;/strong&gt; way, learning will produce a similarly biased outcome.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Practical rule of thumb:
    &lt;ul&gt;
      &lt;li&gt;match test scenario as much as possible&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;data-snooping&quot;&gt;Data Snooping&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Data snooping
    &lt;ul&gt;
      &lt;li&gt;careful about &lt;strong&gt;your brain’s “model complexity”&lt;/strong&gt;.&lt;/li&gt;
      &lt;li&gt;shall be decided &lt;strong&gt;without “snooping” data&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;If data set has affected any step in the learning process, its ability to assess the outcome has been compromised.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dealing with data snooping
    &lt;ul&gt;
      &lt;li&gt;truth - &lt;strong&gt;very hard to avoid&lt;/strong&gt;, unless being extrnmely honest&lt;/li&gt;
      &lt;li&gt;extremely honest: &lt;strong&gt;lock your test data in safe&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;less honest: &lt;strong&gt;reserve validation and use cautiously&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;be blind: avoid making modeling decision by data&lt;/li&gt;
      &lt;li&gt;be suspicious: interpret research results (including your own)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/2015/02/15/three-learning-principles</link>
                <guid>http://zhou-dong.github.io/machine-learning/2015/02/15/three-learning-principles</guid>
                <pubDate>2015-02-15T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Revised Course</title>
                <description>
&lt;h4 id=&quot;three-related-fields&quot;&gt;Three Related Fields&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Data mining&lt;/li&gt;
  &lt;li&gt;Artifical Intelligence&lt;/li&gt;
  &lt;li&gt;Statistics&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;three-theoretical-bounds&quot;&gt;Three Theoretical Bounds&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Hoeffding&lt;/li&gt;
  &lt;li&gt;Muti-Bin Hoeffding&lt;/li&gt;
  &lt;li&gt;VC&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;three-linear-models&quot;&gt;Three Linear Models&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;PLA, pocket&lt;/li&gt;
  &lt;li&gt;Linear regression&lt;/li&gt;
  &lt;li&gt;Logistic regression&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;three-key-tools&quot;&gt;Three Key Tools&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Feature Transform&lt;/li&gt;
  &lt;li&gt;Regularization&lt;/li&gt;
  &lt;li&gt;Validation &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;three-learning-principles&quot;&gt;Three Learning Principles&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Occam’s Razer&lt;/li&gt;
  &lt;li&gt;Sampling Bias&lt;/li&gt;
  &lt;li&gt;Data Snooping &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;three-future-directions&quot;&gt;Three Future Directions&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;More Transform&lt;/li&gt;
  &lt;li&gt;More Regularization&lt;/li&gt;
  &lt;li&gt;Less Label&lt;/li&gt;
&lt;/ol&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/2015/02/15/revised-all</link>
                <guid>http://zhou-dong.github.io/machine-learning/2015/02/15/revised-all</guid>
                <pubDate>2015-02-15T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Regularization, Validation</title>
                <description>
&lt;h3 id=&quot;regularization&quot;&gt;Regularization&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Description:
    &lt;ol&gt;
      &lt;li&gt;我们可以把&lt;script type=&quot;math/tex&quot;&gt;E(in)&lt;/script&gt;和regularizer加在一起&lt;/li&gt;
      &lt;li&gt;minimizes augmented error, where the added regularizer effectively limits model complexity&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Regression with Constraint
    &lt;ol&gt;
      &lt;li&gt;Constraint&lt;/li&gt;
      &lt;li&gt;Softer constraint&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;validation&quot;&gt;Validation&lt;/h3&gt;

&lt;h4 id=&quot;model-selection-problemi-so-many-models&quot;&gt;Model selection problemi, so many models:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Classification:
    &lt;ul&gt;
      &lt;li&gt;PLA&lt;/li&gt;
      &lt;li&gt;pocket&lt;/li&gt;
      &lt;li&gt;linear regression&lt;/li&gt;
      &lt;li&gt;logistic regression&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;transform:
    &lt;ul&gt;
      &lt;li&gt;linear&lt;/li&gt;
      &lt;li&gt;quadratic&lt;/li&gt;
      &lt;li&gt;poly-10&lt;/li&gt;
      &lt;li&gt;Legendre-poly-10&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;regularizer
    &lt;ul&gt;
      &lt;li&gt;L2 regularizer&lt;/li&gt;
      &lt;li&gt;L1 regularizer&lt;/li&gt;
      &lt;li&gt;symmetry regularizer &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;validation-1&quot;&gt;Validation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Description:
    &lt;ul&gt;
      &lt;li&gt;留一份手中的资料做测试集。&lt;/li&gt;
      &lt;li&gt;legeal cheeting&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; E_{val}(h) &lt;/script&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Method: 
    &lt;ul&gt;
      &lt;li&gt;Leave-one-out Cross Validation&lt;/li&gt;
      &lt;li&gt;V-Flod Cross Validation &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
                <link>http://zhou-dong.github.io/regularization/validation/2015/02/15/regularization-validation</link>
                <guid>http://zhou-dong.github.io/regularization/validation/2015/02/15/regularization-validation</guid>
                <pubDate>2015-02-15T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Training, Generaliztion, VC</title>
                <description>
&lt;h4 id=&quot;traing-versus-testing&quot;&gt;1. Traing versus Testing&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;Effective number of Lines:
    &lt;ul&gt;
      &lt;li&gt;some time we can not dichot a set&lt;/li&gt;
      &lt;li&gt;how many lines can dichot a set&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dichotomies: Mini-hypotheses
    &lt;ul&gt;
      &lt;li&gt;dichotomy set: depend on inputs&lt;/li&gt;
      &lt;li&gt;growth function: remove dependence by taking max of all possible&lt;/li&gt;
      &lt;li&gt;finite, upper-bounded by &lt;script type=&quot;math/tex&quot;&gt; 2^n &lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;growth function for positive pays&lt;/li&gt;
      &lt;li&gt;Convex set&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Break Point
    &lt;ul&gt;
      &lt;li&gt;growth function: max number of dichotmies&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;theory-of-generaliztion&quot;&gt;2. Theory of Generaliztion&lt;/h4&gt;

&lt;p&gt;Description: 举一反三&lt;/p&gt;

&lt;p&gt;Detail:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;REstriction of Break Point
    &lt;ul&gt;
      &lt;li&gt;bounding function: maximum number of length-N vectors with(o,x) while “no shatter” any length-k subvectors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pictorial Proof&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;vc-dimension&quot;&gt;3. VC Dimension&lt;/h4&gt;

&lt;p&gt;Description: maximum non-break point. 一个集合，在vc dimension在这个点上可以shatter某N个点&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;positive rays: &lt;script type=&quot;math/tex&quot;&gt; d_{vc} = 1 &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;positive intervals: &lt;script type=&quot;math/tex&quot;&gt; d_{vc} = 2 &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;positive convex sets: &lt;script type=&quot;math/tex&quot;&gt; d_{vc} = \infty &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;2D perceptrons: &lt;script type=&quot;math/tex&quot;&gt; d_{vc} = 3 &lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/vc-dimension/2015/02/14/traing-testing</link>
                <guid>http://zhou-dong.github.io/machine-learning/vc-dimension/2015/02/14/traing-testing</guid>
                <pubDate>2015-02-14T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Linear Regression, Logistic Regression</title>
                <description>
&lt;h4 id=&quot;linear-regression&quot;&gt;Linear Regression&lt;/h4&gt;

&lt;p&gt;Description: 在二维空间找出一条线，或者三维空间找出一个面,分割这个Set。 &lt;/p&gt;

&lt;p&gt;Mathese: &lt;script type=&quot;math/tex&quot;&gt; E_{in}(W) = \frac{1}{N} \sum_{n=1}^N (w^Tx_n - y_n)^2&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Popular/historical error measure: squared error &lt;/p&gt;

&lt;p&gt;How to minimize the &lt;script type=&quot;math/tex&quot;&gt; E_{in} (W) &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Matrix: &lt;script type=&quot;math/tex&quot;&gt; min E_{in}(W) = \frac{1}{N} \begin{Vmatrix} Xw - y \end{Vmatrix}^2 &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;他是一个convex function，所以我们能找到极值点。&lt;/p&gt;

&lt;p&gt;应该是求导值（或者梯度的意思）应该是0.&lt;/p&gt;

&lt;p&gt;求导个人理解是曲线加速的方向。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;在向量空间中求出梯度为0的点&lt;/em&gt;就应该是极值点。&lt;/p&gt;

&lt;h4 id=&quot;linear-classification-vs-linear-regression&quot;&gt;Linear Classification vs. Linear Regression&lt;/h4&gt;

&lt;p&gt;可以用Linear Rregression来做Linear classification&lt;/p&gt;

&lt;p&gt;可以现在用linear regression现在初步的分割数据，然后再用linear classification&lt;/p&gt;

&lt;h4 id=&quot;logistic-regression&quot;&gt;Logistic Regression&lt;/h4&gt;

&lt;p&gt;It is kind of soft binary classification.&lt;/p&gt;

&lt;p&gt;linear regression的数据可以看成是logistic regression有noise的数据。&lt;/p&gt;

&lt;p&gt;Dcription: 预测某件事发生的概率。&lt;/p&gt;

&lt;p&gt;Convert the score to estimated probability by logistic function.&lt;/p&gt;

&lt;p&gt;把值转化成概率的函数。
&lt;script type=&quot;math/tex&quot;&gt; 
\theta(s) = \frac{e^s}{1+ e^s} = \frac{1}{1+e^{-s}}
&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Gradient Descent&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;greedy approch&lt;/li&gt;
  &lt;li&gt;Taylor Expansion&lt;/li&gt;
  &lt;li&gt;choise of n: don’t &lt;strong&gt;too smally&lt;/strong&gt;, don’t &lt;strong&gt;too large&lt;/strong&gt;, &lt;strong&gt;just right&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Stochastic gradient descent: random pick a gradient&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/regression/2015/02/14/linear-regression</link>
                <guid>http://zhou-dong.github.io/machine-learning/regression/2015/02/14/linear-regression</guid>
                <pubDate>2015-02-14T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Linear and Nonlinear Classification</title>
                <description>
&lt;h4 id=&quot;linear-classification&quot;&gt;Linear Classification&lt;/h4&gt;

&lt;p&gt;Basic: &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;One class at a Time&lt;/li&gt;
  &lt;li&gt;Combine Binary Classifiers&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Improve:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;One class at a Time&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Soft&lt;/strong&gt; combine Binary Classifiers&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Enhance:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Sum of all the probability equal 1&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;One class at a Time&lt;/li&gt;
  &lt;li&gt;Soft combine Classifiers&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;One versus&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Two class&lt;/strong&gt; at a time compare&lt;/li&gt;
  &lt;li&gt;Combine &lt;strong&gt;Pairwise&lt;/strong&gt; Classifiers&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;nonlinear-classification&quot;&gt;Nonlinear Classification&lt;/h4&gt;

&lt;p&gt;Circular Separable:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Equtation:
&lt;script type=&quot;math/tex&quot;&gt; 
  h(x) = sign(r \ -1 \cdot x_1^2 -1 \cdot x_2^2)  \\
  h(x) = sign(r \cdot 1 + \ (-1) \cdot x_1^2 + (-1) \cdot x_2^2) \\ 
  h(x) = sign(w_0z_0 + w_1z_1 + w_2z_2) \\
  h(x) = sign(w^Tz)
&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;特征的换：可以把一个平面内的点与圆半径的距离映射到向量空间中去.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Linear hypotheses in Z-space: circle, ellipse, hyperbola, constant&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/linear/classification/2015/02/14/linear-classification</link>
                <guid>http://zhou-dong.github.io/machine-learning/linear/classification/2015/02/14/linear-classification</guid>
                <pubDate>2015-02-14T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Machine Learning Type</title>
                <description>
&lt;h4 id=&quot;learning-with-different-output-space&quot;&gt;Learning with Different Output Space&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Binary Classification&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;credit approve/disapprove&lt;/li&gt;
      &lt;li&gt;email spam/non-spam&lt;/li&gt;
      &lt;li&gt;patient sick/not sick&lt;/li&gt;
      &lt;li&gt;ad profitable/not profitable&lt;/li&gt;
      &lt;li&gt;answer correct/incorrect&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Muticlass Classification
    &lt;ul&gt;
      &lt;li&gt;written digits: 0, 1, …, 9&lt;/li&gt;
      &lt;li&gt;pictures: apple, orange, strawberry&lt;/li&gt;
      &lt;li&gt;emails: spam, primary, social, promotion, update(Google)&lt;/li&gt;
      &lt;li&gt;recognition&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regression&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; y \in R&lt;/script&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Structured Learning
    &lt;ul&gt;
      &lt;li&gt;natural language process (NLP)&lt;/li&gt;
      &lt;li&gt;protein data&lt;/li&gt;
      &lt;li&gt;speech data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;learning-with-different-data-label&quot;&gt;Learning with Different Data Label&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Supervised&lt;/li&gt;
  &lt;li&gt;Unsupervised
    &lt;ul&gt;
      &lt;li&gt;articles to topics&lt;/li&gt;
      &lt;li&gt;consumer profiles to consumer groups&lt;/li&gt;
      &lt;li&gt;density estimation&lt;/li&gt;
      &lt;li&gt;outlier detection&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Semi-supervised&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reinforcement Learning&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;training ad system&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;black jack agent&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;learning-with-different-protocol&quot;&gt;Learning with Different Protocol&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Batch Learning (duck feeding)&lt;/li&gt;
  &lt;li&gt;Online Learning (passive sequdential)&lt;/li&gt;
  &lt;li&gt;Active Learning (question asking)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;learning-with-different-input-space&quot;&gt;Learning with Different Input Space&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;concrete&lt;/li&gt;
  &lt;li&gt;Raw Features&lt;/li&gt;
  &lt;li&gt;Abstract Features&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/2015/02/08/type-of-machine-learning</link>
                <guid>http://zhou-dong.github.io/machine-learning/2015/02/08/type-of-machine-learning</guid>
                <pubDate>2015-02-08T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Perceptron Hypothesis</title>
                <description>
&lt;h4 id=&quot;lecture-1-the-learning-problem&quot;&gt;Lecture 1: The learning problem&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; A &lt;/script&gt; takes &lt;script type=&quot;math/tex&quot;&gt; D &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; H &lt;/script&gt; to get &lt;script type=&quot;math/tex&quot;&gt; g &lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Math Sign&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Definition&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Detail&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; A &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Learning Algorithm&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;–&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; D:(x_1, y_1), \cdots, (x_n, y_n) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;training examples&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;historical records&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; H &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Hypothesis set&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;–&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; g \approx f &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;final hypothesis&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;“learned” formula to be useds&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f: X \rightarrow Y &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;unknown target function&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;ideal credit approval formula&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;lecture-2-learning-to-answer-yesno&quot;&gt;Lecture 2: Learning to answer &lt;strong&gt;Yes/No&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Perceptron Hyphothesis Set&lt;/li&gt;
  &lt;li&gt;Perceptron Learning Algorithm (PLA)&lt;/li&gt;
  &lt;li&gt;Guarantee of PLA&lt;/li&gt;
  &lt;li&gt;Non-Separable Data&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;a-simple-hypothesis-set-the-perceptron&quot;&gt;A Simple Hypothesis Set: the “perceptron”&lt;/h4&gt;
&lt;p&gt;For &lt;script type=&quot;math/tex&quot;&gt; x = (x_1, x_2, \cdots, x_d) &lt;/script&gt; &lt;strong&gt;features of customer&lt;/strong&gt;, computer a weight &lt;code&gt;score&lt;/code&gt; and&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;approve credit if &lt;script type=&quot;math/tex&quot;&gt; \sum_{i=1}^d w_i x_i &gt; threshold &lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;deny credit if &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
 \sum_{i=1}^d w_i x_i &lt;  threshold  %]]&gt;&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; y : \{ +1(good), -1(bad) \}, &lt;/script&gt; &lt;strong&gt;0&lt;/strong&gt; ignored - linear formula &lt;script type=&quot;math/tex&quot;&gt; h \in H &lt;/script&gt; are&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
 h(x) = sign((\sum_{i=1}^d w_i x_i) - threshold ) \\
 \ \ \ \ \ \ = sign((\sum_{i=1}^d w_i x_i) + (-threshold) \cdot (+1)) \\
 \ \ \ \ \ \ = sign((\sum_{i=1}^d w_i x_i) + w_0 \cdot x_0 ) \\
 \ \ \ \ \ \ = sign(\sum_{i=0}^d w_i x_i) \\
 \ \ \ \ \ \ = sign(w^T x) 
&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; h(x) = sign(w_0 + w_1x_1 + w_2x_2 + \cdots + w_nx_n) &lt;/script&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;perceptron-learning-algorithm&quot;&gt;Perceptron Learning Algorithm&lt;/h4&gt;
&lt;p&gt;For &lt;script type=&quot;math/tex&quot;&gt; t = 0, 1, 2, \cdots &lt;/script&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;find a mistake of &lt;script type=&quot;math/tex&quot;&gt; w_t &lt;/script&gt; called &lt;script type=&quot;math/tex&quot;&gt; (x_{n(t)}, y_{n(t)}) &lt;/script&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; sign(w_{t}^T x_{n(t)}) \neq y_{n(t)}&lt;/script&gt;.&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;(try to) correct the mistake by
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; w_{t+1} \leftarrow w_{t} + y_{n(t)}x_{n(t)} &lt;/script&gt;.&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;until no more mistake
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;return last &lt;script type=&quot;math/tex&quot;&gt; w \ (called \ w_{PLA}) \ as \  g&lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;section&quot;&gt;中文解释&lt;/h4&gt;
&lt;p&gt;在不断的循环中:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果在第t轮的循环中发现&lt;script type=&quot;math/tex&quot;&gt; w_t &lt;/script&gt;对一个点&lt;script type=&quot;math/tex&quot;&gt; (x_{n(t)}, y_{n(t)}) &lt;/script&gt;的判断是错误的，即：&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; sign(w_{t}^T x_{n(t)}) \neq y_{n(t)}&lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;加入这个点&lt;script type=&quot;math/tex&quot;&gt; (x_{n(t)}, y_{n(t)}) &lt;/script&gt;对&lt;script type=&quot;math/tex&quot;&gt; w_t &lt;/script&gt;进行修正，即：&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; w_{t+1} \leftarrow w_{t} + y_{n(t)}x_{n(t)} &lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;直到没有错误点为止，返回结果&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt;g = \ w \ (called \ w_{PLA})&lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;guarantee-of-pla&quot;&gt;Guarantee of PLA&lt;/h4&gt;

&lt;h5 id=&quot;linear-separable--d-leftrightarrow--exists-perfect-wt-such-that-yn--signwtt-xn&quot;&gt;Linear Separable &lt;script type=&quot;math/tex&quot;&gt; D \Leftrightarrow &lt;/script&gt; &lt;strong&gt;exists perfect&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt; such that &lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt;y_n = sign(w_t^T x_n)&lt;/script&gt;&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt; perfect hence every &lt;script type=&quot;math/tex&quot;&gt;x_n&lt;/script&gt; correctly away from line:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; y_{n(t)} w_f^T x_{n(t)} \ge  min \ y_n w_f^T x_n &gt; 0 &lt;/script&gt; by updating with any &lt;script type=&quot;math/tex&quot;&gt; (x_{n(t)}, y_{n(t)}) &lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; w_f^T w_{t+1} = w_f^T(w_t + y_{n(t)} x_{n(t)}) \ge w_f^T w_t + min \ y_n w_f^T x_n &gt; w_f^T w_t + 0 &lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;wt-changed-only-when-mistake--wt--dose-not-grow-too-fast&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt; changed only when mistake (&lt;script type=&quot;math/tex&quot;&gt; w_t &lt;/script&gt; Dose Not Grow Too Fast)&lt;/h5&gt;

&lt;h5 id=&quot;section-1&quot;&gt;两个向量内积越大夹角越小(长度不变的情况下)。&lt;/h5&gt;

&lt;h4 id=&quot;non-separable-data&quot;&gt;Non-Separable Data&lt;/h4&gt;

&lt;h5 id=&quot;learning-with-noisy-data&quot;&gt;Learning with &lt;strong&gt;Noisy Data&lt;/strong&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Line with Noise Tolerance
    &lt;ul&gt;
      &lt;li&gt;找出一条犯错误最少的分割线&lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt;&lt;/li&gt;
      &lt;li&gt;NP-hard to solve, unfortunately&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;使用贪心算法&lt;strong&gt;pocket&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;保存当前为止最好的分割线&lt;script type=&quot;math/tex&quot;&gt;w_t&lt;/script&gt;然后和其它策略想比较，如果更好就更新。&lt;/li&gt;
      &lt;li&gt;不会自动停下来，所以需要设置挺下来的条件。(PLA是会自己停下来的)。&lt;/li&gt;
      &lt;li&gt;效率比PLA要差。(PLA每次找一个点来修正，可是&lt;strong&gt;pocket&lt;/strong&gt;会每次都对比所有的点来确认哪次效果更好)。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/perceptron/2015/02/07/machine-learning-perceptron</link>
                <guid>http://zhou-dong.github.io/machine-learning/perceptron/2015/02/07/machine-learning-perceptron</guid>
                <pubDate>2015-02-07T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>BTree Graph</title>
                <description>
&lt;div style=&quot;width:100%&quot;&gt;

&lt;!--
  &lt;img alt=&quot;b-tree&quot; style=&quot;width:100%&quot; src=&quot;http://zhou-dong.github.io/images/b-tree.jpg&quot;/&gt;
--&gt;

  &lt;img alt=&quot;b-tree&quot; style=&quot;width:100%&quot; src=&quot;/images/b-tree.jpg&quot; /&gt;

&lt;div&gt;


&lt;/div&gt;&lt;/div&gt;
</description>
                <link>http://zhou-dong.github.io/2015/02/05/b-tree</link>
                <guid>http://zhou-dong.github.io/2015/02/05/b-tree</guid>
                <pubDate>2015-02-05T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Analysis of Decision Tree</title>
                <description>
&lt;h4 id=&quot;definition-of-decision-tree-from-wikipedia&quot;&gt;Definition of Decision Tree (From Wikipedia):&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm.&lt;/li&gt;
  &lt;li&gt;Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;sort-preformance&quot;&gt;Sort Preformance:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; n! &lt;/script&gt; ;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;search-performance&quot;&gt;Search Performance:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg n &lt;/script&gt; ;&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/decision/tree/2015/02/02/decision-tree-analysis</link>
                <guid>http://zhou-dong.github.io/decision/tree/2015/02/02/decision-tree-analysis</guid>
                <pubDate>2015-02-02T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Elementary Matrix Operations and Elementary Matrix</title>
                <description>
&lt;h4 id=&quot;elementary-matrix-operations-and-systems-of-linear-equations&quot;&gt;Elementary Matrix operations and Systems of Linear Equations&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; A_{m \times n} x_{n \times 1} = b_{m \times 1} &lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;elementary-rowcolumn-operations&quot;&gt;Elementary row(column) operations:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;列（行）交换&lt;/li&gt;
  &lt;li&gt;列（行）乘 - 非0纯量&lt;/li&gt;
  &lt;li&gt;某列（行）非0纯量加到另一列（行）&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;ex&quot;&gt;EX:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

A = \begin{pmatrix} 1 &amp; 3 &amp; 5 \\ 2 &amp; 4 &amp; 6 \end{pmatrix} \\
A_1 = \begin{pmatrix} 2 &amp; 4 &amp; 6 \\ 1 &amp; 3 &amp; 5 \end{pmatrix} \\
A_2 = \begin{pmatrix} -2 &amp; -6 &amp; -10 \\ 2 &amp; 4 &amp; 6 \end{pmatrix}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;elementary-matrix-from-wikipedia&quot;&gt;Elementary matrix (From Wikipedia):&lt;/h4&gt;
&lt;p&gt;In mathematics, an elementary matrix is a matrix which differs from the identity matrix by one single elementary row operation. The elementary matrices generate the general linear group of invertible matrices. Left multiplication (pre-multiplication) by an elementary matrix represents elementary row operations, while right multiplication (post-multiplication) represents elementary column operations. &lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;基本矩阵或者初等矩阵&lt;/h4&gt;
&lt;p&gt;线性代数中，初等矩阵（又称为基本矩阵）是一个与单位矩阵只有微小区别的矩阵。具体来说，一个n阶单位矩阵E经过一次初等行变换或一次初等列变换所得矩阵称为n阶初等矩阵。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;若一矩陣可由單位矩陣經過一次基本列運算而得，則稱此矩陣為基本矩陣。&lt;/li&gt;
  &lt;li&gt;必須進行超過1次基本列運算才能得到的矩陣，就不算是基本矩陣了。&lt;/li&gt;
  &lt;li&gt;它是由&lt;code&gt;單位矩陣&lt;/code&gt;來的，所以必須是個 n*n 的方陣。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;operations&quot;&gt;Operations:&lt;/h4&gt;
&lt;p&gt;初等矩阵分为3种类型，分别对应着3种不同的行/列变换。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;两行（列）互换: (&lt;script type=&quot;math/tex&quot;&gt; R_i \leftrightarrow R_j &lt;/script&gt;)&lt;/li&gt;
  &lt;li&gt;把某行（列）乘以一非零常数: (&lt;script type=&quot;math/tex&quot;&gt; kR_i \rightarrow R_i \ \  k \ne 0 &lt;/script&gt;)&lt;/li&gt;
  &lt;li&gt;把第i行（列）加上第j行（列）的k倍(&lt;script type=&quot;math/tex&quot;&gt; R_i + kR_j = R_i &lt;/script&gt;)&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;operation-one-&quot;&gt;Operation One 性质：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;逆矩阵即自身：&lt;script type=&quot;math/tex&quot;&gt; T_{ij}^{-1} = T_{ij} &lt;/script&gt;。&lt;/li&gt;
  &lt;li&gt;因为单位矩阵的行列式为1，故 &lt;script type=&quot;math/tex&quot;&gt; \vert T_{ij}\vert =-1&lt;/script&gt;。与其他相同大小的方阵A亦有一下性质：&lt;script type=&quot;math/tex&quot;&gt; \vert T_{ij}A \vert = - \vert A \vert  &lt;/script&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;operation-two-&quot;&gt;Operation Two 性质：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;逆矩阵为&lt;script type=&quot;math/tex&quot;&gt; T_{i}(m)^{-1} = T_{i}(\frac{1}{m})&lt;/script&gt;。&lt;/li&gt;
  &lt;li&gt;此矩阵及其逆矩阵均为对角矩阵。&lt;/li&gt;
  &lt;li&gt;其行列式&lt;script type=&quot;math/tex&quot;&gt; \vert T_{i}(m) \vert =m&lt;/script&gt;。故对于一等大方阵A有&lt;script type=&quot;math/tex&quot;&gt; \vert T_{i}(m)A \vert =m \vert A \vert&lt;/script&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;operation-three-&quot;&gt;Operation Three 性质：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;逆矩阵具有性质&lt;script type=&quot;math/tex&quot;&gt;T_{ij}(m)^{-1}=T_{ij}(-m)&lt;/script&gt;。&lt;/li&gt;
  &lt;li&gt;此矩阵及其逆矩阵均为三角矩阵。&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \vert T_{ij}(m)\vert=1&lt;/script&gt;。故对于一等大方阵A有：&lt;script type=&quot;math/tex&quot;&gt; \vert T_{ij}(m)A \vert = \vert A \vert &lt;/script&gt;。&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/elementary/matrix/2015/02/01/elementary-matrix-operations</link>
                <guid>http://zhou-dong.github.io/elementary/matrix/2015/02/01/elementary-matrix-operations</guid>
                <pubDate>2015-02-01T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Change of Coordinate Matrix</title>
                <description>
&lt;h4 id=&quot;section&quot;&gt;个人的理解：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;我自己的理解是，在同一个向量空间中，使用&lt;code&gt;不同的基底&lt;/code&gt;来表示同一个&lt;code&gt;线性函数&lt;/code&gt;或者&lt;code&gt;向量&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;注意，在同一个向量空间中，使用&lt;code&gt;不同的基底&lt;/code&gt;，对函数表达的结果是不一样的。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-1&quot;&gt;数学公式表示：&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

 \dbinom{x&#39;}{y&#39;} = \begin{pmatrix} \cos{\theta} &amp; \sin{\theta} \\ -\sin{\theta} &amp; \cos{\theta} \end{pmatrix} \dbinom{x}{y} \\
 [I]_{\beta}^{\beta&#39;}  = \begin{pmatrix} \cos{\theta} &amp; \sin{\theta} \\ -\sin{\theta} &amp; \cos{\theta} \end{pmatrix} \\
 x&#39; = x\cos{\theta} + y\sin{\theta} \\
 y&#39; = -x\sin{\theta} + y\cos{\theta}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/coordinate/2015/02/01/change-of-coordinate-matrix</link>
                <guid>http://zhou-dong.github.io/coordinate/2015/02/01/change-of-coordinate-matrix</guid>
                <pubDate>2015-02-01T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>What is Machine Learning</title>
                <description>
&lt;h4 id=&quot;machine-learning-acquiring-skill&quot;&gt;Machine Learning: acquiring skill&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;observations –&amp;gt; learning –&amp;gt; skill&lt;/li&gt;
  &lt;li&gt;date –&amp;gt; ML –&amp;gt; skil&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;skill&quot;&gt;Skill:&lt;/h4&gt;
&lt;p&gt;Improving some performance measure with experience computed from data.&lt;/p&gt;

&lt;h4 id=&quot;use-scenarios&quot;&gt;Use Scenarios:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Can not progam the system manually
    &lt;ul&gt;
      &lt;li&gt;Navigation of Mars&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Human can not define the solution easily
    &lt;ul&gt;
      &lt;li&gt;speech/visual recognition&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Need rapid decisions than human can not do
    &lt;ul&gt;
      &lt;li&gt;high-frequency trading&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;need to be user-oriented in massive scale
    &lt;ul&gt;
      &lt;li&gt;consumer-targeted marketing (different consumer use different strategy)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;key-essecnce-of-machine-learning&quot;&gt;Key Essecnce of Machine Learning&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Some &lt;code&gt;underlying pattern&lt;/code&gt; to be learned&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;No&lt;/code&gt; programmable (easy) definition&lt;/li&gt;
  &lt;li&gt;Somehow there is &lt;code&gt;data&lt;/code&gt; about the pattern&lt;/li&gt;
&lt;/ol&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/2015/01/31/what-is-machine-learning</link>
                <guid>http://zhou-dong.github.io/machine-learning/2015/01/31/what-is-machine-learning</guid>
                <pubDate>2015-01-31T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Machine Learning with Other Fields</title>
                <description>
&lt;h5 id=&quot;definition-of-machine-learning&quot;&gt;Definition of Machine Learning:&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Use &lt;code&gt;data&lt;/code&gt; to compute &lt;code&gt;hypothesis&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt;g&lt;/script&gt; that approximates &lt;code&gt;target&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt;\ f&lt;/script&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;relation-with-data-mining&quot;&gt;Relation with Data Mining&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;use &lt;code&gt;huge&lt;/code&gt; data to find property that is interesting.&lt;/li&gt;
  &lt;li&gt;ML = DM (usually what KDD cups does).&lt;/li&gt;
  &lt;li&gt;DM can help ML, and vice versa.&lt;/li&gt;
  &lt;li&gt;Traditional DM also focus on &lt;code&gt;efficent computation in large database&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;relation-with-artifical-intelligence&quot;&gt;Relation with Artifical Intelligence&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;AI: Compute something that show intelligent behavior.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ML can realize AI&lt;/code&gt;, among other routers.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;relation-with-statistics&quot;&gt;Relation With Statistics&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Statistics: use data to make inference about unknown process.&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;g&lt;/script&gt; is an inference outcome; &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; is something unknown.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Statistics can be used to achieve ML&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Traditional statistics also focus on &lt;code&gt;provable results with math assumption&lt;/code&gt;, and care less about &lt;code&gt;computation&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/2015/01/31/machine-learning-with-other-fields</link>
                <guid>http://zhou-dong.github.io/machine-learning/2015/01/31/machine-learning-with-other-fields</guid>
                <pubDate>2015-01-31T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Introduction of ML Course</title>
                <description>
&lt;h4 id=&quot;study-informantion&quot;&gt;Study Informantion:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Begin with Basic knowledge and mixture of:
    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;Philosophical illustrations&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;Math calculaton&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;Key theory&lt;/li&gt;
      &lt;li&gt;Core techniques&lt;/li&gt;
      &lt;li&gt;Usage in practice&lt;/li&gt;
      &lt;li&gt;Hopefully joke&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Others
    &lt;ul&gt;
      &lt;li&gt;Let students feel the environments of TAI DA&lt;/li&gt;
      &lt;li&gt;Story like (enjoy)&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;Improved with Quiz&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/2015/01/31/course-introduction</link>
                <guid>http://zhou-dong.github.io/machine-learning/2015/01/31/course-introduction</guid>
                <pubDate>2015-01-31T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Compontents of Machine Learning</title>
                <description>
&lt;h4 id=&quot;basic-notations&quot;&gt;Basic Notations:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;input: &lt;script type=&quot;math/tex&quot;&gt; x \in X&lt;/script&gt; (customer application)&lt;/li&gt;
  &lt;li&gt;output: &lt;script type=&quot;math/tex&quot;&gt; y \in Y&lt;/script&gt; (good/bad after approving credit card)&lt;/li&gt;
  &lt;li&gt;target function: 
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; f: X \rightarrow Y &lt;/script&gt; (&lt;code&gt;ideal&lt;/code&gt; credit approval formula)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;hypothesis: &amp;lt;=&amp;gt; skill with hopefully good performance:
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; g: X \rightarrow Y &lt;/script&gt; (&lt;code&gt;learned&lt;/code&gt; formula to be used)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; \{(x_n,y_n)\} \ \ from \ \ f \rightarrow [ML] \rightarrow g &lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;final-hypothsis--g-approx-f-&quot;&gt;Final hypothsis: &lt;script type=&quot;math/tex&quot;&gt; g \approx f &lt;/script&gt;&lt;/h4&gt;

&lt;h4 id=&quot;definiton&quot;&gt;Definiton:&lt;/h4&gt;
&lt;p&gt;Trainint examples(&lt;code&gt;data&lt;/code&gt;) –&amp;gt; learning algorithm(&lt;code&gt;A&lt;/code&gt;) –&amp;gt; &lt;code&gt;final hypothsis&lt;/code&gt; &lt;script type=&quot;math/tex&quot;&gt; g \approx f &lt;/script&gt;&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/machine-learning/2015/01/31/components-machine-learning</link>
                <guid>http://zhou-dong.github.io/machine-learning/2015/01/31/components-machine-learning</guid>
                <pubDate>2015-01-31T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>HeapSort Performance</title>
                <description>
&lt;h4 id=&quot;steps-of-heapsort&quot;&gt;Steps of HeapSort:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Create a CompleteBinaryTree Meanwhile heapify the tree.&lt;/li&gt;
  &lt;li&gt;Remove the root from the tree.&lt;/li&gt;
  &lt;li&gt;Switch the last leaf to the root.&lt;/li&gt;
  &lt;li&gt;Heapify the tree.&lt;/li&gt;
  &lt;li&gt;Recurisive the steps from 2 to 4 until tree is empty.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;master-theorem&quot;&gt;Master Theorem&lt;/h4&gt;
&lt;p&gt;Let a &lt;script type=&quot;math/tex&quot;&gt; \ge &lt;/script&gt; 1 and b &amp;gt; 1 be constants, let f(n) be a function. &lt;code&gt;T(n) = aT(n/b) + f(n)&lt;/code&gt; ;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = O(n^{\log_{b} a - \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a })&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Theta(n^{\log_{b} a}) &lt;/script&gt; then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a} \lg n) &lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Omega(n^{\log_{b} a + \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, and if &lt;script type=&quot;math/tex&quot;&gt; af(n/b) \le cf(n)&lt;/script&gt; for some constant c &amp;lt; 1 and all sufficiently large n, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(f(n))&lt;/script&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;evaluation-with-master-theorem&quot;&gt;Evaluation with Master Theorem:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Heapify the n elements tree from the laste leaf will cost steps n.&lt;/li&gt;
  &lt;li&gt;EveryTime change the position from leaf to root will cost steps 1.&lt;/li&gt;
  &lt;li&gt;EveryTime Heapify the tree from root to leaf will cost step &lt;script type=&quot;math/tex&quot;&gt; \lg n&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;Result: &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n \lg n) &lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
                <link>http://zhou-dong.github.io/2015/01/29/heapsort-performance</link>
                <guid>http://zhou-dong.github.io/2015/01/29/heapsort-performance</guid>
                <pubDate>2015-01-29T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>QuickSort Performance</title>
                <description>
&lt;h4 id=&quot;description-of-quicksort&quot;&gt;Description of QuickSort:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Find a pivot.&lt;/li&gt;
  &lt;li&gt;Scan the elements of array from the end, and compare each with pivot if it is bigger than pivot stop remember element.&lt;/li&gt;
  &lt;li&gt;Scan the elements of array from the begin, and compare each with pivot if it is smaller than pivot stop and remember element.&lt;/li&gt;
  &lt;li&gt;Switch two elements of step 2 and step 3.&lt;/li&gt;
  &lt;li&gt;keep doing step 2-4 until pivot in the middle, which means all the elements in the left of pivot smaller than pivot and all the elements in the right side of pivot bigger than pivot.&lt;/li&gt;
  &lt;li&gt;Recursive doing the 1-5, until all the number sorted.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;summary&quot;&gt;Summary:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;It is kind of &lt;code&gt;divide and conquer&lt;/code&gt; method.&lt;/li&gt;
  &lt;li&gt;I think it is similar with ShellSort but more effiency.&lt;/li&gt;
  &lt;li&gt;ShellSort every time change two place of elements, so it is better than sort one element by one time.&lt;/li&gt;
  &lt;li&gt;QuickSort every time change two place of elements meanwhile fixed one position of the element, it is brilliant.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;master-theorem&quot;&gt;Master Theorem:&lt;/h4&gt;
&lt;p&gt;Let a &lt;script type=&quot;math/tex&quot;&gt; \ge &lt;/script&gt; 1 and b &amp;gt; 1 be constants, let f(n) be a function. &lt;code&gt;T(n) = aT(n/b) + f(n)&lt;/code&gt; ;  &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = O(n^{\log_{b} a - \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a })&lt;/script&gt;.  &lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Theta(n^{\log_{b} a}) &lt;/script&gt; then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a} \lg n) &lt;/script&gt;.  &lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Omega(n^{\log_{b} a + \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, and if &lt;script type=&quot;math/tex&quot;&gt; af(n/b) \le cf(n)&lt;/script&gt; for some constant c &amp;lt; 1 and all sufficiently large n, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(f(n))&lt;/script&gt;.  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;evaluation-with-master-theorem&quot;&gt;Evaluation with Master Theorem:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The most balance cast: pivot is the middle large of the array&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Prove: &lt;script type=&quot;math/tex&quot;&gt;
   T(n) = aT(n/b) + f(n) \\ 
   a = 2 \\
   b = 2 \\
   f(n) = n \\
   T(n) = 2T(n/2) + n \\
   n^{\log_b a} = n^{\log_2 2} = n ^1 = n \\
   f(n) = n^{\log_b a} \\
   T(n) = \Theta(n \log_n)
&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Already sorted cast: pivot is the smallest or biggest of the array&lt;/li&gt;
  &lt;li&gt;Prove: &lt;script type=&quot;math/tex&quot;&gt;
   T(n) = T(n-1) + f(n) \\
   T(n) = O(n^2)
&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;improvement&quot;&gt;Improvement:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Every time choose there elments.&lt;/li&gt;
  &lt;li&gt;Choose middle one to be the pivot.&lt;/li&gt;
  &lt;li&gt;Just can improve, but can not avoid worst cast.&lt;/li&gt;
  &lt;li&gt;Best middle elements, the performance wiill be &lt;script type=&quot;math/tex&quot;&gt; n \lg n &lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;One method: we can random pick the pivot, so in chance, we can avoid the bad case.&lt;/li&gt;
  &lt;li&gt;There are some methods to find the middle, we will be talk later.&lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://zhou-dong.github.io/2015/01/28/quicksort-performance</link>
                <guid>http://zhou-dong.github.io/2015/01/28/quicksort-performance</guid>
                <pubDate>2015-01-28T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Invertible Matrix</title>
                <description>
&lt;h4 id=&quot;definition&quot;&gt;Definition:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; AB = BA = I_n &lt;/script&gt;  &lt;/p&gt;

&lt;h5 id=&quot;identity-matrix--identity-matrix-is-an-square-matrix-&quot;&gt;Identity Matrix ( Identity Matrix is an Square Matrix ):&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

 I_n = \begin{pmatrix} 1 &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp;  \cdots &amp; 1 \end{pmatrix}_{n \times n} \\
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;properties&quot;&gt;Properties:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
 I_mA_{mn} = A_{mn}I_n = A \\
 (T_1 T_2)^{-1} = T_2^{-1} T_1^{-1} \\
 [T^{-1}]_{\gamma}^{\beta} = ([T]_{\gamma}^{\beta})^{-1}
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;such-that-&quot;&gt;Such that :&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
 T = I_{V} \\
 U = I_{W} \\
 [UT]_{\beta} = [U]_{\gamma}^{\beta} [T]_{\beta}^{\gamma}
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;总结：&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;只要是维度相同，那么可以看成是同类的矩阵。&lt;/li&gt;
  &lt;li&gt;只有方正才有逆矩阵，但不一定所有的方正都有你矩阵。&lt;/li&gt;
  &lt;li&gt;如果存在逆矩阵，就把这举证叫做可逆矩阵或者非奇异矩阵。&lt;/li&gt;
  &lt;li&gt;两个矩阵相乘的几何意义可以理解为，把一个矩阵的元素表达在另一个矩阵里。&lt;/li&gt;
  &lt;li&gt;个人觉得可逆矩阵可以理解为在两个维度相同的矩阵中，用不同的基底把元素表达出来。&lt;/li&gt;
&lt;/ol&gt;
</description>
                <link>http://zhou-dong.github.io/identity-matrix/2015/01/28/invertible-matrix</link>
                <guid>http://zhou-dong.github.io/identity-matrix/2015/01/28/invertible-matrix</guid>
                <pubDate>2015-01-28T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Matrices</title>
                <description>
&lt;h4 id=&quot;definition&quot;&gt;Definition:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
  A = (A_{ij})_{mn} \\
  B = (B_{ij})_{np} \\
  AB = C = (C_{ij})_{mp} \\
  C_{ij} = \sum_{k=1}^n A_{ik}B_{kj} \  (A的第i行和B的第j列的内积)  
&lt;/script&gt;  &lt;/p&gt;

&lt;h4 id=&quot;example&quot;&gt;Example:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

 A = \begin{pmatrix} 1 &amp; 3 &amp; 5 \\ 4 &amp; 2 &amp; 7 \end{pmatrix}_{2 \times 3} \\
 B = \begin{pmatrix} 2 &amp; 8 &amp; 7 \\ 3 &amp; 6 &amp; 12 \\ 9 &amp; 4 &amp; 10 \end{pmatrix}_{3 \times 3} \\
 AB = \begin{pmatrix}56 &amp; 46 &amp; 93 \\ 77 &amp; 72 &amp; 122 \end{pmatrix}_{2 \times 3}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;properties-of-the-product-of-the-matrix&quot;&gt;Properties of the product of the Matrix:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
(AB)^t = B^tA^t \\
A(B_1 + B_2) = AB_1 + AB_2 \\
(A_1 + A_2)B = A_1B + A_2B \\
\alpha(AB) = A \alpha B = AB \alpha \\
I_mA_{mn} = A_{mn}I_n = A
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;square-matrix&quot;&gt;Square Matrix:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

I_n = \begin{pmatrix} 1 &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp;  \cdots &amp; 1 \end{pmatrix}_{n \times n}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;matrix-tanspose&quot;&gt;Matrix tanspose:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

A = \begin{pmatrix} 1 &amp; 3 &amp; 5 \\ 4 &amp; 2 &amp; 7 \end{pmatrix}_{2 \times 3} \\
A^t = \begin{pmatrix} 1 &amp; 4 \\ 3 &amp; 2 \\ 5 &amp; 7 \end{pmatrix}_{3 \times 2}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/2015/01/27/matrix-mutiply</link>
                <guid>http://zhou-dong.github.io/2015/01/27/matrix-mutiply</guid>
                <pubDate>2015-01-27T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Algorithm Assignment Two</title>
                <description>
&lt;h4 id=&quot;master-theorem&quot;&gt;Master Theorem&lt;/h4&gt;

&lt;p&gt;Let a &lt;script type=&quot;math/tex&quot;&gt; \ge &lt;/script&gt; 1 and b &amp;gt; 1 be constants, let f(n) be a function. &lt;code&gt;T(n) = aT(n/b) + f(n)&lt;/code&gt; ;  &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = O(n^{\log_{b} a - \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a })&lt;/script&gt;.  &lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Theta(n^{\log_{b} a}) &lt;/script&gt; then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(n^{\log_{b} a} \lg n) &lt;/script&gt;.        &lt;/li&gt;
  &lt;li&gt;If &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Omega(n^{\log_{b} a + \epsilon}) &lt;/script&gt; for some constant &lt;script type=&quot;math/tex&quot;&gt; \epsilon &gt; 0 &lt;/script&gt;, and if &lt;script type=&quot;math/tex&quot;&gt; af(n/b) \le cf(n)&lt;/script&gt; for some constant c &amp;lt; 1 and all sufficiently large n, then &lt;script type=&quot;math/tex&quot;&gt; T(n) = \Theta(f(n))&lt;/script&gt;.    &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;recurrence-examples&quot;&gt;4-1 Recurrence examples&lt;/h4&gt;
&lt;p&gt;Give asymptotic upper and lower bounds for T(n) in each of the following recurrences. Assume that T(n) is constant for n &lt;script type=&quot;math/tex&quot;&gt; \le &lt;/script&gt; 2. Make your bounds as tight as possible, and justify your answers.&lt;/p&gt;

&lt;h5 id=&quot;a--tn----2tn2--n4-&quot;&gt;a. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  2T(n/2) + n^4 &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; a = 2, \ b = 2, \ f(n) = n^4 &lt;/script&gt; ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\log_{b} a} = n^{\log_{2} 2} = n^1 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; f(n) = n^4 = \Omega(n^{\log_{b}a + \epsilon})  = \Omega(n^{1 + 3}) &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \epsilon = 3  &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \therefore \  T(n) = \Theta(n^4) &lt;/script&gt; .  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;b--tn----tn710--n-&quot;&gt;b. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  T(n7/10) + n &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  a = 1, \ b = 10/7, \ f(n) = n &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  n^{\log_{b} a} = n^{\log_{10/7} 1} = n^{0} &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  f(n) = n^1 = \Omega(n^{\log_{b}a + \epsilon})  = \Omega(n^{0 + 1}) &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \epsilon = 1 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \therefore \  T(n) = \Theta(n) &lt;/script&gt; .  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;c--tn----16tn4--n2-&quot;&gt;c. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  16T(n/4) + n^2 &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  a = 16, \ b = 4, \ f(n) = n^2 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  n^{\log_{b} a} = n^{\log_{4} 16} = n^2 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  f(n) = n^2 &lt;/script&gt;  ; &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \therefore T(n) = \Theta(n^2 \lg n) &lt;/script&gt;. &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;d--tn----7tn3--n2-&quot;&gt;d. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  7T(n/3) + n^2 &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  a = 7, \ b = 3, \ f(n) = n^2 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  n^{\log_{b} a} = n^{\log_{3} 7} = n^{1.772} &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  f(n) = n^2 = \Omega(n^{\log_{b}a + \epsilon})  = \Omega(n^{1.772 + 0.228}) &lt;/script&gt; ;   &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \epsilon = 0.228 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \therefore T(n) = \Theta(n^2) &lt;/script&gt; .  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;e--tn----7tn2--n2-&quot;&gt;e. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  7T(n/2) + n^2 &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  a = 7, \ b = 2, \ f(n) = n^2 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  n^{\log_{b} a} = n^{\log_{2} 7} = n^{2.8074} &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  f(n) = n^2 = \Omega(n^{\log_{b}a - \epsilon})  = \Omega(n^{2.8074 - 0.8074}) &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \epsilon = 0.8074 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \therefore T(n) = \Theta(n^{\log_{2} 7}) &lt;/script&gt; .  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;f--tn----2tn4--sqrtn-&quot;&gt;f. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  2T(n/4) + \sqrt{n} &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  a = 2, \ b = 4, \ f(n) = 1/2 &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  n^{\log_{b} a} = n^{\log_{4} 2} = n^{1/2} &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  f(n) = n^{1/2} &lt;/script&gt; ;  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;  \therefore T(n) = \Theta(n^{1/2} \lg n) = \Theta(\sqrt{n} \lg n) &lt;/script&gt; .  &lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;g--tn----tn-2--n2-&quot;&gt;g. &lt;script type=&quot;math/tex&quot;&gt; T(n)  =  T(n-2) + n^2 &lt;/script&gt;&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
\ \ \ \ T(n)  =  T(n-2) + n^2  \\
\ \ \ \ \ \ \ \ \ \ \ = T(n-4) + (n-2)^2 + n^2 \\
\ \ \ \ \ \ \ \ \ \ \ = T(n-6) + (n-4)^2 + (n-2)^2 + n^2 \\
\ \ \ \ \ \ \ \ \ \ \ = T(n-2k) + \sum_{i=0}^{2k-1} (n-2i)^2 ; \ \ (k=n/2) \\
\ \ \ \ \ \ \ \ \ \ \ = T(0) + \sum_{i=0}^{n/2-1} (n^2-4ni-4i^2)^2 \\
\ \ \ \ \therefore T(n) = \Theta(n^3)
&lt;/script&gt;&lt;/p&gt;

</description>
                <link>http://zhou-dong.github.io/2015/01/23/algorithm-assignment-two</link>
                <guid>http://zhou-dong.github.io/2015/01/23/algorithm-assignment-two</guid>
                <pubDate>2015-01-23T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Function Merge</title>
                <description>
&lt;h4 id=&quot;ordered-basis&quot;&gt;Ordered Basis&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; \beta &lt;/script&gt; is an &lt;code&gt;ordered basis&lt;/code&gt; for V, which means that: 
&lt;script type=&quot;math/tex&quot;&gt; \beta = \{u_1, u_2, u_3, \cdots , u_n\}  \ne \beta&#39;\{u_2, u_3, u_1, \cdots, u_n\} &lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;example-1&quot;&gt;Example 1:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; 
 V = P_2(R) \\ 
 \beta = \{1,x,x^2\} \\
 \beta&#39; = \{1, x^2,x\} \\
 v = -2 + 3x + x^2 \in P_2(R) \\
 [v]_{\beta} = \begin{pmatrix} -2 \\ 3 \\1 \end{pmatrix} \\
 [v]_{\beta&#39;} = \begin{pmatrix} -2 \\ 1 \\ 3 \end{pmatrix}
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;matrix-repretation&quot;&gt;Matrix Repretation&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
 T(v_j) = \sum_{i=1}^m a_{ij}v_i, \ \ j=1, 2, \cdots, n
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;example-2&quot;&gt;Example 2:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; 
  T: \ \ P_2(R) \rightarrow R \ \  and \ \ T(f(x)) = f(2) \\ 
  f(x) = x^2 \\
  T(x) = 4
&lt;/script&gt;  &lt;/p&gt;

&lt;h4 id=&quot;function--function&quot;&gt;Function + Function&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
(U +T)_x = (U)_x + (T)_x \\
U + T = T + U \\
(U + T)(x) = (T + U)(x)
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;function--times---r-&quot;&gt;Function &lt;script type=&quot;math/tex&quot;&gt; \times  \ R &lt;/script&gt;&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
(\alpha T)(x) = \alpha T(x)
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;function-merge&quot;&gt;Function Merge&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Funcitons can not multiply with each other, they can merge.&lt;/strong&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;
 U \circ T = UT
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;definition&quot;&gt;Definition:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
 X \rightarrow  T(x) \rightarrow U(T(x))
&lt;/script&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;V&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \rightarrow &lt;/script&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;W&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;  \rightarrow &lt;/script&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Z&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;U&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; x&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(x)&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;U(T(x))&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;some-equation&quot;&gt;Some Equation&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
(T_1 + T_2)U = T_1U + T_2U \\
T(U_1 + U_2) = TU_1 + TU_2 \\
(TU_1)U_2 = T(U_1U_2)
&lt;/script&gt;&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/basis/2015/01/20/function-merge</link>
                <guid>http://zhou-dong.github.io/basis/2015/01/20/function-merge</guid>
                <pubDate>2015-01-20T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Algorithm Assignment One</title>
                <description>
&lt;h4 id=&quot;notations&quot;&gt;Notations:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; O &lt;/script&gt; : Less than (Worst Situation)&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; o &lt;/script&gt; : Less or Equal&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \Omega &lt;/script&gt; : Bigger than (Best Situation)&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \omega &lt;/script&gt; : Big or Equal &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \Theta &lt;/script&gt; : Between { &lt;script type=&quot;math/tex&quot;&gt; O,\ \ \Omega &lt;/script&gt; }  &lt;/li&gt;
&lt;/ul&gt;

&lt;!-- PDF page 77 --&gt;

&lt;h4 id=&quot;definition-from-book-page-56&quot;&gt;Definition from book (page 56):&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg n = \log_{2} n &lt;/script&gt; (binary logarithm) ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\ln n = \log_{e} n &lt;/script&gt; (natural logarithm) ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^k n = (\lg n)^k &lt;/script&gt; (exponentiation) ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg \lg n = \lg(\lg n) &lt;/script&gt; (composition) .  &lt;/li&gt;
&lt;/ul&gt;

&lt;!-- PDF page 79 --&gt;

&lt;h4 id=&quot;definition-of---lg-n---from-book-page-58&quot;&gt;Definition of [ &lt;script type=&quot;math/tex&quot;&gt; \lg^* n &lt;/script&gt; ] from book (page 58):&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2 = 1 &lt;/script&gt; ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 4 = 2 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 16 = 3 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 65536 = 4 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{65536} = 5 &lt;/script&gt; .  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Translated from book by me(Dong Zhou)&lt;/strong&gt;:  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{2^0} = 1 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{2^1} = 2 &lt;/script&gt; ,  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{2^2} = 3 &lt;/script&gt; ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{2^4} = 4 &lt;/script&gt; ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg^* 2^{2^{16}} = 5 &lt;/script&gt; .&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;assignment-zero&quot;&gt;Assignment Zero:&lt;/h4&gt;

&lt;h5 id=&quot;tn--atnb--fn-&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = aT(n/b) + f(n) &lt;/script&gt;&lt;/h5&gt;

&lt;h5 id=&quot;example-&quot;&gt;Example :&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;Let:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt; a=2, \ b=2, \ f(n) = 1 &lt;/script&gt;   &lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Step&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Function One&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Equal&lt;/th&gt;
      &lt;th&gt;Functin Two&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 2T(n/2) + 1 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^1T(n/2^1) + 1 &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 4T(n/4) + 1 + 1 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^2T(n/2^2) + 2 &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = 8T(n/8) + 1 + 1 + 1 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^3T(n/2^3) + 3 &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = \ \ \ \ \ \ \  \vdots &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \ \ \ \ \ \ \  \vdots &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = nT(n/n) + \log_{2} n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\log_{2}n}T(n/2^{\log_{2}n}) + \log_{2} n &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;step1--step2---cdots---step5-&quot;&gt;Step1 + Step2 + &lt;script type=&quot;math/tex&quot;&gt; \cdots &lt;/script&gt; + Step5 :&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; T(n) = nT(1)  + \sum_{i=0}^{\log_{2}n} i &lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;assignment-one&quot;&gt;Assignment One:&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Indicate, for each pair of expressions(A, B) in the table below, whether A is &lt;script type=&quot;math/tex&quot;&gt; O, o, \Omega, \omega \ or \ \Theta &lt;/script&gt; of B. Assume that &lt;script type=&quot;math/tex&quot;&gt; k \geq 1, \epsilon &gt; 0, and \ c &gt; 1 &lt;/script&gt; are constants. Your answer should be in the form of the table with “yes” or “no” written in each box.&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;   &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    A    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    B    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    &lt;script type=&quot;math/tex&quot;&gt; O &lt;/script&gt;    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    &lt;script type=&quot;math/tex&quot;&gt; o &lt;/script&gt;    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    &lt;script type=&quot;math/tex&quot;&gt; \Omega &lt;/script&gt;    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    &lt;script type=&quot;math/tex&quot;&gt; \omega &lt;/script&gt;    &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;    &lt;script type=&quot;math/tex&quot;&gt; \Theta &lt;/script&gt;    &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;a.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^kn &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^\epsilon &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;b.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^k &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; c^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;c.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \sqrt{n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\sin n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;d.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{n/2} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;e.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\lg c} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; c^{\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;f.&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(n!) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(n^n) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;a-compare-between--lgkn--and--nepsilon-&quot;&gt;a. compare between &lt;script type=&quot;math/tex&quot;&gt; \lg^kn &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; n^\epsilon &lt;/script&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \frac{\lg^k n}{n^\epsilon} = \lim_{n \to \infty} \frac{(\lg n)^k}{n^\epsilon} \approx \lim_{n \to \infty} \frac{\ln (\lg n)^k}{\ln n^\epsilon} = \lim_{n \to \infty} \frac{k \ln(\lg n)}{\epsilon\ln n} = \lim_{n \to \infty} (\frac{k}{\epsilon} \cdot \frac{\ln \lg n}{\ln n})  \approx \lim_{n \to \infty} \frac{\ln \lg n}{\ln n} \approx \lim_{n \to \infty} \frac{\lg n}{ n} = 0 &lt;/script&gt; .&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;b-compare-between--nk--and--cn-&quot;&gt;b. compare between &lt;script type=&quot;math/tex&quot;&gt; n^k &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; c^n &lt;/script&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \frac{n^k}{c^n} \approx \lim_{n \to \infty} \frac{\ln n^k}{\ln c^n} = \lim_{n \to \infty} \frac{k\ln n}{n\ln c} =  \lim_{n \to \infty} (\frac{k}{\ln c} \cdot \frac{\ln n}{n}) \approx  \lim_{n \to \infty} \frac{\ln n}{n} = 0 &lt;/script&gt; .  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;c-compare-between--sqrtn--and--nsin-n-&quot;&gt;c. compare between &lt;script type=&quot;math/tex&quot;&gt; \sqrt{n} &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; n^{\sin n} &lt;/script&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\sin n &lt;/script&gt; in range [-1, 1]  &lt;/li&gt;
  &lt;li&gt;when &lt;script type=&quot;math/tex&quot;&gt;\sin n = 1, \lim_{n \to \infty} \frac{n}{n^{1/2}} = \lim_{n \to \infty} n^{1/2} = \infty &lt;/script&gt;  ,&lt;/li&gt;
  &lt;li&gt;when &lt;script type=&quot;math/tex&quot;&gt;\sin n = -1, \lim_{n \to \infty} \frac{n^{-1}}{n^{1/2}} = \lim_{n \to \infty} \frac{1}{n^{3/2}} = 0 &lt;/script&gt;  ,&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;d-compare-between--2n--and--2n2-&quot;&gt;d. compare between &lt;script type=&quot;math/tex&quot;&gt; 2^n &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; 2^{n/2} &lt;/script&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \frac{2^n}{2^{n/2}}  = \lim_{n \to \infty} 2^{n/2} = \infty &lt;/script&gt;  .&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;e-compare-between--nlg-c--adn---clg-n-&quot;&gt;e. compare between &lt;script type=&quot;math/tex&quot;&gt; n^{\lg c} &lt;/script&gt; adn  &lt;script type=&quot;math/tex&quot;&gt; c^{\lg n} &lt;/script&gt;&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;assume &lt;script type=&quot;math/tex&quot;&gt; n^{\lg c} = c^{\lg n} &lt;/script&gt; both side lg  &lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg n^{\lg c}  = \lg c^{\lg n}&lt;/script&gt;  ,&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;(\lg c)(\lg n) = (\lg n)(\lg c)&lt;/script&gt; ,   &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;f-compare-between--lgn--and--lgnn-&quot;&gt;f. compare between &lt;script type=&quot;math/tex&quot;&gt; \lg(n!) &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; \lg(n^n) &lt;/script&gt;&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg n^n = n\lg n&lt;/script&gt; ;&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\lg (n!) = \lg n + \lg (n-1) + \cdots + \lg 1 = \sum_{i=1}^n \lg i &lt;/script&gt; ;
    &lt;ul&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^n \lg i \le \sum_{i=1}^n \lg n  = n\lg n&lt;/script&gt; ;   &lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg (n!) = O(n\lg n) &lt;/script&gt; ;&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^n \lg i \ge \sum_{i=1 + n/2}^n \lg n/2  = (n/2)\lg (n/2) &lt;/script&gt; ;&lt;/li&gt;
      &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg (n!) = \Omega(n\lg n) &lt;/script&gt; ;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;assigement-two&quot;&gt;Assigement Two:&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;a. Rank the following functions by order of growth; that is, find an arrangement &lt;script type=&quot;math/tex&quot;&gt; g_1, g_2, \cdots ,g_{30} &lt;/script&gt; of the functions satisfying &lt;script type=&quot;math/tex&quot;&gt; g_1 = \Omega(g_2), g_2 = \Omega(g_3), \cdots , g_{29} = \Omega(g_{30}) &lt;/script&gt;. Partition your list into equivalence classes such that functions &lt;script type=&quot;math/tex&quot;&gt; f(n) &lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt; g(n) &lt;/script&gt; are in the same class if and only if &lt;script type=&quot;math/tex&quot;&gt; f(n) = \Theta(g(n)) &lt;/script&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;            &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(\lg^* n) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt;  2^{\lg^* n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; (\sqrt{2})^{\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^2 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n! &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; (\lg n)! &lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; (\frac{3}{2})^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^3 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^2 n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(n!) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{2^n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{1/\lg n}&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \ln\ln n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^* n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n2^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\lg\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \ln n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; (\lg n)^{\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; e^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 4^{\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; (n+1)! &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \sqrt{\lg n}&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^*(\lg n) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\sqrt{2\lg n}} &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; n \lg n &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{2^{n+1}}&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;answer&quot;&gt;Answer:&lt;/h5&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{2^{n+1}} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;  2^{2^n} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;  (n+1)! &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n! &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; e^n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n2^n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; (\frac{3}{2})^n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\lg\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; (\lg n)^{\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(n!) &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n^3 &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n^2 &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 4^{\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n \lg n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;=&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; (\lg n)! &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;=&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; (\sqrt{2})^{\lg n} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; 2^{\sqrt{2\lg n}} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^2 n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \ln n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \sqrt{\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \ln\ln n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt;  2^{\lg^* n} &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^* n &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg^* (\lg n) &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; \lg(\lg^* n) &lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{1/\lg n}&lt;/script&gt;&lt;/td&gt;
      &lt;td&gt;&amp;gt;&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;detail&quot;&gt;Detail:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; \lim_{n \to \infty} \frac{(n+1)!}{2^{2^n}} \approx \lim_{n \to \infty} \frac{\lg (n+1)!}{\lg 2^{2^n}} = \lim_{n \to \infty} \frac{(n+1) + n + \cdots + 1}{2^n} = \lim_{n \to \infty} \frac{(n+1)(n+2)}{2^{n-1}} \le \lim_{n \to \infty} \frac{(n+2)^2}{2^{n-1}} \approx \lim_{n \to \infty} \frac{\lg (n+2)^2}{\lg 2^{n-1}} = \lim_{n \to \infty} \frac{2\lg (n+2)}{n-1}&lt;/script&gt; ,&lt;br /&gt;
 &lt;script type=&quot;math/tex&quot;&gt; \approx \lim_{n \to \infty} \frac{\lg (n + 2)}{n-1}  \approx \lim_{n \to \infty} \frac{\lg n}{n} = 0  &lt;/script&gt;  ;    &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; \lim_{n \to \infty} \frac{n2^n}{e^n} \approx  \lim_{n \to \infty} \frac{\ln n2^n}{\ln e^n} = \lim_{n \to \infty} \frac{\ln n + n\ln 2}{n} = \lim_{n \to \infty} (\frac{\ln n}{n} + \ln 2) \approx \lim_{n \to \infty} \frac{\ln n}{n} = 0 &lt;/script&gt; ;  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \frac{(\lg n)^{\lg n}}{(3/2)^n} \approx \lim_{n \to \infty} \frac{\lg n(\lg \lg n)}{n \lg (3/2)} \approx \lim_{n \to \infty} \frac{\lg n(\lg \lg n)}{n} \le \lim_{n \to \infty} \frac{(\lg n)^2}{n} \approx \lim_{n \to \infty} \frac{2\lg \lg n}{\lg n} \approx \lim_{n \to \infty} \frac{\lg \lg n}{\lg n} \approx \lim_{n \to \infty} \frac{\lg n}{n} = 0 &lt;/script&gt;  ; &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\lg \lg n} = (2^{\lg n })^{\lg \lg n} = 2^{\lg n \lg \lg n} = (2^{\lg \lg n})^{\lg n} = (\lg n)^{\lg n}&lt;/script&gt; ;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; \lim_{n \to \infty} \frac{\lg (n!)}{(\lg n)^{\lg n}} \le \lim_{n \to \infty} \frac{\lg n^n}{(\lg n)^{\lg n}} = \lim_{n \to \infty} \frac{n\lg n}{(\lg n)^{\lg n}} \approx \lim_{n \to \infty} \frac{\lg n + \lg \lg n}{\lg n \lg \lg n} = \lim_{n \to \infty} (\frac{1}{\lg \lg n} + \frac{1}{\lg n}) = 0 &lt;/script&gt; ;  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; 4^{\lg n} = (2^2)^{\lg n} = 2^{2\lg n} =  2^{\lg^{n^2}} = n^2 &lt;/script&gt; ;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{\sqrt{2/\lg n}} = (2^{\lg n})^{\sqrt{2/\lg n}} = 2^{\lg n \sqrt{2/\lg n}} = 2^{\sqrt{2\lg n}} &lt;/script&gt; ;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; n = 2^{\lg n} &lt;/script&gt; ; &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \frac{\sqrt{\lg n}}{\ln n} \approx \lim_{n \to \infty} \frac{1/2 \ln \lg n}{\ln \ln n} \approx \lim_{n \to \infty} \frac{\ln \lg n}{\ln \ln n} \approx \lim_{n \to \infty} \frac{\lg n}{\ln n} = 0 &lt;/script&gt; ;  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; (\sqrt{2})^{\lg n} = 2^{1/2 \lg n} = (2^{\lg n})^{1/2} = n^{1/2} = \sqrt{n}&lt;/script&gt; ;  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \lg(\lg^*n) = \lim_{n \to \infty} \lg 5&lt;/script&gt; less than 3 ;   &lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\lim_{n \to \infty} \lg^* (\lg n) = \lim_{n \to \infty} \lg^* \lg n &lt;/script&gt; could be 4 or 5 ;    &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; n^{1/{\lg n}} = (2^{\lg n})^{1/{\lg n}} = 2^1 = 2 &lt;/script&gt; ;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;b. Give an example of a single nonnegative function &lt;script type=&quot;math/tex&quot;&gt; f(n) &lt;/script&gt; such that for all functions &lt;script type=&quot;math/tex&quot;&gt; g_i(n) &lt;/script&gt; in part &lt;script type=&quot;math/tex&quot;&gt; (a) &lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt; f(n)&lt;/script&gt; is neither &lt;script type=&quot;math/tex&quot;&gt; O(g_i(n))&lt;/script&gt;  nor &lt;script type=&quot;math/tex&quot;&gt; \Omega(g_i(n)) &lt;/script&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h5 id=&quot;answer-1&quot;&gt;Answer:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Could be bigger than &lt;script type=&quot;math/tex&quot;&gt; 2^{2n+1} &lt;/script&gt; and less than 1&lt;/strong&gt;  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; f(n) = 2^{3n+1}(1 + \sin n) &lt;/script&gt; or&lt;/strong&gt;  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;script type=&quot;math/tex&quot;&gt; f(n) = 2^{2n+3}(1 + \cos n) &lt;/script&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
                <link>http://zhou-dong.github.io/2015/01/20/algorithm-assignment-one</link>
                <guid>http://zhou-dong.github.io/2015/01/20/algorithm-assignment-one</guid>
                <pubDate>2015-01-20T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Basis and Dimension</title>
                <description>
&lt;h4 id=&quot;linearly-dependent&quot;&gt;Linearly dependent&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
a_1v_1 + a_2v_2 + \cdots + a_nv_n = 0 ; \\
\textstyle \sum_{i=1}^n a_iv_i = 0 ;
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;bases-and-dimension&quot;&gt;Bases and dimension&lt;/h4&gt;

&lt;h5 id=&quot;linearly-idependent-example1&quot;&gt;Linearly Idependent Example1:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V= R^2 \\
\beta = \{(1, 0), (0, 1)\} \\
\beta = \{(1, 0), (1, 1)\} \\
dim(v) = 2
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;linearly-idependent-example2&quot;&gt;Linearly Idependent Example2:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

V = M_{2 \times 3}(R) \\
\beta = 
 \begin{Bmatrix}
  \begin{pmatrix}
   1 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 0 
  \end{pmatrix},
 \begin{pmatrix}
   0 &amp; 1 &amp; 0 \\
   0 &amp; 0 &amp; 0
  \end{pmatrix},
 \begin{pmatrix}
   0 &amp; 0 &amp; 1 \\
   0 &amp; 0 &amp; 0
  \end{pmatrix},
 \begin{pmatrix}
   0 &amp; 0 &amp; 0 \\
   1 &amp; 0 &amp; 0
  \end{pmatrix},
 \begin{pmatrix}
   0 &amp; 0 &amp; 0 \\
   0 &amp; 1 &amp; 0
  \end{pmatrix},
 \begin{pmatrix}
   0 &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 1
  \end{pmatrix}
 \end{Bmatrix} \\
dim(v) = 6
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;linearly-independent-example3&quot;&gt;Linearly Independent Example3:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V = \{0\} \\
\beta = \Phi
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;linearly-independent-example4&quot;&gt;Linearly Independent Example4:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
P_2(R) = V \\
\beta = \{1, x, x^2\} \\
\beta = \{1, x+1, 2x^2\} \\
dim(V) = 3 
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;linearly-dependent-example5&quot;&gt;Linearly &lt;code&gt;Dependent&lt;/code&gt; Example5:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V= R^2 \\
\beta = \{(1, 0), (0, 1),(1,1)\}
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;基底：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;线性独立是基底的必要条件，但不是充分条件。基底中的各个向量一定线性独立。&lt;/li&gt;
  &lt;li&gt;基底是向量空间最具代表性的一些集，这些集合中的元素不多不少：向量空间中的任何元素都可以用基底&lt;code&gt;唯一&lt;/code&gt;的表达出来。&lt;/li&gt;
  &lt;li&gt;一项向量空间可以有不同的基底。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-1&quot;&gt;理解&lt;code&gt;基底&lt;/code&gt;的选择：&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;需要在向量空间中的每个维度，需要一个向量来代表这个维度
    &lt;ul&gt;
      &lt;li&gt;如果有两个向量、或者多个向量、或者向量乘以某个实数以后，之和为0，那么这些个向量为非线性独立。&lt;/li&gt;
      &lt;li&gt;为了保证用基底&lt;code&gt;唯一&lt;/code&gt;的表示一个向量空间中的元素，每个维度只应该有一个向量。&lt;/li&gt;
      &lt;li&gt;线性独立或者非独立是需找某个维度向量的方法。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;线性独立的向量可能没有覆盖向量空间的所有维度，线性独立的向量集合不一定是&lt;code&gt;基底&lt;/code&gt;。
    &lt;ul&gt;
      &lt;li&gt;基底中的各个向量之间都线性独立。&lt;/li&gt;
      &lt;li&gt;线性独立的向量集合不一定是基底。 &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;一个向量空间可以有不同的基底。&lt;/li&gt;
  &lt;li&gt;非线性独立的例子：
    &lt;ul&gt;
      &lt;li&gt;{(1,1),(2,2)}，用这两个向量不能表达二维空间的所有元素。&lt;/li&gt;
      &lt;li&gt;它的性质是：(1,1)*2 - (2,2) = 0 ;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;线性独立的例子：
    &lt;ul&gt;
      &lt;li&gt;{(0,1),(1,0)}，用这两个向量可以表示集合空间中的所元素。&lt;/li&gt;
      &lt;li&gt;它的性质是：(0,1)n + (1,0)m != 0 ;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</description>
                <link>http://zhou-dong.github.io/basis/dimension/2015/01/07/bases-and-dimension</link>
                <guid>http://zhou-dong.github.io/basis/dimension/2015/01/07/bases-and-dimension</guid>
                <pubDate>2015-01-07T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Gauss Elimination</title>
                <description>
&lt;h4 id=&quot;subspace&quot;&gt;Subspace&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V = p(F) = \{a_nx^n + \cdots + a_1x^1 + a_0 : n \in N, a_i \in F, i = 0,1 \cdots n \} \\
W = p_n(F) = \{a_nx^n + \cdots + a_0: n-is-fixed , a_i \in F, i=0,1 \cdots n \} \\
W \in V
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-1&quot;&gt;Example 1:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

define: \\
u_1 = (1,2,1) \\
u_2 = (-2,-4,-2) \\
u_3 = (0,2,3) \\ 
u_4 = (2,0,3) \\
u_5 = (-3,8,16) \\
v = (2,6,8) \\
result: \\
x_1u_1 + x_2u_2 + x_3u_3 + x_4u_4 + x_5u_5 = v \\ 
method 1: \\
x_1 - 2x_2 + 0x_3 + 2x_4 - 3x_5 = 2 \\
2x_1 - 4x_2 + 2x_3 + 0x_4 - 8x_5 = 6 \\
x_1 - 2x_2 + 3x_3 + 3x_4 + 16x_5 = 8 \\
method 2: \\
x_1
\begin{pmatrix}
 1 \\
 2 \\
 1
\end{pmatrix}
+ x_2
\begin{pmatrix}
 -2 \\
 -4 \\
 -2
\end{pmatrix}
+ x_3
\begin{pmatrix}
 0 \\
 2 \\
 3
\end{pmatrix}
+ x_4
\begin{pmatrix}
 2 \\
 0 \\
 3
\end{pmatrix}
+ x_5
\begin{pmatrix}
 -3 \\
 8 \\
 16
\end{pmatrix}
= 
\begin{pmatrix}
 2 \\
 6 \\
 8
\end{pmatrix} \\
\left[\begin{array}{rrrrr|r}
1 &amp; -2 &amp; 0 &amp; 2 &amp; -3 &amp; 2 \\
2 &amp; -4 &amp; 2 &amp; 0 &amp; 8 &amp; 6 \\
1 &amp; -2 &amp; 3 &amp; 3 &amp; 16 &amp; 8
\end{array}\right] 
\Rightarrow 
\left[\begin{array}{rrrrr|r}
1 &amp; -2 &amp; 0 &amp; 2 &amp; -3 &amp; 2 \\
0 &amp; 0 &amp; 2 &amp; -4 &amp; 14 &amp; 2 \\
1 &amp; -2 &amp; 3 &amp; 3 &amp; 16 &amp; 8
\end{array}\right] 
\Rightarrow 
\left[\begin{array}{rrrrr|r}
1 &amp; -2 &amp; 0 &amp; 2 &amp; -3 &amp; 2 \\
0 &amp; 0 &amp; 2 &amp; -4 &amp; 14 &amp; 2 \\
0 &amp; 0 &amp; 3 &amp; 1 &amp; 19 &amp; 6
\end{array}\right]
\Rightarrow
\left[\begin{array}{rrrrr|r}
1 &amp; -2 &amp; 0 &amp; 2 &amp; -3 &amp; 2 \\
0 &amp; 0 &amp; 2 &amp; -4 &amp; 14 &amp; 2 \\
0 &amp; 0 &amp; 0 &amp; 7 &amp; -2 &amp; 3
\end{array}\right]
\Rightarrow \\
1). \ 7x_4 - 2x_5 = 3 \\
2). \ 2x_3 - 4x_4 + 14x_5 = 2 \\
3). \ x_1 - 2x_2 + 2x_4 - 3x_5 = 2
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-2&quot;&gt;Example 2:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

u_1 = x^3 -2x^2 - 5x -3 \\
u_2 = 3x^3 - 5x^2 - 4x - 9 \\
v = 2x^3 - 2x^2 + 12x -6 \\
v = 3x^3 - 2x^2 + 7x + 8 \\
result: \\
x_1u_1 + x_2u_2 = v \\
process: \\
\left[\begin{array}{rr|rr}
 1 &amp; 3 &amp; 2 &amp; 3 \\
 -2 &amp; -5 &amp; -2 &amp; -2 \\
 -5 &amp; -4 &amp; 12 &amp; 7 \\
 -3 &amp; -9 &amp; -6 &amp; 8
 \end{array}\right]
\Rightarrow 
\left[\begin{array}{rr|rr}
 1 &amp; 3 &amp; 2 &amp; 3 \\
 0 &amp; 1 &amp; 2 &amp; 4 \\
 0 &amp; 11 &amp; 22 &amp; 22 \\
 0 &amp; 0 &amp; 0 &amp; 17
 \end{array}\right]
\Rightarrow
\left[\begin{array}{rr|rr}
 1 &amp; 3 &amp; 2 &amp; 3 \\
 0 &amp; 1 &amp; 2 &amp; 4 \\
 0 &amp; 0 &amp; 0 &amp; -22 \\
 0 &amp; 0 &amp; 0 &amp; 17
 \end{array}\right]
\Rightarrow \\
1). \ x_2 = 2 \\
2). \ x_1 + 3x_2 = 2
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;the-first-has-sollution-the-second-not&quot;&gt;The first has sollution the second not.&lt;/h4&gt;
</description>
                <link>http://zhou-dong.github.io/guass/2015/01/06/linear-combination</link>
                <guid>http://zhou-dong.github.io/guass/2015/01/06/linear-combination</guid>
                <pubDate>2015-01-06T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Introduction of Linear Algebra and Vector space</title>
                <description>
&lt;h4 id=&quot;definiton-of-linear-algebra&quot;&gt;Definiton of Linear algebra&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Function&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Is Linear Algebra&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f(x) = ax &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f(x) = ax + b &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f(x) = x^2 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f(x) = ax^2 + bxy + cy^2 &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;script type=&quot;math/tex&quot;&gt; f(\theta) = sin(\theta) &lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;vector-space&quot;&gt;Vector space&lt;/h4&gt;

&lt;h4 id=&quot;example-1&quot;&gt;Example 1:&lt;/h4&gt;

&lt;h5 id=&quot;definiton-of-two-dimensional-vector&quot;&gt;Definiton of Two dimensional vector:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
a = (x_1, y_1) ;
b = (x_2, y_2) ;
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;plus&quot;&gt;Plus:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
a + b  = (x_1 + x_2, y_1 + y_2) ;
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;mutiply&quot;&gt;Mutiply:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
\alpha \cdot a = (\alpha \cdot x_1, \alpha \cdot y_1) ;
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-2&quot;&gt;Example 2:&lt;/h4&gt;

&lt;h5 id=&quot;definition-of-mulit-dimensional-vector&quot;&gt;Definition of Mulit dimensional vector:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V = 
 \begin{Bmatrix}
  \begin{pmatrix}
   a_1 \\
   \vdots \\
   a_n
  \end{pmatrix}  
  a \in R, 1 \ll i \ll n; 
 \end{Bmatrix} ;
a, b \in V;
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;plus-1&quot;&gt;Plus:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
a + b = 
 \begin{pmatrix}
  a_1 + b _1 \\
  \vdots \\
  a_n + b_n
 \end{pmatrix}
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;multiply&quot;&gt;Multiply:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
\alpha \cdot a = 
 \begin{pmatrix}
  \alpha \cdot a_1 \\
  \vdots \\
  \alpha \cdot a_n
 \end{pmatrix}
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-3&quot;&gt;Example 3:&lt;/h4&gt;

&lt;h5 id=&quot;definiton-of-matrix&quot;&gt;Definiton of Matrix:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
V = 
 \begin{Bmatrix}
  \begin{pmatrix}
   a_{11} \cdots a_{1n} \\
   \vdots \ddots \vdots \\
   a_{m1} \cdots a_{mn}
  \end{pmatrix} ;
  a_{ij} \in R; 1 \ll i \ll n; 1 \ll j \ll m; 
 \end{Bmatrix} 
 ; A = (a_{ij}), B = (b_{ij}) \in V ;
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;plus-2&quot;&gt;Plus:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
A + B = (a_{ij} + b_{ij}) ;
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;multiply-1&quot;&gt;Multiply:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
\alpha \cdot A = (\alpha \cdot a_{ij}) ;
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;example-4&quot;&gt;Example 4:&lt;/h4&gt;

&lt;h5 id=&quot;definition-of-function-in-a-vector-space&quot;&gt;Definition of Function in a vector space:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
v = {f(f:S--&gt;F)}
&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;plus-3&quot;&gt;Plus:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

f + g = h &lt;==&gt; h(x) = f(x) + g(x);
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h5 id=&quot;mutiply-1&quot;&gt;Mutiply:&lt;/h5&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
\alpha \in F, f \in V;  (\alpha \cdot f)(s) = \alpha \cdot (f(s)); 
&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;theme&quot;&gt;Theme:&lt;/h4&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;
-(ax) = (-a)x = a(-x)
&lt;/script&gt;&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/linear-algebra/vector-space/2015/01/04/intro-vector-space</link>
                <guid>http://zhou-dong.github.io/linear-algebra/vector-space/2015/01/04/intro-vector-space</guid>
                <pubDate>2015-01-04T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>I am back</title>
                <description>
&lt;h3 id=&quot;new-life-begin&quot;&gt;New life begin&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;终于到Troy了，感觉突然就回来了！&lt;/li&gt;
  &lt;li&gt;行李终于在意料之中的没有随航班一起来。不过应该马上回到了。&lt;/li&gt;
  &lt;li&gt;刚才一直在收拾从家里寄过来的书，堆了慢慢的一书架，感觉还是挺骄傲的，同时也为那些不能带来注定要扔掉的书感到遗憾。&lt;/li&gt;
  &lt;li&gt;现在好好整理整理心情，开始做读书计划、生活计划、旅游计划、还有各种计划。然后开始好好生活了。&lt;/li&gt;
&lt;/ul&gt;

</description>
                <link>http://zhou-dong.github.io/2014/12/25/merry-christmas</link>
                <guid>http://zhou-dong.github.io/2014/12/25/merry-christmas</guid>
                <pubDate>2014-12-25T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Stuck in Dallas</title>
                <description>
&lt;h3 id=&quot;stuck-in-dallas&quot;&gt;Stuck in Dallas&lt;/h3&gt;

&lt;p&gt;第一天来美国，就被困在Dallas机场了。原因是蒙哥马利当地突然下暴雨，所以航班取消了，导致必须在机场里住一个晚上。而且由于第二天去蒙哥马利的所有的航班都已经满员了，所以check in service的工作人员帮我预定了Waiting list or stanking by，所以只有有人取消航班我才能登机。不过还好，已经通知了学校来接的shuttle bus，也通知了其他人来接我。而且行李也确定了会在明天记到蒙哥马利。幸好早来了几天，所以有时间浪费！中间由于着急，还把毕业证书给弄丢了！不过还好最终找回来了！&lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;这次最大的收获：&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;想的开了，人生总会遇上各种各样的麻烦，静下心来慢慢处理好就好了，而且好事多磨嘛！&lt;/li&gt;
  &lt;li&gt;用英语跟各种人员沟通的时候，完全没有问题，这也给自己增加了不少信心！&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;still-in-dallas&quot;&gt;Still in Dallas&lt;/h3&gt;
&lt;p&gt;结果第二天的航班也取消了，在Dallas呆了超过24小时，不过还好机场安排了住宿和餐饮。而且住宿的地方很棒。也算是赚了！&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/2014/12/24/stack-in-dalls</link>
                <guid>http://zhou-dong.github.io/2014/12/24/stack-in-dalls</guid>
                <pubDate>2014-12-24T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>First day in USA</title>
                <description>
&lt;h3 id=&quot;first-arrived-usa&quot;&gt;First arrived USA&lt;/h3&gt;

&lt;p&gt;我对气味本来就是个非常敏感的人，当在芝加哥机场乘坐机场大巴转美国国内航班的时候突然闻到了熟悉的美国的味道，以前的感觉瞬间回来了，好像根本没有离开美国一样，特别恍惚，不知道在国内的8年是梦幻、还是在美国的两年是梦幻、还是现在的我是梦幻。不管怎么样，已经踏上了美国的土地，我会好好生活。&lt;/p&gt;

&lt;h3 id=&quot;the-other-things&quot;&gt;The other things&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;这次来美国与第一次来美国的感觉彻底不一样了，发现美国的人也没那么帅了，美国女孩子也不是都比国内女孩子漂亮了，虽然整体上还是要不好不少。&lt;/li&gt;
  &lt;li&gt;在芝加哥转机到达拉斯的候机厅。对面坐着3个中国人，旁边坐着两个。穿着自以为很时尚的衣服，但我觉得LOW极了，看来我真的老了，已经欣赏不了年轻的时尚了。&lt;/li&gt;
  &lt;li&gt;美国的中国人真的很多，芝加哥机场转机的时候，到处能看到中国人。&lt;/li&gt;
  &lt;li&gt;美国各个种族的人都很多，有穆斯林、说着德语的夫妻、说着西班牙语的工作人员，当然还有各种各样的亚洲面孔：中国人，日本人，韩国人、听不懂来自哪里的亚洲人！&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section&quot;&gt;在飞机上的十几个小时，看完了吴军先生的《文明之光》第一册，一如既往的酣畅淋漓，读好的书籍，却是会让人有酣畅淋漓的感觉。&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;第一章给我的感觉就是磅礴大气，酣畅淋漓。从大爆物质的坍塌、恒星的形成、重元素的释放、行星的形成，到地球的形成，月亮的形成，海洋的形成到地球生物的形成。&lt;/li&gt;
  &lt;li&gt;人类的演化，共同的祖先，来自非洲大陆的人类祖先消灭了其它的人类，最终统治了整个地球。&lt;/li&gt;
  &lt;li&gt;古埃及的文明。&lt;/li&gt;
  &lt;li&gt;美索不达米亚平原的文明。&lt;/li&gt;
  &lt;li&gt;东方中国两河流域的文明。&lt;/li&gt;
  &lt;li&gt;古希腊在科学方面的文明。&lt;/li&gt;
  &lt;li&gt;罗马人对世界的贡献。&lt;/li&gt;
  &lt;li&gt;牛逼的瓷器。&lt;/li&gt;
  &lt;li&gt;欧洲的文艺复兴。&lt;/li&gt;
  &lt;li&gt;以对香料的需求引发的大航海时代的来领。&lt;/li&gt;
  &lt;li&gt;对于我这个自诩为还比较懂一些些历史的人，其实只是知道一些历史的点和故事，希望这本书能从对历史的了解联通起来。&lt;/li&gt;
  &lt;li&gt;本来从历史发展的角度和科学对文明的推动的角度去写历史，就是很好的创意。其实也应该是现在知识分子应该思维的方式。&lt;/li&gt;
&lt;/ol&gt;

</description>
                <link>http://zhou-dong.github.io/2014/12/23/transfer-chicago</link>
                <guid>http://zhou-dong.github.io/2014/12/23/transfer-chicago</guid>
                <pubDate>2014-12-23T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Shell of Totem Router</title>
                <description>
&lt;h4 id=&quot;routersh&quot;&gt;router.sh&lt;/h4&gt;
&lt;pre class=&quot;prettyprint linenums&quot;&gt; 
#!/bin/sh

RUNNING_USER=root
APP_HOME=/workspace/totem
APP_MAINCLASS=org.x.server.router.RouterServer

CLASSPATH=$APP_HOME
for i in &quot;$APP_HOME&quot;/lib/*.jar; do
CLASSPATH=&quot;$CLASSPATH&quot;:&quot;$i&quot;
done

export MALLOC_CHECK_=0

JAVA_OPTS=&quot;-server -Xms8192m -Xmx8192m -Xmn1024m -Djava.awt.headless=true -XX:MaxPermSize=128m&quot;

psid=0

checkpid()
{
javaps=`$JAVA_HOME/bin/jps -l | grep $APP_MAINCLASS`
if [ -n &quot;$javaps&quot; ]; then
psid=`echo $javaps | awk &#39;{print $1}&#39;`
else
psid=0
fi
echo &quot;psid=$psid&quot;
}


start()
{
checkpid
if [ $psid -ne 0 ]; then
echo &quot;================================&quot;
echo &quot;warn: $APP_MAINCLASS already started! (pid=$psid)&quot;
echo &quot;================================&quot;
else
echo -n &quot;Starting $APP_MAINCLASS ...&quot;
JAVA_CMD=&quot;nohup java $JAVA_OPTS -classpath $CLASSPATH $APP_MAINCLASS &amp;gt; /app/logs/router.log 2&amp;gt;&amp;amp;1 &amp;lt;/dev/null &amp;amp;&quot;
su -c &quot;$JAVA_CMD&quot;
checkpid
if [ $psid -ne 0 ]; then
echo &quot;(pid=$psid) [OK]&quot;
else
echo &quot;[Failed]&quot;
fi
fi
}

stop()
{
checkpid
if [ $psid -ne 0 ]; then
echo -n &quot;Stopping $APP_MAINCLASS ...(pid=$psid) &quot;
kill -9 $psid
if [ $? -eq 0 ]; then
echo &quot;[OK]&quot;
else
echo &quot;[Failed]&quot;
fi
checkpid
if [ $psid -ne 0 ]; then
stop
fi
else
echo &quot;================================&quot;
echo &quot;warn: $APP_MAINCLASS is not running&quot;
echo &quot;================================&quot;
fi
echo &quot;===remove bigqueue&quot;
rm -rf /server/bigqueue/logs/indexlogs/*

}

status()
{
checkpid
if [ $psid -ne 0 ];  then
echo &quot;$APP_MAINCLASS is running! (pid=$psid)&quot;
else
echo &quot;$APP_MAINCLASS is not running&quot;
fi
}

info()
{
echo &quot;System Information:&quot;
echo &quot;****************************&quot;
echo `head -n 1 /etc/issue`
echo `uname -a`
echo
echo &quot;JAVA_HOME=$JAVA_HOME&quot;
echo `$JAVA_HOME/bin/java -version`
echo
echo &quot;APP_HOME=$APP_HOME&quot;
echo &quot;APP_MAINCLASS=$APP_MAINCLASS&quot;
echo &quot;****************************&quot;
}

case &quot;$1&quot; in
&#39;start&#39;)
start
;;
&#39;stop&#39;)
stop
;;
&#39;restart&#39;)
stop
start
;;
&#39;status&#39;)
status
;;
&#39;info&#39;)
info
;;
*)
echo &quot;Usage: $0 {start|stop|restart|status|info}&quot;
exit 1
esac
exit 0

&lt;/pre&gt;
</description>
                <link>http://zhou-dong.github.io/2014/12/04/totem-router-shell</link>
                <guid>http://zhou-dong.github.io/2014/12/04/totem-router-shell</guid>
                <pubDate>2014-12-04T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Shell of Totem Appserver</title>
                <description>
&lt;h4 id=&quot;appserversh&quot;&gt;appserver.sh&lt;/h4&gt;
&lt;pre class=&quot;prettyprint linenums&quot;&gt; 
#!/bin/sh

UNNING_USER=root
APP_HOME=/workspace/totem
APP_MAINCLASS=org.x.server.app.AppServer

CLASSPATH=$APP_HOME
for i in &quot;$APP_HOME&quot;/lib/*.jar; do
CLASSPATH=&quot;$CLASSPATH&quot;:&quot;$i&quot;
done

export MALLOC_CHECK_=0

if [ `free -g |grep Mem |awk &#39;{print $2}&#39;` -ge  70 ]
   then 
     JAVA_OPTS=&quot;-server -Xms65536m -Xmx65536m -Xmn2048m -Djava.awt.headless=true -XX:MaxPermSize=256m&quot;
   else
     JAVA_OPTS=&quot;-server -Xms24576m -Xmx24576m -Xmn2048m -Djava.awt.headless=true -XX:MaxPermSize=256m&quot;
fi

psid=0

checkpid()
{
javaps=`$JAVA_HOME/bin/jps -l | grep $APP_MAINCLASS`
if [ -n &quot;$javaps&quot; ]; then
psid=`echo $javaps | awk &#39;{print $1}&#39;`
else
psid=0
fi
echo &quot;psid=$psid&quot;
}


start()
{
checkpid
if [ $psid -ne 0 ]; then
echo &quot;================================&quot;
echo &quot;warn: $APP_MAINCLASS already started! (pid=$psid)&quot;
echo &quot;================================&quot;
else
echo -n &quot;Starting $APP_MAINCLASS ...&quot;
JAVA_CMD=&quot;nohup java $JAVA_OPTS -classpath $CLASSPATH $APP_MAINCLASS &amp;gt; /app/logs/appserver.log 2&amp;gt;&amp;amp;1 &amp;lt;/dev/null &amp;amp;&quot;
su -c &quot;$JAVA_CMD&quot;
checkpid
if [ $psid -ne 0 ]; then
echo &quot;(pid=$psid) [OK]&quot;
else
echo &quot;[Failed]&quot;
fi
fi
}

stop()
{
checkpid
if [ $psid -ne 0 ]; then
echo -n &quot;Stopping $APP_MAINCLASS ...(pid=$psid) &quot;
kill -9 $psid
if [ $? -eq 0 ]; then
echo &quot;[OK]&quot;
else
echo &quot;[Failed]&quot;
fi
checkpid
if [ $psid -ne 0 ]; then
stop
fi
else
echo &quot;================================&quot;
echo &quot;warn: $APP_MAINCLASS is not running&quot;
echo &quot;================================&quot;
fi
echo &quot;===remove index lock tlog bigqueue&quot;
rm -f /server/solr/product/data/index/*.lock
rm -rf /server/bigqueue/logs/ModuleQueue/*
rm -rf /server/bigqueue/logs/schedule/*
rm -rf /server/bigqueue/logs/searchlogs/*
}

status()
{
checkpid
if [ $psid -ne 0 ];  then
echo &quot;$APP_MAINCLASS is running! (pid=$psid)&quot;
else
echo &quot;$APP_MAINCLASS is not running&quot;
fi
}

info()
{
echo &quot;System Information:&quot;
echo &quot;****************************&quot;
echo `head -n 1 /etc/issue`
echo `uname -a`
echo
echo &quot;JAVA_HOME=$JAVA_HOME&quot;
echo `$JAVA_HOME/bin/java -version`
echo
echo &quot;APP_HOME=$APP_HOME&quot;
echo &quot;APP_MAINCLASS=$APP_MAINCLASS&quot;
echo &quot;****************************&quot;
}

case &quot;$1&quot; in
&#39;start&#39;)
start
;;
&#39;stop&#39;)
stop
;;
&#39;restart&#39;)
stop
start
;;
&#39;status&#39;)
status
;;
&#39;info&#39;)
info
;;
*)
echo &quot;Usage: $0 {start|stop|restart|status|info}&quot;
exit 1
esac
exit 0
&lt;/pre&gt;

</description>
                <link>http://zhou-dong.github.io/2014/12/04/totem-appserver-shell</link>
                <guid>http://zhou-dong.github.io/2014/12/04/totem-appserver-shell</guid>
                <pubDate>2014-12-04T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Shell of Totem Beanstalk</title>
                <description>
&lt;h4 id=&quot;startsh&quot;&gt;start.sh&lt;/h4&gt;
&lt;pre class=&quot;prettyprint linenums&quot;&gt;
#!/bin/sh

LOG_DIR=/app/logs/beanstalk
PID=`ps aux |grep beanstalkd |grep -v grep |awk &#39;{print $2}&#39;`

start()
{
	PID=`ps aux |grep beanstalkd |grep -v grep |awk &#39;{print $2}&#39;`

	if [ -n &quot;$PID&quot; ];
		then 
			echo &quot;.....address already in use......&quot;
			exit
	fi


	if [ -d /app/logs/beanstalk ];
  		then
			echo &quot;begin to start...&quot;
	  	else 
			echo &quot;begin to make log file and start...&quot;
			mkdir -p /app/logs/beanstalk
	fi 

	nohup ./beanstalkd -z 52428800 -l 0.0.0.0 -p 11300  -V &amp;gt;$LOG_DIR/start.log 2&amp;gt;&amp;amp;1 &amp;lt;/dev/null &amp;amp;

	echo &quot;beanstalkd is running...&quot;
}

stop()
{

        if [ -n &quot;$PID&quot; ];
                then
                        echo &quot;stop ...&quot;
			kill -9 $PID
        fi	
}

info()
{
	echo `tail -n 2 $LOG_DIR/start.log`
	exit
}

case &quot;$1&quot; in
	&#39;start&#39;)
		start
		;;
	&#39;stop&#39;)
		stop
		;;
	&#39;restart&#39;)
		stop
		start
		;;
	&#39;info&#39;)
		info
		;;
	*)
		echo &quot;pls type $0 {start|stop|restart|info}&quot;

	exit 1
esac

&lt;/pre&gt;
</description>
                <link>http://zhou-dong.github.io/2014/12/04/beanstalk-shell</link>
                <guid>http://zhou-dong.github.io/2014/12/04/beanstalk-shell</guid>
                <pubDate>2014-12-04T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Machine Learning</title>
                <description>
&lt;p&gt;&lt;a href=&quot;http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial&quot;&gt;UFLDL&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ufldl.stanford.edu/wiki/index.php/UFLDL%E6%95%99%E7%A8%8B&quot;&gt;UFLDL教程&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://openclassroom.stanford.edu/MainFolder/CoursePage.php?course=MachineLearning&quot;&gt;Machine Learning - Andrew Ng&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.holehouse.org/mlclass/index.html&quot;&gt;Stanford Machine Learning&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.zhihu.com/question/20691338&quot;&gt;机器学习该怎么入门&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;上海交通大学-开发课程&lt;/a&gt;&lt;/p&gt;
</description>
                <link>http://zhou-dong.github.io/2014/12/02/machinel-learning</link>
                <guid>http://zhou-dong.github.io/2014/12/02/machinel-learning</guid>
                <pubDate>2014-12-02T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>网站技术点</title>
                <description>
&lt;h4 id=&quot;dns&quot;&gt;DNS供应商&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;www.godaddy.com&lt;/li&gt;
  &lt;li&gt;www.name.com&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;cdn&quot;&gt;CDN服务商&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;蓝汛、网宿、Webluker、帝联、阿里云、安全宝、加速乐、快网、17CDN&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section&quot;&gt;负载均衡&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;LVS&lt;/li&gt;
  &lt;li&gt;NGIX&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-1&quot;&gt;静态文件代理/缓存&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Squid&lt;/li&gt;
  &lt;li&gt;Varnish&lt;/li&gt;
  &lt;li&gt;Ngix&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-2&quot;&gt;前端&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Bootstrap&lt;/li&gt;
  &lt;li&gt;AngularJS&lt;/li&gt;
  &lt;li&gt;Jquery&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-3&quot;&gt;后端&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Express.js&lt;/li&gt;
  &lt;li&gt;Node.js&lt;/li&gt;
  &lt;li&gt;Tomcat + apr&lt;/li&gt;
  &lt;li&gt;Appserver&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-4&quot;&gt;消息中间件&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://kafka.apache.org/&quot;&gt;Kafka&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;ZeroMQ&lt;/li&gt;
  &lt;li&gt;RocketMQ&lt;/li&gt;
  &lt;li&gt;Netty&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.rabbitmq.com/&quot;&gt;RabbitMQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://activemq.apache.org/&quot;&gt;ActiveMQ&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/twitter/kestrel&quot;&gt;twitter/jestrel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-5&quot;&gt;存储系统&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;程序内存储
    &lt;ul&gt;
      &lt;li&gt;Ehcache&lt;/li&gt;
      &lt;li&gt;LRU&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/bulldog2011/bigqueue.git&quot;&gt;Bigqueue&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;传统关系型数据库
    &lt;ul&gt;
      &lt;li&gt;Mqsql&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;嵌入式数据库
    &lt;ul&gt;
      &lt;li&gt;LevelDB（LSM）&lt;/li&gt;
      &lt;li&gt;RocketsDB (基于LevelDB内核做二次开发)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;分布式数据库
    &lt;ul&gt;
      &lt;li&gt;MongoDB&lt;/li&gt;
      &lt;li&gt;CouchDB&lt;/li&gt;
      &lt;li&gt;Hbase&lt;/li&gt;
      &lt;li&gt;OceanBase&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;内存数据库
    &lt;ul&gt;
      &lt;li&gt;Redis&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;分布式图片存储
    &lt;ul&gt;
      &lt;li&gt;TFS&lt;/li&gt;
      &lt;li&gt;FASTDFS&lt;/li&gt;
      &lt;li&gt;MOGILEFS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-6&quot;&gt;搜索产品&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Solr&lt;/li&gt;
  &lt;li&gt;Elasticsearch&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-7&quot;&gt;分布式任务控制&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Zookeeper&lt;/li&gt;
  &lt;li&gt;Dubbo&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-8&quot;&gt;公共产品开发&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;分布式session共享
    &lt;ul&gt;
      &lt;li&gt;Redis&lt;/li&gt;
      &lt;li&gt;Jetty&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;分布式Scheduler
    &lt;ul&gt;
      &lt;li&gt;quartz + LevelDB/MongoDB + Zookeeper&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-9&quot;&gt;数据收集和分析&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Flume + Log4J&lt;/li&gt;
  &lt;li&gt;Hadoop&lt;/li&gt;
  &lt;li&gt;Spark&lt;/li&gt;
  &lt;li&gt;Strom&lt;/li&gt;
  &lt;li&gt;Mahout&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-10&quot;&gt;爬虫系统&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;防屏蔽
    &lt;ul&gt;
      &lt;li&gt;动态ADSL切换(家庭网络)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;程序开发
    &lt;ul&gt;
      &lt;li&gt;PhantomJs + Node.js&lt;/li&gt;
      &lt;li&gt;Webkit C++ 内核&lt;/li&gt;
      &lt;li&gt;Java Httputil&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-11&quot;&gt;系统运维和监控&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Cacti&lt;/li&gt;
  &lt;li&gt;Zabbix&lt;/li&gt;
  &lt;li&gt;Ganglia&lt;/li&gt;
  &lt;li&gt;Zookeepr监控&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-12&quot;&gt;服务器虚拟化&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Docker&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-13&quot;&gt;操作系统&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;服务器操作系统
    &lt;ul&gt;
      &lt;li&gt;CentOS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;开发操作系统
    &lt;ul&gt;
      &lt;li&gt;Macbook&lt;/li&gt;
      &lt;li&gt;Fedora&lt;/li&gt;
      &lt;li&gt;Ubuntu&lt;/li&gt;
      &lt;li&gt;openSUSE&lt;/li&gt;
      &lt;li&gt;Debian&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;vps&quot;&gt;VPS提供商&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;AWS&lt;/li&gt;
  &lt;li&gt;阿里云&lt;/li&gt;
  &lt;li&gt;linode(linux node)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-14&quot;&gt;自然语言处理&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;CRFPP&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.nltk.org/&quot;&gt;NLTK&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-15&quot;&gt;版本控制&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Git + GitHub&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-16&quot;&gt;博客&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Gitpages + Jekyll + markdown&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-17&quot;&gt;开发语言&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Java&lt;/li&gt;
  &lt;li&gt;Javscript&lt;/li&gt;
  &lt;li&gt;Python&lt;/li&gt;
  &lt;li&gt;C++&lt;/li&gt;
  &lt;li&gt;C Language&lt;/li&gt;
&lt;/ul&gt;

</description>
                <link>http://zhou-dong.github.io/2014/11/30/web-technology</link>
                <guid>http://zhou-dong.github.io/2014/11/30/web-technology</guid>
                <pubDate>2014-11-30T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>English Vocabulary Thinking</title>
                <description>
&lt;h4 id=&quot;section&quot;&gt;不只是长篇的文学作品，&lt;code&gt;文字&lt;/code&gt;或者&lt;code&gt;单词&lt;/code&gt;才是一个名族文化的浓缩和核心。如：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Odyssey：漫长而艰苦的旅程。来自于：特洛伊战争后，奥迪赛和他的小伙伴们经历种种困难终于回到家乡的故事。&lt;/li&gt;
  &lt;li&gt;exodus ：大批的离去。 来自于：圣经故事中的出埃及记。&lt;/li&gt;
  &lt;li&gt;narcissus：水仙花。源于希腊神话中一个叫Narcissus的青年，他因眷恋自己在水中的形象而死去，死后变成了花，人们称之为水仙花。&lt;/li&gt;
  &lt;li&gt;narcissism：自恋，自我陶醉。自恋的Narcissus。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-1&quot;&gt;英语单词就像汉字一样，也是有边旁部首的，只不过英语中叫做&lt;code&gt;词根&lt;/code&gt;、&lt;code&gt;前缀&lt;/code&gt;、&lt;code&gt;后缀&lt;/code&gt;。&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;orthodox：正统的人或事。 ortho：right；dox：opinion。&lt;/li&gt;
  &lt;li&gt;heterodox：异端的、非正统的。hetero：不同的；dox：opinion。&lt;/li&gt;
  &lt;li&gt;paradox：悖论。para：高于、反面；dox：opinion。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section-2&quot;&gt;与跟汉字一样，造词和读音是两个系统。&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;metabolism：新陈代谢。读音：[mɪ’tæbəlɪz(ə)m]；造词：mata[改变] + bolism。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;section-3&quot;&gt;目的：&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;从理论上明确单词的组成。&lt;/li&gt;
  &lt;li&gt;让自己背单词的过程不那么的枯燥。&lt;/li&gt;
  &lt;li&gt;总结自己的收获。&lt;/li&gt;
&lt;/ol&gt;
</description>
                <link>http://zhou-dong.github.io/2014/11/30/english-vocabulary</link>
                <guid>http://zhou-dong.github.io/2014/11/30/english-vocabulary</guid>
                <pubDate>2014-11-30T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Study List</title>
                <description>
&lt;h3 id=&quot;program-language&quot;&gt;Program Language&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;C&lt;/li&gt;
  &lt;li&gt;C++&lt;/li&gt;
  &lt;li&gt;Java&lt;/li&gt;
  &lt;li&gt;Python&lt;/li&gt;
  &lt;li&gt;Node.js&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;english-study&quot;&gt;English Study&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;TOEFL&lt;/li&gt;
  &lt;li&gt;GRE&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;master-course&quot;&gt;Master Course&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Natural Language Process&lt;/li&gt;
  &lt;li&gt;Machine Learning&lt;/li&gt;
  &lt;li&gt;Deep Learning&lt;/li&gt;
  &lt;li&gt;Neural Networks&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tools&quot;&gt;Tools&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Fedora&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;other&quot;&gt;Other&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;School Transfer&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;american-life&quot;&gt;American Life&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Credit card apply&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;basic-course&quot;&gt;Basic Course&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;高等数学-上&lt;/li&gt;
  &lt;li&gt;高等数学-下&lt;/li&gt;
  &lt;li&gt;概率论与数理统计&lt;/li&gt;
  &lt;li&gt;算法&lt;/li&gt;
  &lt;li&gt;矩阵计算&lt;/li&gt;
  &lt;li&gt;离散数学&lt;/li&gt;
  &lt;li&gt;信息论&lt;/li&gt;
  &lt;li&gt;凸优化	&lt;/li&gt;
&lt;/ul&gt;

</description>
                <link>http://zhou-dong.github.io/2014/11/28/study-list</link>
                <guid>http://zhou-dong.github.io/2014/11/28/study-list</guid>
                <pubDate>2014-11-28T00:00:00-06:00</pubDate>
        </item>

        <item>
                <title>Books</title>
                <description>
&lt;ol&gt;
  &lt;li&gt;鸟哥的Linux私房菜服务器架设篇（第二版）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;牧羊少年奇幻之旅&lt;/strong&gt; &lt;/li&gt;
  &lt;li&gt;小王子&lt;/li&gt;
  &lt;li&gt;精通CSS：高级Web标准解决方案（第2版）&lt;/li&gt;
  &lt;li&gt;Java编程思想（第4版）&lt;/li&gt;
  &lt;li&gt;操作系统：精髓与设计原理（原书第6版）&lt;/li&gt;
  &lt;li&gt;人月神话（32周年中文纪念版）&lt;/li&gt;
  &lt;li&gt;编译原理（第2版）&lt;/li&gt;
  &lt;li&gt;程序员修炼之道——从小工到专家&lt;/li&gt;
  &lt;li&gt;代码大全&lt;/li&gt;
  &lt;li&gt;设计模式 可复用面向对象软件的基础&lt;/li&gt;
  &lt;li&gt;计算机程序的构造和解释：原书第2版&lt;/li&gt;
  &lt;li&gt;追风筝的人&lt;/li&gt;
  &lt;li&gt;算法导论(原书第2版)&lt;/li&gt;
  &lt;li&gt;魔术的耳语&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;大卫的伤疤&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;浪潮之巅&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;美国种族简史&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;世界上的另一个你&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lucene实战(第2版)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;这个历史挺靠谱·全三册&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;数学之美&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;如丧——我们终于老得可以谈谈未来&lt;/li&gt;
  &lt;li&gt;百年孤独&lt;/li&gt;
  &lt;li&gt;美国怎么了：一个自由主义者的良知&lt;/li&gt;
  &lt;li&gt;《虎妈战歌》&lt;/li&gt;
  &lt;li&gt;孤独天使&lt;/li&gt;
  &lt;li&gt;傲慢与偏见-Pride and Prejudice（典藏英文原版）&lt;/li&gt;
  &lt;li&gt;生猛的进化心理学&lt;/li&gt;
  &lt;li&gt;带着鲑鱼去旅行&lt;/li&gt;
  &lt;li&gt;宇宙简史—霍金系列讲座精华&lt;/li&gt;
  &lt;li&gt;李敖快意恩仇录&lt;/li&gt;
  &lt;li&gt;霍乱时期的爱情&lt;/li&gt;
  &lt;li&gt;算法竞赛入门经典&lt;/li&gt;
  &lt;li&gt;自控力&lt;/li&gt;
  &lt;li&gt;走进搜索引擎（第2版）&lt;/li&gt;
  &lt;li&gt;拖延心理学&lt;/li&gt;
  &lt;li&gt;编程之美&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;这就是搜索引擎&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;暗时间&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;禅与摩托车维修艺术&lt;/li&gt;
  &lt;li&gt;Hadoop实战&lt;/li&gt;
  &lt;li&gt;Hadoop权威指南&lt;/li&gt;
  &lt;li&gt;MongoDB 权威指南&lt;/li&gt;
  &lt;li&gt;畅游英国&lt;/li&gt;
  &lt;li&gt;不减20斤就别说你瘦了&lt;/li&gt;
  &lt;li&gt;世界通史（彩图）&lt;/li&gt;
  &lt;li&gt;1988——我想和这个世界谈谈&lt;/li&gt;
  &lt;li&gt;人类群星闪耀时&lt;/li&gt;
  &lt;li&gt;《朝圣》&lt;/li&gt;
  &lt;li&gt;牛奶可乐经济学（完整版）&lt;/li&gt;
  &lt;li&gt;不能承受的生命之轻（百万纪念版）&lt;/li&gt;
  &lt;li&gt;算法竞赛入门经典&lt;/li&gt;
  &lt;li&gt;编程珠玑（第2版）&lt;/li&gt;
  &lt;li&gt;正能量&lt;/li&gt;
  &lt;li&gt;史蒂夫·乔布斯传 精装版&lt;/li&gt;
  &lt;li&gt;上帝掷骰子吗？&lt;/li&gt;
  &lt;li&gt;淘宝技术这十年&lt;/li&gt;
  &lt;li&gt;1984.动物庄园&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;三体3：死神永生&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;三体2：黑暗森林&lt;/li&gt;
  &lt;li&gt;三体1：地球往事&lt;/li&gt;
  &lt;li&gt;信息检索导论&lt;/li&gt;
  &lt;li&gt;搜索引擎技术基础&lt;/li&gt;
  &lt;li&gt;Head First 设计模式（中文版）&lt;/li&gt;
  &lt;li&gt;时间简史（插图本）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;构建高性能Web站点&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Effective Java中文版(第2版)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;挪威的森林（村上春树经典著作）&lt;/li&gt;
  &lt;li&gt;把你的英语用起来&lt;/li&gt;
  &lt;li&gt;数据挖掘导论(完整版)&lt;/li&gt;
  &lt;li&gt;机器学习（决战大数据时代！IT技术人员不得不读！）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;历史深处的忧虑：近距离看美国之一&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;总统是靠不住的：近距离看美国之二&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;我也有一个梦想：近距离看美国之三&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;如彗星划过夜空：近距离看美国之四&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;算法（第4版）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Java并发编程实战&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;像自由一样美丽&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;西班牙旅行笔记&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;一路走来一路读&lt;/li&gt;
  &lt;li&gt;离散数学&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Effective Java中文版(第2版)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;从一到无穷大&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;扫起落叶好过冬(林达著)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;黑客与画家&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;重来（更为简单有效的商业思维 ）&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;物理世界奇遇记(中译本）&lt;/li&gt;
  &lt;li&gt;啊哈，灵机一动&lt;/li&gt;
  &lt;li&gt;银河帝国&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;深入浅出Node.js&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;大话处理器&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;七周七语言&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;JavaScript高级程序设计&lt;/li&gt;
  &lt;li&gt;GRE词汇精选&lt;/li&gt;
  &lt;li&gt;深入理解计算机系统&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;重构：改善既有代码的设计&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;TCP/IP 详解(卷1:协议)&lt;/li&gt;
  &lt;li&gt;巴西：未来之国&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;汇编语言(第3版）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;深入理解Java虚拟机&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;推荐系统实践&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;社交网站的数据挖掘与分析&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;信息简史&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;计算机程序设计艺术 卷4A&lt;/li&gt;
  &lt;li&gt;敏捷软件开发——原则、模式与实践&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;维罗妮卡决定去死&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;少女布莱达灵修之旅&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;魔鬼与普里姆小姐&lt;/li&gt;
  &lt;li&gt;波多贝罗的女巫&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;大型网站技术架构&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;大规模分布式存储系统&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;机器学习实战&lt;/li&gt;
  &lt;li&gt;统计自然语言处理&lt;/li&gt;
  &lt;li&gt;啊哈C！思考快你一步&lt;/li&gt;
  &lt;li&gt;统计学习方法&lt;/li&gt;
  &lt;li&gt;大数据日知录：架构与算法&lt;/li&gt;
  &lt;li&gt;大型网站系统与Java中间件实践&lt;/li&gt;
  &lt;li&gt;编程珠玑：续&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;把信送给加西亚&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;万物简史&lt;/li&gt;
  &lt;li&gt;《大设计》&lt;/li&gt;
  &lt;li&gt;量子宇宙&lt;/li&gt;
  &lt;li&gt;啊哈！算法&lt;/li&gt;
  &lt;li&gt;我的简史&lt;/li&gt;
  &lt;li&gt;少有人走的路&lt;/li&gt;
  &lt;li&gt;如何阅读一本书&lt;/li&gt;
  &lt;li&gt;模式识别（第四版）&lt;/li&gt;
  &lt;li&gt;概率论与数理统计习题全解指南 浙大第四版&lt;/li&gt;
  &lt;li&gt;线性代数(原书第7版)&lt;/li&gt;
  &lt;li&gt;高效程序员的45个习惯：敏捷开发修炼之道&lt;/li&gt;
  &lt;li&gt;高等数学 同济第六版(上册)&lt;/li&gt;
  &lt;li&gt;高等数学 同济第六版（下册）&lt;/li&gt;
  &lt;li&gt;数据挖掘导论(完整版)&lt;/li&gt;
  &lt;li&gt;概率论与数理统计 浙大第四版（新版）&lt;/li&gt;
  &lt;li&gt;C++ Primer中文版（第5版）&lt;/li&gt;
  &lt;li&gt;More Effective C++&lt;/li&gt;
  &lt;li&gt;Effective C++&lt;/li&gt;
  &lt;li&gt;Web 前端黑客技术揭秘&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;深入浅出统计学&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;从你的全世界路过：让所有人心动的故事(电子书)&lt;/li&gt;
  &lt;li&gt;向前一步(电子书)&lt;/li&gt;
  &lt;li&gt;全球最美的地方精华特辑.走遍美国(电子书)&lt;/li&gt;
  &lt;li&gt;卡耐基当众演讲的艺术(电子书)&lt;/li&gt;
  &lt;li&gt;你一定爱读的极简欧洲史(电子书) &lt;/li&gt;
  &lt;li&gt;UNIX编程艺术&lt;/li&gt;
  &lt;li&gt;英语阅读参考手册&lt;/li&gt;
  &lt;li&gt;深入浅出数据分析&lt;/li&gt;
  &lt;li&gt;谁说菜鸟不会数据分析&lt;/li&gt;
  &lt;li&gt;果壳中的宇宙·霍金（插图本） &lt;/li&gt;
  &lt;li&gt;文明之光 1-2 套装全2册 &lt;/li&gt;
  &lt;li&gt;线性代数及其应用（原书第3版） &lt;/li&gt;
  &lt;li&gt;Vim实用技巧 &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;信息简史&lt;/strong&gt; &lt;/li&gt;
  &lt;li&gt;MacTalk 人生元编程 &lt;/li&gt;
  &lt;li&gt;Mahout实战 &lt;/li&gt;
  &lt;li&gt;程序员的数学 &lt;/li&gt;
  &lt;li&gt;CPU自制入门 &lt;/li&gt;
  &lt;li&gt;Aha!Gotcha啊哈!原来如此&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;代码整洁之道&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Head First Python（中文版）&lt;/li&gt;
  &lt;li&gt;鸟哥的Linux私房菜 基础学习篇(第三版)&lt;/li&gt;
  &lt;li&gt;此生未完成：一个母亲、妻子、女儿的生命日记&lt;/li&gt;
  &lt;li&gt;白鹿原&lt;/li&gt;
  &lt;li&gt;看见&lt;/li&gt;
  &lt;li&gt;重口味心理学&lt;/li&gt;
  &lt;li&gt;偷影子的人&lt;/li&gt;
  &lt;li&gt;沃顿商学院最受欢迎的谈判课&lt;/li&gt;
  &lt;li&gt;天才在左疯子在右 &lt;/li&gt;
  &lt;li&gt;矩阵分析与应用（第2版）&lt;/li&gt;
  &lt;li&gt;人工智能智能系统指南(原书第2版)&lt;/li&gt;
  &lt;li&gt;挑战程序设计竞赛 （第2版）&lt;/li&gt;
  &lt;li&gt;硅谷百年史——伟大的科技创新与创业历程(1900-2013)&lt;/li&gt;
  &lt;li&gt;数学女孩&lt;/li&gt;
  &lt;li&gt;神似祖先&lt;/li&gt;
  &lt;li&gt;GRE数学高分快速突破&lt;/li&gt;
  &lt;li&gt;大话数据结构&lt;/li&gt;
  &lt;li&gt;大话设计模式&lt;/li&gt;
  &lt;li&gt;挑战编程：程序设计竞赛训练手册&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;信息论基础（原书第2版）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;人工智能（英文版）&lt;/li&gt;
  &lt;li&gt;数据结构与算法分析Java语言描述 第2版&lt;/li&gt;
  &lt;li&gt;阿莱夫&lt;/li&gt;
  &lt;li&gt;带一本书去巴黎&lt;/li&gt;
  &lt;li&gt;历史在你我身边&lt;/li&gt;
  &lt;li&gt;哥德尔、艾舍尔、巴赫：集异璧之大成&lt;/li&gt;
  &lt;li&gt;代码的未来&lt;/li&gt;
  &lt;li&gt;凸优化&lt;/li&gt;
  &lt;li&gt;C++ Primer Plus(第6版)中文版&lt;/li&gt;
  &lt;li&gt;机器学习：实用案例解析&lt;/li&gt;
  &lt;li&gt;具体数学&lt;/li&gt;
  &lt;li&gt;文明之光（三）&lt;/li&gt;
  &lt;li&gt;数学之美（第二版）&lt;/li&gt;
  &lt;li&gt;你不可不知道50个数学知识&lt;/li&gt;
  &lt;li&gt;算法帝国&lt;/li&gt;
&lt;/ol&gt;
</description>
                <link>http://zhou-dong.github.io/2014/11/27/book-list</link>
                <guid>http://zhou-dong.github.io/2014/11/27/book-list</guid>
                <pubDate>2014-11-27T00:00:00-06:00</pubDate>
        </item>


</channel>
</rss>
